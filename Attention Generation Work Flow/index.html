
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://localhost:8000/Attention%20Generation%20Work%20Flow/">
      
      
        <link rel="prev" href="../Visualization%20Work%20Flow/">
      
      
        <link rel="next" href="../Autograd%20mechanics%20%E2%80%94%20PyTorch%202_3%20documentation/">
      
      
      <link rel="icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.39">
    
    
      
        <title>Attention Generation Work Flow - One Last Kiss</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-M0R7V8QGQ7"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-M0R7V8QGQ7",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-M0R7V8QGQ7",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#attention-generation-work-flow" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="One Last Kiss" class="md-header__button md-logo" aria-label="One Last Kiss" data-md-component="logo">
      
  <img src="../img/icon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            One Last Kiss
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Attention Generation Work Flow
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/aletolia/aletolia.github.io.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    aletolia/aletolia.github.io
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href=".." class="md-tabs__link">
          
  
    
  
  🏠 Home

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../Mygo/" class="md-tabs__link">
          
  
    
  
  ⛏️ CV and Multimodels

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../Session%201/" class="md-tabs__link">
          
  
    
  
  🚀 Re:0 Road to CPath & Visualization

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../1.1%20Single-cell%20RNA%20sequencing/" class="md-tabs__link">
          
  
    
  
  💤 Re:0 Road to scRNA-seq Analysis

        </a>
      </li>
    
  

    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../Large-scale%20foundation%20model%20on%20single-cell%20transcriptomics/" class="md-tabs__link">
          
  
    
  
  🧬 scRNA Analysis

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../%E7%AC%AC%201%20%E7%AB%A0%20python%20%E5%85%A5%E9%97%A8/" class="md-tabs__link">
          
  
    
  
  📐 Data Structures

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../Best%20practices%20for%20single-cell%20analysis%20across%20modalities/" class="md-tabs__link">
          
  
    
  
  💡 Reviews

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="One Last Kiss" class="md-nav__button md-logo" aria-label="One Last Kiss" data-md-component="logo">
      
  <img src="../img/icon.png" alt="logo">

    </a>
    One Last Kiss
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/aletolia/aletolia.github.io.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    aletolia/aletolia.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href=".." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    🏠 Home
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            🏠 Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ⛏️ CV and Multimodels
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            ⛏️ CV and Multimodels
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Mygo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MyGO: Discrete Modality Information as Fine-Grained Tokens for Multi-modal Knowledge Graph Completion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GMM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GMM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DINO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DINO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Mamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Mamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ViT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ViT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Self-Supervised%20Learning%20MoCo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MoCo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Self-Supervised%20Learning%20MoCoV2%2C3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MoCo V2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%28%E4%B8%80%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer  (一)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%20%28%E4%BA%8C%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer (二)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%28%E4%B8%89%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer  (三)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%28%E5%9B%9B%29%20%28TNT%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer (四)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%28%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%20%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer (知识蒸馏 预训练）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%28PyramidTNT%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer(Pyramid TNT)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0%E5%92%8C%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E4%B8%93%E9%A2%98/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    傅里叶级数和傅里叶变换专题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Python%20%E5%AD%98%E5%82%A8%E4%B8%8E%E8%AF%BB%E5%8F%96%20HDF5%20%E6%96%87%E4%BB%B6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python 存储与读取 HDF5 文件
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Segment%20Anything%20in%20Medical%20Images/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Segment Anything in Medical Images
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Mamba%20Efficient%20Visual%20Representation%20Learning%20with%20Bidirectional%20State%20Space%20Model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Mamba Efficient Visual Representation Learning with Bidirectional State Space Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_18" >
        
          
          <label class="md-nav__link" for="__nav_2_18" id="__nav_2_18_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🚑 医学影像相关
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_18">
            <span class="md-nav__icon md-icon"></span>
            🚑 医学影像相关
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Why%20is%20the%20winner%20the%20best/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Why is the winner the best
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PORPOISE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PORPOISE
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../HIPT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scaling Vision Transformers to Gigapixel Images via Hierarchical Self-Supervised Learning(HIPT)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Data-efficient%20and%20weakly%20supervised%20computational%20pathology%20on%20whole-slide%20images%28CLAM%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data efficient and weakly supervised computational pathology on whole slide images(CLAM)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Towards%20a%20general-purpose%20foundation%20model%20for%20computational%20pathology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Towards a general purpose foundation model for computational pathology
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20whole-slide%20foundation%20model%20for%20digital%20pathology%20from%20real-world%20data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A whole slide foundation model for digital pathology from real world data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20visual-language%20foundation%20model%20for%20computational%20pathology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A visual language foundation model for computational pathology
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Recurrent%20memory%20with%20optimal%20polynomial%20projections./" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recurrent memory with optimal polynomial projections.
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Modeling%20Dense%20Multimodal%20Interactions%20Between%20Biological%20Pathways%20and%20Histology%20for%20Survival%20Prediction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Inferring%20super-resolution%20tissue%20architecture%20by%20integrating%20spatial%20transcriptomics%20with%20histology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inferring super resolution tissue architecture by integrating spatial transcriptomics with histology
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Prediction%20of%20recurrence%20risk%20in%20endometrial%20cancer%20with%20multimodal%20deep%20learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prediction of recurrence risk in endometrial cancer with multimodal deep learning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    🚀 Re:0 Road to CPath & Visualization
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            🚀 Re:0 Road to CPath & Visualization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Session%201/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    理解全幅切片图像
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Session%202/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在计算病理学中用于癌症诊断的弱监督深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Session%203/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于注意力的多示例学习可解释性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../How%20to%20visualize%20Attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to visualize Attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AttentionViz%20A%20Global%20View%20of%20Transformer%20Attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AttentionViz A Global View of Transformer Attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Transformer%20Interpretability%20Beyond%20Attention%20Visualization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer Interpretability Beyond Attention Visualization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Visualization%20Work%20Flow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualization Work Flow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Attention Generation Work Flow
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Attention Generation Work Flow
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#clam_sb" class="md-nav__link">
    <span class="md-ellipsis">
      CLAM_SB 架构的定义
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-explainability" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer-Explainability
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_9" >
        
          
          <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="">
            
  
  <span class="md-ellipsis">
    🪛 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_9">
            <span class="md-nav__icon md-icon"></span>
            🪛 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Autograd%20mechanics%20%E2%80%94%20PyTorch%202_3%20documentation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd mechanics — PyTorch 2 3 documentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PyTorch%20Autograd%20Explained%20-%20In-depth%20Tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Autograd Explained   In depth Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    💤 Re:0 Road to scRNA-seq Analysis
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            💤 Re:0 Road to scRNA-seq Analysis
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Using Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Using Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1_1" id="__nav_4_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ⏳ CHAPTER 1 简介
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_1">
            <span class="md-nav__icon md-icon"></span>
            ⏳ CHAPTER 1 简介
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.1%20Single-cell%20RNA%20sequencing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1.The building block of life
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.2%20Raw%20Data%20Processing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 Raw data processing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.3%20Analysis%20frameworks%20and%20tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.3 Analysis frameworks and tools
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_2" >
        
          
          <label class="md-nav__link" for="__nav_4_1_2" id="__nav_4_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🌏 CHAPTER 2 数据准备与可视化
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_2">
            <span class="md-nav__icon md-icon"></span>
            🌏 CHAPTER 2 数据准备与可视化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.1%20quality_control/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.1 Quality Control
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.2%20normalization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.2 Normalization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.3_feature_selection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.3 Feature selection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.4_dimensionality_reduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.4 Dimensionality Reduction
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_3" >
        
          
          <label class="md-nav__link" for="__nav_4_1_3" id="__nav_4_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🍀 CHAPTER 3 识别细胞结构
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_3">
            <span class="md-nav__icon md-icon"></span>
            🍀 CHAPTER 3 识别细胞结构
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.1clustering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 Clustering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.2annotation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 Annotation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.3integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 Data integration
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_4" >
        
          
          <label class="md-nav__link" for="__nav_4_1_4" id="__nav_4_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ⏱️ CHAPTER 4 推断细胞轨迹
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_4">
            <span class="md-nav__icon md-icon"></span>
            ⏱️ CHAPTER 4 推断细胞轨迹
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pseudotemporal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 Pseudotemporal ordering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rna_velocity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 RNA velocity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lineage_tracing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.3 Lineage tracing
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_5" >
        
          
          <label class="md-nav__link" for="__nav_4_1_5" id="__nav_4_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🎁 CHAPTER 5 应对特殊情况
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_5">
            <span class="md-nav__icon md-icon"></span>
            🎁 CHAPTER 5 应对特殊情况
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../differential_gene_expression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 Differential gene expression analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../compositional/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.2 Compositional analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gsea_pathway/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.3 Gene set enrichment and pathway analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../perturbation_modeling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.4 Perturbation modeling
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_6" >
        
          
          <label class="md-nav__link" for="__nav_4_1_6" id="__nav_4_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ⚙️ CHAPTER 6 机制建模
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_6">
            <span class="md-nav__icon md-icon"></span>
            ⚙️ CHAPTER 6 机制建模
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gene_regulatory_networks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 Gene regulatory networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cell_cell_communication/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 Cell-cell communication
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_7" >
        
          
          <label class="md-nav__link" for="__nav_4_1_7" id="__nav_4_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🔓 CHAPTER 7 反卷积
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_7">
            <span class="md-nav__icon md-icon"></span>
            🔓 CHAPTER 7 反卷积
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bulk_deconvolution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.1 Bulk deconvolution
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    简明易懂的单细胞分析流程（使用 R 语言）
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            简明易懂的单细胞分析流程（使用 R 语言）
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%89%8D%E8%A8%80/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    环境配置
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.1%20%E6%9E%84%E5%BB%BA%E5%8D%95%E7%BB%86%E8%83%9E%20RNA-seq%20%E5%88%86%E6%9E%90%E7%8E%AF%E5%A2%83/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1 构建单细胞 RNA seq 分析环境
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.2%20R%20%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 R 环境安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.3%20Docker%20%E5%AE%89%E8%A3%85/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.3 Docker 安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.4%20%E5%9C%A8%20Docker%20%E4%B8%AD%E5%90%AF%E5%8A%A8%20Rstudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.4 在 Docker 中启动 Rstudio
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.5%20%E6%9C%89%E5%85%B3%20Bioconductor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.5 有关 Bioconductor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.1%20R%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.1 R 的基本用法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.2%20%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%20DataFrame%EF%BC%9F/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.2 如何处理 DataFrame？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.3%20%E4%BD%BF%E7%94%A8%20ggplot2%20%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.3 使用 ggplot2 可视化数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.1%20PCA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 PCA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.2%20%E4%BD%BF%E7%94%A8%20clusterPlofiler%20%E8%BF%9B%E8%A1%8C%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 使用 clusterPlofiler 进行富集分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.3%20%E5%9F%BA%E5%9B%A0%E6%9C%AC%E4%BD%93%EF%BC%88GO%EF%BC%89%E4%B8%AD%E5%90%84%20BP%E3%80%81MF%20%E5%92%8C%20CC%20%E7%9A%84%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 基因本体（GO）中各 BP、MF 和 CC 的富集分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.3%20%E4%BD%BF%E7%94%A8%20DEseq2%20%E6%8F%90%E5%8F%96%20RNA-seq%20%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%20DEG/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 使用 DEseq2 提取 RNA seq 分析数据中的 DEG
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.4%20%E4%BD%BF%E7%94%A8%E5%85%B6%E4%BB%96%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%88KEGG%E3%80%81Reactome%20%E7%AD%89%EF%BC%89%E8%BF%9B%E8%A1%8C%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.4 使用其他数据库（KEGG、Reactome 等）进行富集分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.1%20scRNA-seq%20%E6%A6%82%E8%A6%81/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 scRNA seq 概要
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.2%20%E5%87%86%E5%A4%87%E4%BD%BF%E7%94%A8%20Seurat%20%E8%BF%9B%E8%A1%8C%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 准备使用 Seurat 进行分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.3%20%E4%BD%BF%E7%94%A8%20Seurat%20%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.3 使用 Seurat 进行数据预处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.4%20%E4%BD%BF%E7%94%A8%20Seurat%20%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%9A%84%E4%B8%80%E8%88%AC%E9%A1%BA%E5%BA%8F/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.4 使用 Seurat 进行数据分析的一般顺序
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.1%20%E5%A6%82%E4%BD%95%E6%9F%A5%E6%89%BE%E5%8D%95%E7%BB%86%E8%83%9E%20RNA-seq%20%E6%95%B0%E6%8D%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 如何查找单细胞 RNA seq 数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.2%20%E4%B8%BA%E6%AF%8F%E4%B8%AA%E7%B0%87%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0%E7%BB%86%E8%83%9E%E6%B3%A8%E9%87%8A%E6%A0%87%E7%AD%BE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.2 为每个簇自动添加细胞注释标签
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.3%20%E4%BD%BF%E7%94%A8%20FeaturePlot%20%E6%A3%80%E6%9F%A5%E5%9F%BA%E5%9B%A0%E8%A1%A8%E8%BE%BE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.3 使用 FeaturePlot 检查基因表达
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.4%20%E5%B0%86%E5%8D%95%E7%BB%86%E8%83%9E%20RNA-seq%20%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E4%BA%92%E7%BB%93%E5%90%88/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.4 将单细胞 RNA seq 数据集相互结合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.5%20%E7%BA%A0%E6%AD%A3%E6%89%B9%E6%AC%A1%E6%95%88%E5%BA%94%EF%BC%8C%E6%AF%94%E8%BE%83%E5%AF%B9%E7%85%A7%E7%BB%84%E5%92%8C%E5%88%BA%E6%BF%80%E7%BB%84/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.5 纠正批次效应，比较对照组和刺激组
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.6%20%E7%A1%AE%E5%AE%9A%E6%AF%8F%E4%B8%AA%E7%BE%A4%E7%BB%84%E7%9A%84%E6%A0%87%E8%AE%B0%E5%9F%BA%E5%9B%A0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.6 确定每个群组的标记基因
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6.1%20%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%20Cell%20Ranger%20%E7%BB%9F%E8%AE%A1%20scRNA-seq%20%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%E5%9F%BA%E5%9B%A0%E8%A1%A8%E8%BE%BE%E6%B0%B4%E5%B9%B3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 如何使用 Cell Ranger 统计 scRNA seq 数据中的基因表达水平
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6.2%20%E4%BD%BF%E7%94%A8%20Cell%20Ranger%20%E5%A4%84%E7%90%86%20NCBI%20Sequence%20Read%20Archive%20%28SRA%29%20%E6%95%B0%E6%8D%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 使用 Cell Ranger 处理 NCBI Sequence Read Archive (SRA) 数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7.1%20%E5%85%B3%E4%BA%8E%20scRNA-seq%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%B4%A8%E9%87%8F%E6%8E%A7%E5%88%B6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.1 关于 scRNA seq 数据的质量控制
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7.2%20%E4%BD%BF%E7%94%A8%20DoubleFinder%20%E6%A3%80%E6%B5%8B%E5%8F%8C%E9%87%8D%E7%BB%86%E8%83%9E/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.2 使用 DoubleFinder 检测双重细胞
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7.3%20%E7%94%A8%20CellBender%20%E5%8E%BB%E9%99%A4%E8%83%8C%E6%99%AF%20RNA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.3 用 CellBender 去除背景 RNA
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🧬 scRNA Analysis
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            🧬 scRNA Analysis
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🐍 Using Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            🐍 Using Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Large-scale%20foundation%20model%20on%20single-cell%20transcriptomics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Large scale foundation model on single cell transcriptomics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scGPT%20toward%20building%20a%20foundation%20model%20for%20single-cell%20multi-omics%20using%20generative%20AI/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scGPT toward building a foundation model for single cell multi omics using generative AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scBERT%20as%20a%20large-scale%20pretrained%20deep%20language%20model%20for%20cell%20type%20annotation%20of%20single-cell%20RNA-seq%20data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scBERT as a large scale pretrained deep language model for cell type annotation of single cell RNA seq data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../RNA%20velocity%20of%20single%20cells/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RNA velocity of single cells
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../TFvelo_gene%20regulation%20inspired%20RNA%20velocity%20estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TFvelo gene regulation inspired RNA velocity estimation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Disentanglement%20of%20single-cell%20data%20with%20biolord/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Disentanglement of single cell data with biolord
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E2%AD%90%E2%AD%90%E2%AD%90C5aR1%20inhibition%20reprograms%20tumor%20associated%20macrophages%20and%20reverses%20PARP%20inhibitor%20resistance%20in%20breast%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⭐⭐⭐C5aR1 inhibition reprograms tumor associated macrophages and reverses PARP inhibitor resistance in breast cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Spatial%20transition%20tensor%20of%20single%20cells/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial transition tensor of single cells
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Statistical%20method%20scDEED%20for%20detecting%20dubious%202D%20single-cell%20embeddings%20and%20optimizing%20t-SNE%20and%20UMAP%20hyperparameters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Statistical method scDEED for detecting dubious 2D single cell embeddings and optimizing t SNE and UMAP hyperparameters
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scRank%20infers%20drug-responsive%20cell%20types%20from%20untreated%20scRNA-seq%20data%20using%20a%20target-perturbed%20gene%20regulatory%20network/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scRank infers drug responsive cell types from untreated scRNA seq data using a target perturbed gene regulatory network
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    📔 文献
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            📔 文献
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZNF689%20deficiency%20promotes%20intratumor%20heterogeneity%20and%20immunotherapy%20resistance%20in%20triple-negative%20breast%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ZNF689 deficiency promotes intratumor heterogeneity and immunotherapy resistance in triple negative breast cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Tumour%20vasculature%20at%20single-cell%20resolution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tumour vasculature at single-cell resolution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scRNA-seq%20of%20gastric%20tumor%20shows%20complex%20intercellular%20interaction%20with%20an%20alternative%20T%20cell%20exhaustion%20trajectory%EF%BC%88%E5%8F%82%E8%80%83%EF%BC%89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scRNA seq of gastric tumor shows complex intercellular interaction with an alternative T cell exhaustion trajectory（参考）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20analysis%20reveals%20new%20evolutionary%20complexity%20in%20uveal%20melanoma%EF%BC%88%E5%8F%82%E8%80%83%202%EF%BC%89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell analysis reveals new evolutionary complexity in uveal melanoma（参考 2）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20characterization%20of%20macrophages%20in%20uveal%20melanoma%20uncovers%20transcriptionally%20heterogeneous%20subsets%20conferring%20poor%20prognosis%20and%20aggressive%20behavior%EF%BC%88%E8%8C%83%E4%BE%8B%201%EF%BC%89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell characterization of macrophages in uveal melanoma uncovers transcriptionally heterogeneous subsets conferring poor prognosis and aggressive behavior（范例 1）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ScRNA-seq%20of%20gastric%20cancer%20tissues%20reveals%20differences%20in%20the%20immune%20microenvironment%20of%20primary%20tumors%20and%20metastases/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ScRNA seq of gastric cancer tissues reveals differences in the immune microenvironment of primary tumors and metastases
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Blimp-1%20and%20c-Maf%20regulate%20immune%20gene%20networks%20to%20protect%20against%20distinct%20pathways%20of%20pathobiont-induced%20colitis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Blimp 1 and c Maf regulate immune gene networks to protect against distinct pathways of pathobiont induced colitis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single%20cell%20analysis%20unveils%20B%20cell-dominated%20immune%20subtypes%20in%20HNSCC%20for%20enhanced%20prognostic%20and%20therapeutic%20stratification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell analysis unveils B cell dominated immune subtypes in HNSCC for enhanced prognostic and therapeutic stratification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20spatial%20multi-omics%20and%20deep%20learning%20dissect%20enhancer-driven%20gene%20regulatory%20networks%20in%20liver%20zonation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell spatial multi omics and deep learning dissect enhancer driven gene regulatory networks in liver zonation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Neutrophil%20profiling%20illuminates%20anti-tumor%20antigen%20presenting%20potency/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neutrophil profiling illuminates anti tumor antigen presenting potency
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20blueprint%20for%20tumor-infiltrating%20B%20cells%20across%20human%20cancers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A blueprint for tumor infiltrating B cells across human cancers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20transcriptomic%20analyses%20reveal%20distinct%20immune%20cell%20contributions%20to%20epithelial%20barrier%20dysfunction%20in%20checkpoint%20inhibitor%20colitis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell transcriptomic analyses reveal distinct immune cell contributions to epithelial barrier dysfunction in checkpoint inhibitor colitis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Systematic%20dissection%20of%20tumor-normal%20single-cell%20ecosystems%20across%20a%20thousand%20tumors%20of%2030%20cancer%20types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Systematic dissection of tumor normal single cell ecosystems across a thousand tumors of 30 cancer types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../The%20aged%20tumor%20microenvironment%20limits%20T%20cell%20control%20of%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The aged tumor microenvironment limits T cell control of cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../TIM-3%2B%20CD8%20T%20cells%20with%20a%20terminally%20exhausted%20phenotype%20retain%20functional%20capacity%20in%20hematological%20malignancies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TIM 3+ CD8 T cells with a terminally exhausted phenotype retain functional capacity in hematological malignancies
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20lactate-SREBP2%20signaling%20axis%20drives%20tolerogenic%20dendritic%20cell%20maturation%20and%20promotes%20cancer%20progression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A lactate SREBP2 signaling axis drives tolerogenic dendritic cell maturation and promotes cancer progression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20human%20omentum-specific%20mesothelial-like%20stromal%20population%20inhibits%20adipogenesis%20through%20IGFBP2%20secretion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A human omentum specific mesothelial like stromal population inhibits adipogenesis through IGFBP2 secretion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Interferon-stimulated%20neutrophils%20as%20a%20predictor%20of%20immunotherapy%20response/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Interferon stimulated neutrophils as a predictor of immunotherapy response
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Repression%20of%20latent%20NF-%CE%BAB%20enhancers%20by%20PDX1%20regulates%20%CE%B2%20cell%20functional%20heterogeneity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Repression of latent NF κB enhancers by PDX1 regulates β cell functional heterogeneity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20systematic%20pan-cancer%20study%20on%20deep%20learning-based%20prediction%20of%20multi-omic%20biomarkers%20from%20routine%20pathology%20images/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A systematic pan cancer study on deep learning based prediction of multi omic biomarkers from routine pathology images
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20and%20spatial%20transcriptomics%20analysis%20of%20non-small%20cell%20lung%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell and spatial transcriptomics analysis of non small cell lung cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Seeing%20data%20as%20t-SNE%20and%20UMAP%20do/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Seeing data as t SNE and UMAP do
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Mapping%20the%20cellular%20biogeography%20of%20human%20bone%20marrow%20niches%20using%20single-cell%20transcriptomics%20and%20proteomic%20imaging/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Mapping the cellular biogeography of human bone marrow niches using single cell transcriptomics and proteomic imaging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Onco-fetal%20Reprogramming%20of%20Endothelial%20Cells%20Drives%20Immunosuppressive%20Macrophages%20in%20Hepatocellular%20Carcinoma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Onco fetal Reprogramming of Endothelial Cells Drives Immunosuppressive Macrophages in Hepatocellular Carcinoma
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20analysis%20of%20anti-BCMA%20CAR%20T%20cell%20therapy%20in%20patients%20with%20central%20nervous%20system%20autoimmunity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell analysis of anti BCMA CAR T cell therapy in patients with central nervous system autoimmunity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20sequencing%20depicts%20tumor%20architecture%20and%20empowers%20clinical%20decision%20in%20metastatic%20conjunctival%20melanoma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell sequencing depicts tumor architecture and empowers clinical decision in metastatic conjunctival melanoma
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PR-SET7%20epigenetically%20restrains%20uterine%20interferon%20response%20and%20cell%20death%20governing%20proper%20postnatal%20stromal%20development/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PR SET7 epigenetically restrains uterine interferon response and cell death governing proper postnatal stromal development
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Clonal%20associations%20between%20lymphocyte%20subsets%20and%20functional%20states%20in%20rheumatoid%20arthritis%20synovium/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Clonal associations between lymphocyte subsets and functional states in rheumatoid arthritis synovium
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    📐 Data Structures
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            📐 Data Structures
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%201%20%E7%AB%A0%20python%20%E5%85%A5%E9%97%A8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 1 章 python 入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%202%20%E7%AB%A0%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 2 章 面向对象编程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%203%20%E7%AB%A0%20%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 3 章 算法分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%204%20%E7%AB%A0%20%E9%80%92%E5%BD%92/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 4 章 递归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%205%20%E7%AB%A0%20%E5%9F%BA%E4%BA%8E%E6%95%B0%E7%BB%84%E7%9A%84%E5%BA%8F%E5%88%97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 5 章 基于数组的序列
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%206%20%E7%AB%A0%20%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E5%8F%8C%E7%AB%AF%E9%98%9F%E5%88%97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 6 章 栈、队列和双端队列
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%207%20%E7%AB%A0%20%E9%93%BE%E8%A1%A8%28Linked%20Lists%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 7 章 链表(Linked Lists)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%208%20%E7%AB%A0%20%E6%A0%91%20%E2%98%85/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 8 章 树 ★
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%209%20%E7%AB%A0%20%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 9 章 优先级队列
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    💡 Reviews
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            💡 Reviews
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_1" >
        
          
          <label class="md-nav__link" for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🧭 scRNA analysis
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            🧭 scRNA analysis
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Best%20practices%20for%20single-cell%20analysis%20across%20modalities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Best practices for single cell analysis across modalities
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Multi-omics%20integration%20in%20biomedical%20research%20%E2%80%93%20A%20metabolomics-centric%20review/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi omics integration in biomedical research – A metabolomics centric review
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Museum%20of%20spatial%20transcriptomics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Museum of spatial transcriptomics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20guide%20to%20artificial%20intelligence%20for%20cancer%20researchers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A guide to artificial intelligence for cancer researchers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_2" >
        
          
          <label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🦠 Metabolism
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            🦠 Metabolism
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Metabolic%20analysis%20as%20a%20driver%20for%20discovery%2C%20diagnosis%2C%20and%20therapy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metabolic analysis as a driver for discovery, diagnosis, and therapy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Metabolic%20heterogeneity%20in%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metabolic heterogeneity in cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Toward%20modeling%20metabolic%20state%20from%20single-cell%20transcriptomics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Toward modeling metabolic state from single cell transcriptomics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Metabolic%20reprogramming%20and%20cancer%20progression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metabolic reprogramming and cancer progression
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_3" >
        
          
          <label class="md-nav__link" for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Protein
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_3">
            <span class="md-nav__icon md-icon"></span>
            Protein
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Proteomic%20and%20interactomic%20insights%20into%20the%20molecular%20basis%20of%20cell%20functional%20diversity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Proteomic and interactomic insights into the molecular basis of cell functional diversity
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#clam_sb" class="md-nav__link">
    <span class="md-ellipsis">
      CLAM_SB 架构的定义
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-explainability" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer-Explainability
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/aletolia/aletolia.github.io.git/edit/master/docs/Attention Generation Work Flow.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/aletolia/aletolia.github.io.git/raw/master/docs/Attention Generation Work Flow.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="attention-generation-work-flow">Attention Generation Work Flow<a class="headerlink" href="#attention-generation-work-flow" title="Permanent link">&para;</a></h1>
<p>这个文档描述了如何从网络中计算注意力分数，可以是 backbone，也可以是从 neck 中</p>
<ul>
<li>首先仍然以 CLAM 为例子</li>
</ul>
<p>注意力网络的定义</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos" data-linenos=" 2 "></span><span class="sd">注意力网络（无门控，包含两个全连接层）</span>
<span class="linenos" data-linenos=" 3 "></span><span class="sd">参数：</span>
<span class="linenos" data-linenos=" 4 "></span><span class="sd">    L: 输入特征维度</span>
<span class="linenos" data-linenos=" 5 "></span><span class="sd">    D: 隐藏层维度</span>
<span class="linenos" data-linenos=" 6 "></span><span class="sd">    dropout: 是否使用dropout（概率p = 0.25）</span>
<span class="linenos" data-linenos=" 7 "></span><span class="sd">    n_classes: 类别数</span>
<span class="linenos" data-linenos=" 8 "></span><span class="sd">&quot;&quot;&quot;</span>
<span class="linenos" data-linenos=" 9 "></span><span class="k">class</span> <span class="nc">Attn_Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos" data-linenos="10 "></span>    <span class="c1"># 构造函数，定义网络结构。</span>
<span class="linenos" data-linenos="11 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="linenos" data-linenos="12 "></span>        <span class="nb">super</span><span class="p">(</span><span class="n">Attn_Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>  <span class="c1"># 调用父类的构造函数，初始化模块。</span>
<span class="linenos" data-linenos="13 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos="14 "></span>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">D</span><span class="p">),</span>  <span class="c1"># 定义第一个全连接层，从输入特征维度L到隐藏层维度D。</span>
<span class="linenos" data-linenos="15 "></span>            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()]</span>  <span class="c1"># 使用Tanh激活函数。</span>
<span class="linenos" data-linenos="16 "></span>
<span class="linenos" data-linenos="17 "></span>        <span class="k">if</span> <span class="n">dropout</span><span class="p">:</span>
<span class="linenos" data-linenos="18 "></span>            <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>  <span class="c1"># 如果启用dropout，添加一个dropout层，丢弃率为0.25。</span>
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>  <span class="c1"># 添加第二个全连接层，从隐藏层维度D到输出类别数n_classes。</span>
<span class="linenos" data-linenos="21 "></span>
<span class="linenos" data-linenos="22 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">)</span>  <span class="c1"># 将定义的层组合成一个顺序模型。</span>
<span class="linenos" data-linenos="23 "></span>
<span class="linenos" data-linenos="24 "></span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="linenos" data-linenos="25 "></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span>  <span class="c1"># 前向传播函数，返回注意力网络的输出和原始输入x。返回形式为N x n_classes。</span>
</code></pre></div>
<p>应该说，这个网络的定义并非严格意义上的 <code>attention_net</code> ，接下来则是“门控注意力”</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">class</span> <span class="nc">Attn_Net_Gated</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="c1"># 构造函数，定义网络结构。</span>
<span class="linenos" data-linenos=" 3 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="linenos" data-linenos=" 4 "></span>        <span class="nb">super</span><span class="p">(</span><span class="n">Attn_Net_Gated</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>  <span class="c1"># 调用父类的构造函数，初始化模块。</span>
<span class="linenos" data-linenos=" 5 "></span>        <span class="c1"># 定义第一组注意力机制的层，使用 Tanh 激活函数。</span>
<span class="linenos" data-linenos=" 6 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_a</span> <span class="o">=</span> <span class="p">[</span>
<span class="linenos" data-linenos=" 7 "></span>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">D</span><span class="p">),</span>  <span class="c1"># 定义全连接层，从输入特征维度L到隐藏层维度D。</span>
<span class="linenos" data-linenos=" 8 "></span>            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()]</span>  <span class="c1"># 应用 Tanh 激活函数。</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>        <span class="c1"># 定义第二组注意力机制的层，使用 Sigmoid 激活函数。</span>
<span class="linenos" data-linenos="11 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">D</span><span class="p">),</span>  <span class="c1"># 定义全连接层。</span>
<span class="linenos" data-linenos="12 "></span>                            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()]</span>  <span class="c1"># 应用 Sigmoid 激活函数来实现门控。</span>
<span class="linenos" data-linenos="13 "></span>
<span class="linenos" data-linenos="14 "></span>        <span class="k">if</span> <span class="n">dropout</span><span class="p">:</span>
<span class="linenos" data-linenos="15 "></span>            <span class="bp">self</span><span class="o">.</span><span class="n">attention_a</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>  <span class="c1"># 如果启用 dropout，为第一组添加 dropout 层。</span>
<span class="linenos" data-linenos="16 "></span>            <span class="bp">self</span><span class="o">.</span><span class="n">attention_b</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>  <span class="c1"># 为第二组添加 dropout 层。</span>
<span class="linenos" data-linenos="17 "></span>
<span class="linenos" data-linenos="18 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_a</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_a</span><span class="p">)</span>  <span class="c1"># 将第一组层组合成顺序模型。</span>
<span class="linenos" data-linenos="19 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_b</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_b</span><span class="p">)</span>  <span class="c1"># 将第二组层组合成顺序模型。</span>
<span class="linenos" data-linenos="20 "></span>
<span class="linenos" data-linenos="21 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_c</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>  <span class="c1"># 定义第三个全连接层，用于将经过门控的特征映射到类别数。</span>
<span class="linenos" data-linenos="22 "></span>
<span class="linenos" data-linenos="23 "></span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="linenos" data-linenos="24 "></span>        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_a</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 通过第一组层处理输入数据 x。</span>
<span class="linenos" data-linenos="25 "></span>        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_b</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># 通过第二组层处理输入数据 x。</span>
<span class="linenos" data-linenos="26 "></span>        <span class="n">A</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>  <span class="c1"># 将两组输出的结果相乘，实现门控机制。</span>
<span class="linenos" data-linenos="27 "></span>        <span class="n">A</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_c</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>  <span class="c1"># 将门控后的特征通过第三层映射到类别输出。</span>
<span class="linenos" data-linenos="28 "></span>        <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">x</span>  <span class="c1"># 返回类别输出和原始输入。</span>
</code></pre></div>
<p>这里的 <code>Attn_Net_Gate</code> 实际上实现了下面的式子</p>
<div class="arithmatex">\[
\begin{gathered}
a_i, k=\frac{\exp \left\{W_{\mathrm{a}, i}\left(\tanh \left(V_{\mathrm{a}} \mathbf{h}_k\right) \odot \operatorname{sigm}\left(U_{\mathrm{a}} \mathbf{h}_k\right)\right)\right\}}{\sum_{j=1}^K \exp \left\{W_{\mathrm{a}, i}\left(\tanh \left(V_{\mathrm{a}} \mathbf{h}_j\right) \odot \operatorname{sigm}\left(U_{\mathrm{a}} \mathbf{h}_j\right)\right)\right\}} \\
\mathbf{h}_{\mathrm{slide}, i}=\sum_{k=1}^K a_{i, k} \mathbf{h}_k
\end{gathered}
\]</div>
<p>如原文所述：注意网络由若干堆叠的完全连接层组成；如果我们将注意网络的前两层 <span class="arithmatex">\(U_{\mathrm{a}} \in \mathbb{R}^{256 \times 512}\)</span> 和 <span class="arithmatex">\(V_{\mathrm{a}} \in \mathbb{R}^{256 \times 512}\)</span> 以及 <span class="arithmatex">\(W_1\)</span> 一起视为所有类共享的注意力骨干的一部分，那么注意网络将分为 <span class="arithmatex">\(N\)</span> 个并行的注意力分支 <span class="arithmatex">\(W_{\mathrm{a}, 1}, \ldots, W_{\mathrm{a}, \mathrm{N}} \in \mathbb{R}^{1 \times 256}\)</span>。</p>
<h2 id="clam_sb">CLAM_SB 架构的定义<a class="headerlink" href="#clam_sb" title="Permanent link">&para;</a></h2>
<p>在构造上，<code>CLAM_SB</code> 在定义时定义了下面的几个 layer</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">class</span> <span class="nc">CLAM_SB</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="c1"># 构造函数，初始化网络结构。</span>
<span class="linenos" data-linenos=" 3 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size_arg</span><span class="o">=</span><span class="s2">&quot;small&quot;</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">k_sample</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="linenos" data-linenos=" 4 "></span>                 <span class="n">instance_loss_fn</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span> <span class="n">subtyping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">1024</span><span class="p">):</span>
<span class="linenos" data-linenos=" 5 "></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>  <span class="c1"># 调用父类的构造函数。</span>
<span class="linenos" data-linenos=" 6 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">size_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;small&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">embed_dim</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span> <span class="s2">&quot;big&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">embed_dim</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">384</span><span class="p">]}</span>
<span class="linenos" data-linenos=" 7 "></span>        <span class="n">size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">size_dict</span><span class="p">[</span><span class="n">size_arg</span><span class="p">]</span>  <span class="c1"># 根据网络尺寸配置获取维度参数。</span>
<span class="linenos" data-linenos=" 8 "></span>        <span class="n">fc</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)]</span>  <span class="c1"># 定义全连接层序列。</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>        <span class="c1"># 根据是否使用门控选择相应的注意力网络。</span>
<span class="linenos" data-linenos="11 "></span>        <span class="k">if</span> <span class="n">gate</span><span class="p">:</span>
<span class="linenos" data-linenos="12 "></span>            <span class="n">attention_net</span> <span class="o">=</span> <span class="n">Attn_Net_Gated</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">D</span><span class="o">=</span><span class="n">size</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos" data-linenos="13 "></span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos" data-linenos="14 "></span>            <span class="n">attention_net</span> <span class="o">=</span> <span class="n">Attn_Net</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">D</span><span class="o">=</span><span class="n">size</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos" data-linenos="15 "></span>        <span class="n">fc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attention_net</span><span class="p">)</span>
<span class="linenos" data-linenos="16 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attention_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">fc</span><span class="p">)</span>  <span class="c1"># 创建注意力网络。</span>
<span class="linenos" data-linenos="17 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">classifiers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_classes</span><span class="p">)</span>  <span class="c1"># 定义主分类器。</span>
<span class="linenos" data-linenos="18 "></span>        <span class="n">instance_classifiers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)]</span>  <span class="c1"># 为每个类别定义实例分类器。</span>
<span class="linenos" data-linenos="19 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">instance_classifiers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">instance_classifiers</span><span class="p">)</span>  <span class="c1"># 创建实例分类器列表。</span>
<span class="linenos" data-linenos="20 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">k_sample</span> <span class="o">=</span> <span class="n">k_sample</span>  <span class="c1"># 设置采样数量。</span>
<span class="linenos" data-linenos="21 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">instance_loss_fn</span> <span class="o">=</span> <span class="n">instance_loss_fn</span>  <span class="c1"># 设置实例级损失函数。</span>
<span class="linenos" data-linenos="22 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">n_classes</span> <span class="o">=</span> <span class="n">n_classes</span>  <span class="c1"># 设置类别数量。</span>
<span class="linenos" data-linenos="23 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">subtyping</span> <span class="o">=</span> <span class="n">subtyping</span>  <span class="c1"># 设置是否为亚型问题。</span>
</code></pre></div>
<ul>
<li><code>attention_net</code>：由门控注意力层和一层全连接层构成</li>
<li><code>classifiers</code>：一个分类头</li>
</ul>
<p>前向传播中，即通过了一次 <code>attention_net</code>，返回注意力分数 A 后对 A 进行 <code>softmax</code></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">instance_eval</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_features</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">attention_only</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="linenos" data-linenos="2 "></span>        <span class="n">A</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_net</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>  <span class="c1"># 通过注意力网络处理输入h，得到注意力得分A和更新后的特征h，NxK。</span>
<span class="linenos" data-linenos="3 "></span>        <span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># 转置A以匹配后续操作的维度要求，KxN。</span>
<span class="linenos" data-linenos="4 "></span>
<span class="linenos" data-linenos="5 "></span>        <span class="k">if</span> <span class="n">attention_only</span><span class="p">:</span>
<span class="linenos" data-linenos="6 "></span>            <span class="k">return</span> <span class="n">A</span>  <span class="c1"># 如果仅需要注意力得分，则直接返回A。</span>
<span class="linenos" data-linenos="7 "></span>
<span class="linenos" data-linenos="8 "></span>        <span class="n">A_raw</span> <span class="o">=</span> <span class="n">A</span>  <span class="c1"># 保存原始的注意力得分。</span>
<span class="linenos" data-linenos="9 "></span>        <span class="n">A</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 对N维进行softmax操作，归一化注意力得分</span>
</code></pre></div>
<p>进行迭代，迭代过程中进行实例评估，调用</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">instance_loss</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inst_eval</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">classifier</span><span class="p">)</span>
</code></pre></div>
<p>首先检查输入维度</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
<span class="linenos" data-linenos="2 "></span>            <span class="n">A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 调整A的形状。</span>
</code></pre></div>
<p>检查输入张量 <code>A</code> 的形状。如果 <code>A</code> 只有一个维度，则将其重新整形为具有两个维度的张量。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">top_p_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_sample</span><span class="p">)[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># 获取正样本的top k样本索引。</span>
<span class="linenos" data-linenos="2 "></span><span class="n">top_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">top_p_ids</span><span class="p">)</span>  <span class="c1"># 根据索引选择正样本。</span>
<span class="linenos" data-linenos="3 "></span><span class="n">top_n_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="o">-</span><span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_sample</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># 获取负样本的top k样本索引。</span>
<span class="linenos" data-linenos="4 "></span><span class="n">top_n</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">top_n_ids</span><span class="p">)</span>  <span class="c1"># 根据索引选择负样本。</span>
</code></pre></div>
<p><code>top_p_ids = torch.topk(A, self.k_sample)[1][-1]</code>: 使用 <code>torch.topk</code> 函数找到 <code>A</code> 中值最大的 <code>k_sample</code> 个元素的索引并存储在 <code>top_p_ids</code> 中。这些索引对应于最有可能属于正样本的数据点。</p>
<p><code>top_p = torch.index_select(h, dim=0, index=top_p_ids)</code>: 使用 <code>torch.index_select</code> 函数根据 <code>top_p_ids</code> 中的索引从嵌入张量 <code>h</code> 中选取对应的行，得到 <code>k_sample</code> 个最有可能属于正样本的嵌入，并存储在 <code>top_p</code> 中。</p>
<p><code>top_n_ids = torch.topk(-A, self.k_sample, dim=1)[1][-1]</code>: 类似于选择正样本，这行代码找到 <code>A</code> 中值最小的 <code>k_sample</code> 个元素的索引并存储在 <code>top_n_ids</code> 中，这些索引对应于最有可能属于负样本的数据点。</p>
<p><code>top_n = torch.index_select(h, dim=0, index=top_n_ids)</code>: 类似于选择正样本的嵌入，根据 <code>top_n_ids</code> 中的索引从嵌入张量 <code>h</code> 中选取对应的行，得到 <code>k_sample</code> 个最有可能属于负样本的嵌入，并存储在 <code>top_n</code> 中。</p>
<ul>
<li>根据之前的代码，<code>x</code> 是原始输入</li>
</ul>
<p>接下来创建用于后续计算损失的正负样本目标：</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">p_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_positive_targets</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_sample</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">n_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_negative_targets</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k_sample</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</code></pre></div>
<p>这分别是两个静态方法</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="nd">@staticmethod</span>
<span class="linenos" data-linenos="2 "></span>    <span class="k">def</span> <span class="nf">create_positive_targets</span><span class="p">(</span><span class="n">length</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="linenos" data-linenos="3 "></span>        <span class="c1"># 创建正样本目标。</span>
<span class="linenos" data-linenos="4 "></span>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">length</span><span class="p">,),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
</code></pre></div>
<p>该静态方法用于创建正样本目标。它接收两个参数：</p>
<ul>
<li><code>length</code>: 要创建的正样本目标的数量 (与 <code>k_sample</code> 相同)。</li>
<li><code>device</code>: 张量所在的设备信息 (CPU 或 GPU)。</li>
</ul>
<p>函数内部使用 <code>torch.full</code> 函数创建一个指定形状 (<code>(length,)</code>) 的全 1 张量。该张量中的所有元素都设置为 1，表示正样本的目标值。 <code>device=device</code> 参数确保创建的张量位于与输入数据相同的设备上</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">all_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">p_targets</span><span class="p">,</span> <span class="n">n_targets</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">all_instances</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">top_p</span><span class="p">,</span> <span class="n">top_n</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<ul>
<li><code>all_targets = torch.cat([p_targets, n_targets], dim=0)</code>: 使用 <code>torch.cat</code> 函数将正负样本目标张量 (<code>p_targets</code> 和 <code>n_targets</code>) 在第 0 维 (batch 维度) 进行拼接，得到包含所有样本目标的张量 <code>all_targets</code>。</li>
<li><code>all_instances = torch.cat([top_p, top_n], dim=0)</code>: 类似于合并目标，将正负样本的嵌入张量 (<code>top_p</code> 和 <code>top_n</code>) 在第 0 维进行拼接，得到包含所有样本实例的张量 <code>all_instances</code>。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">ogits</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">(</span><span class="n">all_instances</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">all_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<ul>
<li><code>logits = classifier(all_instances)</code>: 将所有样本实例 (<code>all_instances</code>) 送入分类器 (<code>classifier</code>) 进行分类，得到 logits (未归一化的类别概率)</li>
<li><code>torch.topk(logits, 1, dim=1)</code>: 该部分使用 <code>torch.topk</code> 函数找到 logits 中每个样本得分最高的元素 (top 1) 的索引，并将其存储在张量中</li>
<li><code>[1]</code>: 取 <code>torch.topk</code> 函数返回结果的第二个元素，即包含每个样本得分最高元素的索引张量。</li>
<li><code>.squeeze(1)</code>: 去除索引张量的第二维 (因为我们只关心每个样本的单一预测类别)。 这将得到一个包含所有样本预测类别的张量 <code>all_preds</code></li>
</ul>
<p>计算损失函数（交叉熵）</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">instance_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance_loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">all_targets</span><span class="p">)</span>
</code></pre></div>
<h2 id="transformer-explainability">Transformer-Explainability<a class="headerlink" href="#transformer-explainability" title="Permanent link">&para;</a></h2>
<p>以 DeiT 的可视化为例，首先使用 <code>transforms</code> 进行图像尺寸的转化</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="c1"># 设置图像预处理的归一化操作，指定均值和标准差</span>
<span class="linenos" data-linenos="2 "></span><span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="linenos" data-linenos="3 "></span>
<span class="linenos" data-linenos="4 "></span><span class="c1"># 定义一个图像转换流程，包括缩放到224x224、转换为张量、归一化处理</span>
<span class="linenos" data-linenos="5 "></span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
<span class="linenos" data-linenos="6 "></span>    <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)),</span>  <span class="c1"># 调整图像大小</span>
<span class="linenos" data-linenos="7 "></span>    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>          <span class="c1"># 将图像转换为Tensor</span>
<span class="linenos" data-linenos="8 "></span>    <span class="n">normalize</span><span class="p">,</span>                      <span class="c1"># 应用归一化</span>
<span class="linenos" data-linenos="9 "></span><span class="p">])</span>
</code></pre></div>
<p>预设了一个热图生成函数，输入参数是 <code>img</code> 和 <code>mask</code> ，首先将 <code>mask</code> 转换为 heatmap</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">def</span> <span class="nf">show_cam_on_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
<span class="linenos" data-linenos="2 "></span>    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">applyColorMap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="mi">255</span> <span class="o">*</span> <span class="n">mask</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLORMAP_JET</span><span class="p">)</span>  <span class="c1"># 创建热图</span>
</code></pre></div>
<p>这里指将 <code>mask</code> 投影到 256 位色彩上，颜色映射使用 <code>COLORMAP_JET</code></p>
<p>然后归一化转换为浮点数后叠加到源图像上</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">heatmap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">heatmap</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>  <span class="c1"># 将热图转换为0到1的浮点数</span>
<span class="linenos" data-linenos="2 "></span><span class="n">cam</span> <span class="o">=</span> <span class="n">heatmap</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>  <span class="c1"># 将热图叠加到原始图像上</span>
<span class="linenos" data-linenos="3 "></span><span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">cam</span><span class="p">)</span>  <span class="c1"># 归一化处理以增强显示效果</span>
<span class="linenos" data-linenos="4 "></span><span class="k">return</span> <span class="n">cam</span>  <span class="c1"># 返回叠加后的图像</span>
</code></pre></div>
<p>因此实际上模型的难点在于</p>
<ol>
<li>取出每一层的注意力数值</li>
<li>按照加权（深度泰勒分解）方式解释注意力在不同 patch 处的贡献程度</li>
</ol>
<p>初始化模型，设置为 <code>eval()</code> 模式</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">model</span> <span class="o">=</span> <span class="n">vit_LRP</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="linenos" data-linenos="2 "></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="linenos" data-linenos="3 "></span><span class="n">attribution_generator</span> <span class="o">=</span> <span class="n">LRP</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div>
<p>乘此机会，也来看一下 ViT 的一般架构，下面是 <code>vit_LRP</code>  的模型定义，首先是输出联合注意力的函数</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">def</span> <span class="nf">compute_rollout_attention</span><span class="p">(</span><span class="n">all_layer_matrices</span><span class="p">,</span> <span class="n">start_layer</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="c1"># 从第一个矩阵的维度中计算出token的数量和批次大小。</span>
<span class="linenos" data-linenos=" 3 "></span>    <span class="n">num_tokens</span> <span class="o">=</span> <span class="n">all_layer_matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="linenos" data-linenos=" 4 "></span>    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">all_layer_matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos" data-linenos=" 5 "></span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="c1"># 创建一个单位矩阵，并扩展它以匹配批次大小，然后将其移动到相应的设备上。</span>
<span class="linenos" data-linenos=" 7 "></span>    <span class="n">eye</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">num_tokens</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">,</span> <span class="n">num_tokens</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">all_layer_matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span>    <span class="c1"># 为每层的注意力矩阵添加一个单位矩阵，以包括残差连接。</span>
<span class="linenos" data-linenos="10 "></span>    <span class="n">all_layer_matrices</span> <span class="o">=</span> <span class="p">[</span><span class="n">all_layer_matrices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">eye</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_layer_matrices</span><span class="p">))]</span>
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span>    <span class="c1"># 初始化联合注意力矩阵为指定起始层的注意力矩阵。</span>
<span class="linenos" data-linenos="13 "></span>    <span class="n">joint_attention</span> <span class="o">=</span> <span class="n">all_layer_matrices</span><span class="p">[</span><span class="n">start_layer</span><span class="p">]</span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span>    <span class="c1"># 从起始层开始，逐层计算联合注意力矩阵，通过矩阵乘法将当前层的注意力矩阵与之前累积的联合注意力矩阵相乘。</span>
<span class="linenos" data-linenos="16 "></span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_layer</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_layer_matrices</span><span class="p">)):</span>
<span class="linenos" data-linenos="17 "></span>        <span class="n">joint_attention</span> <span class="o">=</span> <span class="n">all_layer_matrices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">joint_attention</span><span class="p">)</span>
<span class="linenos" data-linenos="18 "></span>
<span class="linenos" data-linenos="19 "></span>    <span class="c1"># 返回计算得到的最终联合注意力矩阵。</span>
<span class="linenos" data-linenos="20 "></span>    <span class="k">return</span> <span class="n">joint_attention</span>
</code></pre></div>
<ol>
<li><strong>初始化变量</strong>：首先从输入的多层注意力矩阵列表（<code>all_layer_matrices</code>）的第一项中获取 token 的数量和批次大小。</li>
<li>接着创建一个单位矩阵，并将其扩展到与输入矩阵相同的批次大小，并确保其在相同的计算设备上。</li>
<li><strong>添加残差连接</strong>：为了考虑残差连接，函数将每一层的注意力矩阵与单位矩阵相加。这样做可以帮助改善训练过程中的梯度流动和模型的整体性能。</li>
<li><strong>计算联合注意力</strong>：从指定的起始层开始，通过矩阵连乘操作累积计算联合注意力。<strong>这个过程中，每一层的注意力矩阵会与前一层的联合注意力矩阵相乘，逐步构建从起始层到当前层的全局注意力映射。</strong></li>
<li><strong>输出最终结果</strong>：最终，函数输出从指定起始层到最后一层的联合注意力矩阵，这个矩阵包含了经过所有这些层的信息流的累积影响。</li>
</ol>
<p>接着定义了一个类，是一个多层感知机，主要用于转换特征维度</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">class</span> <span class="nc">Mlp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
<span class="linenos" data-linenos=" 3 "></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos" data-linenos=" 4 "></span>        <span class="c1"># 如果没有指定输出特征数，就使用输入特征数</span>
<span class="linenos" data-linenos=" 5 "></span>        <span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span> <span class="ow">or</span> <span class="n">in_features</span>
<span class="linenos" data-linenos=" 6 "></span>        <span class="c1"># 如果没有指定隐藏层特征数，也使用输入特征数</span>
<span class="linenos" data-linenos=" 7 "></span>        <span class="n">hidden_features</span> <span class="o">=</span> <span class="n">hidden_features</span> <span class="ow">or</span> <span class="n">in_features</span>
<span class="linenos" data-linenos=" 8 "></span>        <span class="c1"># 定义第一个全连接层</span>
<span class="linenos" data-linenos=" 9 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">)</span>
<span class="linenos" data-linenos="10 "></span>        <span class="c1"># 定义激活函数，这里使用GELU激活函数</span>
<span class="linenos" data-linenos="11 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">act</span> <span class="o">=</span> <span class="n">GELU</span><span class="p">()</span>
<span class="linenos" data-linenos="12 "></span>        <span class="c1"># 定义第二个全连接层</span>
<span class="linenos" data-linenos="13 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
<span class="linenos" data-linenos="14 "></span>        <span class="c1"># 定义dropout层，用于减少过拟合</span>
<span class="linenos" data-linenos="15 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">drop</span><span class="p">)</span>
<span class="linenos" data-linenos="16 "></span>
<span class="linenos" data-linenos="17 "></span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="linenos" data-linenos="18 "></span>        <span class="c1"># 输入通过第一个全连接层</span>
<span class="linenos" data-linenos="19 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="20 "></span>        <span class="c1"># 应用激活函数</span>
<span class="linenos" data-linenos="21 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="22 "></span>        <span class="c1"># 应用dropout</span>
<span class="linenos" data-linenos="23 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="24 "></span>        <span class="c1"># 输入通过第二个全连接层</span>
<span class="linenos" data-linenos="25 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="26 "></span>        <span class="c1"># 再次应用dropout</span>
<span class="linenos" data-linenos="27 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="28 "></span>        <span class="c1"># 返回最终结果</span>
<span class="linenos" data-linenos="29 "></span>        <span class="k">return</span> <span class="n">x</span>
<span class="linenos" data-linenos="30 "></span>
<span class="linenos" data-linenos="31 "></span>    <span class="k">def</span> <span class="nf">relprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="linenos" data-linenos="32 "></span>        <span class="c1"># 反向传播分析的最后一步，逆过程应用dropout</span>
<span class="linenos" data-linenos="33 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="34 "></span>        <span class="c1"># 逆过程通过第二个全连接层</span>
<span class="linenos" data-linenos="35 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="36 "></span>        <span class="c1"># 逆过程应用激活函数</span>
<span class="linenos" data-linenos="37 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">act</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="38 "></span>        <span class="c1"># 逆过程通过第一个全连接层</span>
<span class="linenos" data-linenos="39 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="40 "></span>        <span class="c1"># 返回最终的相关性传播结果</span>
<span class="linenos" data-linenos="41 "></span>        <span class="k">return</span> <span class="n">cam</span>
</code></pre></div>
<p>值得一提的是这里使用的 <code>relprop</code> 函数，用于模型解释性分析，主要是反向追踪输入特征对输出的影响，过程与前向传播相反</p>
<p>接下来是注意力块的定义：</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="  1 "></span><span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos" data-linenos="  2 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">attn_drop</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">proj_drop</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
<span class="linenos" data-linenos="  3 "></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos" data-linenos="  4 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>  <span class="c1"># 头的数量</span>
<span class="linenos" data-linenos="  5 "></span>        <span class="n">head_dim</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">//</span> <span class="n">num_heads</span>  <span class="c1"># 计算每个头的维度</span>
<span class="linenos" data-linenos="  6 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">head_dim</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>  <span class="c1"># 缩放因子，用于稳定训练</span>
<span class="linenos" data-linenos="  7 "></span>
<span class="linenos" data-linenos="  8 "></span>        <span class="c1"># 定义用于矩阵运算的函数</span>
<span class="linenos" data-linenos="  9 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">matmul1</span> <span class="o">=</span> <span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bhid,bhjd-&gt;bhij&#39;</span><span class="p">)</span>  <span class="c1"># Q*K^T</span>
<span class="linenos" data-linenos=" 10 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">matmul2</span> <span class="o">=</span> <span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;bhij,bhjd-&gt;bhid&#39;</span><span class="p">)</span>  <span class="c1"># A*V</span>
<span class="linenos" data-linenos=" 11 "></span>
<span class="linenos" data-linenos=" 12 "></span>        <span class="c1"># 定义全连接层，用于生成查询Q、键K和值V</span>
<span class="linenos" data-linenos=" 13 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
<span class="linenos" data-linenos=" 14 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">attn_drop</span><span class="p">)</span>  <span class="c1"># 注意力dropout</span>
<span class="linenos" data-linenos=" 15 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>  <span class="c1"># 最后的投影层</span>
<span class="linenos" data-linenos=" 16 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">proj_drop</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">proj_drop</span><span class="p">)</span>  <span class="c1"># 投影层的dropout</span>
<span class="linenos" data-linenos=" 17 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># softmax用于计算注意力权重</span>
<span class="linenos" data-linenos=" 18 "></span>
<span class="linenos" data-linenos=" 19 "></span>        <span class="c1"># 用于保存注意力权重和中间梯度的属性</span>
<span class="linenos" data-linenos=" 20 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn_cam</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos" data-linenos=" 21 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos" data-linenos=" 22 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos" data-linenos=" 23 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">v_cam</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos" data-linenos=" 24 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn_gradients</span> <span class="o">=</span> <span class="kc">None</span>
<span class="linenos" data-linenos=" 25 "></span>
<span class="linenos" data-linenos=" 26 "></span>    <span class="c1"># 以下方法用于存取注意力权重、值和梯度等中间结果</span>
<span class="linenos" data-linenos=" 27 "></span>    <span class="k">def</span> <span class="nf">get_attn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos" data-linenos=" 28 "></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span>
<span class="linenos" data-linenos=" 29 "></span>
<span class="linenos" data-linenos=" 30 "></span>    <span class="k">def</span> <span class="nf">save_attn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attn</span><span class="p">):</span>
<span class="linenos" data-linenos=" 31 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span>
<span class="linenos" data-linenos=" 32 "></span>
<span class="linenos" data-linenos=" 33 "></span>    <span class="k">def</span> <span class="nf">save_attn_cam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cam</span><span class="p">):</span>
<span class="linenos" data-linenos=" 34 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn_cam</span> <span class="o">=</span> <span class="n">cam</span>
<span class="linenos" data-linenos=" 35 "></span>
<span class="linenos" data-linenos=" 36 "></span>    <span class="k">def</span> <span class="nf">get_attn_cam</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos" data-linenos=" 37 "></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_cam</span>
<span class="linenos" data-linenos=" 38 "></span>
<span class="linenos" data-linenos=" 39 "></span>    <span class="k">def</span> <span class="nf">get_v</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos" data-linenos=" 40 "></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">v</span>
<span class="linenos" data-linenos=" 41 "></span>
<span class="linenos" data-linenos=" 42 "></span>    <span class="k">def</span> <span class="nf">save_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
<span class="linenos" data-linenos=" 43 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">v</span>
<span class="linenos" data-linenos=" 44 "></span>
<span class="linenos" data-linenos=" 45 "></span>    <span class="k">def</span> <span class="nf">save_v_cam</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cam</span><span class="p">):</span>
<span class="linenos" data-linenos=" 46 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">v_cam</span> <span class="o">=</span> <span class="n">cam</span>
<span class="linenos" data-linenos=" 47 "></span>
<span class="linenos" data-linenos=" 48 "></span>    <span class="k">def</span> <span class="nf">get_v_cam</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos" data-linenos=" 49 "></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_cam</span>
<span class="linenos" data-linenos=" 50 "></span>
<span class="linenos" data-linenos=" 51 "></span>    <span class="k">def</span> <span class="nf">save_attn_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attn_gradients</span><span class="p">):</span>
<span class="linenos" data-linenos=" 52 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn_gradients</span> <span class="o">=</span> <span class="n">attn_gradients</span>
<span class="linenos" data-linenos=" 53 "></span>
<span class="linenos" data-linenos=" 54 "></span>    <span class="k">def</span> <span class="nf">get_attn_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos" data-linenos=" 55 "></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_gradients</span>
<span class="linenos" data-linenos=" 56 "></span>
<span class="linenos" data-linenos=" 57 "></span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="linenos" data-linenos=" 58 "></span>        <span class="c1"># 对输入数据重新排列和分配头</span>
<span class="linenos" data-linenos=" 59 "></span>        <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span>
<span class="linenos" data-linenos=" 60 "></span>        <span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos=" 61 "></span>        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="s1">&#39;b n (qkv h d) -&gt; qkv b h n d&#39;</span><span class="p">,</span> <span class="n">qkv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>
<span class="linenos" data-linenos=" 62 "></span>
<span class="linenos" data-linenos=" 63 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_v</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="linenos" data-linenos=" 64 "></span>
<span class="linenos" data-linenos=" 65 "></span>        <span class="c1"># 计算注意力分数并应用softmax和dropout</span>
<span class="linenos" data-linenos=" 66 "></span>        <span class="n">dots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul1</span><span class="p">([</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
<span class="linenos" data-linenos=" 67 "></span>        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dots</span><span class="p">)</span>
<span class="linenos" data-linenos=" 68 "></span>        <span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<span class="linenos" data-linenos=" 69 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_attn</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<span class="linenos" data-linenos=" 70 "></span>        <span class="n">attn</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_attn_gradients</span><span class="p">)</span>
<span class="linenos" data-linenos=" 71 "></span>
<span class="linenos" data-linenos=" 72 "></span>        <span class="c1"># 根据注意力权重和值向量计算输出</span>
<span class="linenos" data-linenos=" 73 "></span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul2</span><span class="p">([</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">])</span>
<span class="linenos" data-linenos=" 74 "></span>        <span class="n">out</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="s1">&#39;b h n d -&gt; b n (h d)&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 75 "></span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="linenos" data-linenos=" 76 "></span>        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj_drop</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="linenos" data-linenos=" 77 "></span>        <span class="k">return</span> <span class="n">out</span>
<span class="linenos" data-linenos=" 78 "></span>
<span class="linenos" data-linenos=" 79 "></span>    <span class="k">def</span> <span class="nf">relprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="linenos" data-linenos=" 80 "></span>        <span class="c1"># 反向传播方法，用于相关性传播分析，即解释模型决策过程</span>
<span class="linenos" data-linenos=" 81 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj_drop</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 82 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 83 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="s1">&#39;b n (h d) -&gt; b h n d&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<span class="linenos" data-linenos=" 84 "></span>
<span class="linenos" data-linenos=" 85 "></span>        <span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="n">cam_v</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul2</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 86 "></span>        <span class="n">cam1</span> <span class="o">/=</span> <span class="mi">2</span>
<span class="linenos" data-linenos=" 87 "></span>        <span class="n">cam_v</span> <span class="o">/=</span> <span class="mi">2</span>
<span class="linenos" data-linenos=" 88 "></span>
<span class="linenos" data-linenos=" 89 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_v_cam</span><span class="p">(</span><span class="n">cam_v</span><span class="p">)</span>
<span class="linenos" data-linenos=" 90 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_attn_cam</span><span class="p">(</span><span class="n">cam1</span><span class="p">)</span>
<span class="linenos" data-linenos=" 91 "></span>
<span class="linenos" data-linenos=" 92 "></span>        <span class="n">cam1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 93 "></span>        <span class="n">cam1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 94 "></span>
<span class="linenos" data-linenos=" 95 "></span>        <span class="p">(</span><span class="n">cam_q</span><span class="p">,</span> <span class="n">cam_k</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul1</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 96 "></span>        <span class="n">cam_q</span> <span class="o">/=</span> <span class="mi">2</span>
<span class="linenos" data-linenos=" 97 "></span>        <span class="n">cam_k</span> <span class="o">/=</span> <span class="mi">2</span>
<span class="linenos" data-linenos=" 98 "></span>
<span class="linenos" data-linenos=" 99 "></span>        <span class="n">cam_qkv</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">([</span><span class="n">cam_q</span><span class="p">,</span> <span class="n">cam_k</span><span class="p">,</span> <span class="n">cam_v</span><span class="p">],</span> <span class="s1">&#39;qkv b h n d -&gt; b n (qkv h d)&#39;</span><span class="p">,</span> <span class="n">qkv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<span class="linenos" data-linenos="100 "></span>
<span class="linenos" data-linenos="101 "></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam_qkv</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>类似 ViT 的原始定义，要如何实现将输入转换为 <code>Q,K,V</code> 三个矩阵？最简单的实现方法就是通过线性投影将输入投影到维度*3 的维度，然后再分割开</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="bp">self</span><span class="o">.</span><span class="n">qkv</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="n">qkv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">qkv</span><span class="p">,</span> <span class="s1">&#39;b n (qkv h d) -&gt; qkv b h n d&#39;</span><span class="p">,</span> <span class="n">qkv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>
</code></pre></div>
<p>保存 <code>v</code></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="bp">self</span><span class="o">.</span><span class="n">save_v</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="k">def</span> <span class="nf">save_v</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
<span class="linenos" data-linenos="4 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <span class="n">v</span>
</code></pre></div>
<p>计算注意力分数并保存</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">dots</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul1</span><span class="p">([</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
<span class="linenos" data-linenos="2 "></span><span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">dots</span><span class="p">)</span>
<span class="linenos" data-linenos="3 "></span><span class="n">attn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<span class="linenos" data-linenos="4 "></span>
<span class="linenos" data-linenos="5 "></span><span class="bp">self</span><span class="o">.</span><span class="n">save_attn</span><span class="p">(</span><span class="n">attn</span><span class="p">)</span>
<span class="linenos" data-linenos="6 "></span>
<span class="linenos" data-linenos="7 "></span><span class="k">def</span> <span class="nf">save_attn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attn</span><span class="p">):</span>
<span class="linenos" data-linenos="8 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">attn</span>
</code></pre></div>
<p>下面是重头戏，在网络中 register 了一个 hook</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">attn</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_attn_gradients</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span>
<span class="linenos" data-linenos="3 "></span><span class="k">def</span> <span class="nf">save_attn_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attn_gradients</span><span class="p">):</span>
<span class="linenos" data-linenos="4 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">attn_gradients</span> <span class="o">=</span> <span class="n">attn_gradients</span>
</code></pre></div>
<p>在 PyTorch 中，<code>register_hook</code> 方法用于在一个 <code>torch.Tensor</code> 上 register 一个反向传播钩子。这个钩子是一个函数，它会在反向传播期间当该张量的梯度被计算时被调用，用于在反向传播时捕获并保存注意力权重 <code>attn</code> 的<strong>梯度</strong></p>
<p>当 pytorch 在计算这个变量的梯度时，这个 hook 会被自动调用，然后把梯度传到这个函数中</p>
<p>接着将这些注意力分数（权重）应用的 <code>v</code> （Value）上（进行点积）</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul2</span><span class="p">([</span><span class="n">attn</span><span class="p">,</span> <span class="n">v</span><span class="p">])</span>
</code></pre></div>
<p>使用 <code>rearrange</code> 函数来改变 <code>out</code> 张量的形状。这个操作的目的是将不同头的输出合并为单个维度，从而为后续的全连接层做准备</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">out</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="s1">&#39;b h n d -&gt; b n (h d)&#39;</span><span class="p">)</span>
</code></pre></div>
<p>全连接层输出提取好的特征</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="linenos" data-linenos="2 "></span><span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj_drop</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</code></pre></div>
<p>添加 <code>Dropout</code> 后的 <code>out</code> 可以在训练过程中提高模型的泛化能力，避免在训练数据上过度拟合</p>
<p>同时在这个注意力块中，也定义了一个相关性传播方法：</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">def</span> <span class="nf">relprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="c1"># 对输出层的Dropout进行反向传播</span>
<span class="linenos" data-linenos=" 3 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj_drop</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 4 "></span>    <span class="c1"># 对输出层的全连接层进行反向传播</span>
<span class="linenos" data-linenos=" 5 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="c1"># 将cam张量的格式从扁平化特征重新排列为多头格式，以匹配多头注意力的原始维度</span>
<span class="linenos" data-linenos=" 7 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="s1">&#39;b n (h d) -&gt; b h n d&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span>    <span class="c1"># 反向传播通过注意力机制的第二部分，即A*V，其中A是注意力权重，V是值</span>
<span class="linenos" data-linenos="10 "></span>    <span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="n">cam_v</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul2</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="11 "></span>    <span class="c1"># 由于相关性传播需要考虑到每个输入的贡献，这里将cam分成两半，确保总相关性保持不变</span>
<span class="linenos" data-linenos="12 "></span>    <span class="n">cam1</span> <span class="o">/=</span> <span class="mi">2</span>
<span class="linenos" data-linenos="13 "></span>    <span class="n">cam_v</span> <span class="o">/=</span> <span class="mi">2</span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span>    <span class="c1"># 保存反向传播的值向量V的相关性</span>
<span class="linenos" data-linenos="16 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">save_v_cam</span><span class="p">(</span><span class="n">cam_v</span><span class="p">)</span>
<span class="linenos" data-linenos="17 "></span>    <span class="c1"># 保存反向传播的注意力权重A的相关性</span>
<span class="linenos" data-linenos="18 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">save_attn_cam</span><span class="p">(</span><span class="n">cam1</span><span class="p">)</span>
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span>    <span class="c1"># 对注意力权重应用的Dropout进行反向传播</span>
<span class="linenos" data-linenos="21 "></span>    <span class="n">cam1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="22 "></span>    <span class="c1"># 使用softmax的反向传播方法进一步传播相关性</span>
<span class="linenos" data-linenos="23 "></span>    <span class="n">cam1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="24 "></span>
<span class="linenos" data-linenos="25 "></span>    <span class="c1"># 反向传播通过注意力机制的第一部分，即Q*K^T，其中Q是查询，K是键</span>
<span class="linenos" data-linenos="26 "></span>    <span class="p">(</span><span class="n">cam_q</span><span class="p">,</span> <span class="n">cam_k</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul1</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="27 "></span>    <span class="n">cam_q</span> <span class="o">/=</span> <span class="mi">2</span>
<span class="linenos" data-linenos="28 "></span>    <span class="n">cam_k</span> <span class="o">/=</span> <span class="mi">2</span>
<span class="linenos" data-linenos="29 "></span>
<span class="linenos" data-linenos="30 "></span>    <span class="c1"># 将Q、K、V的相关性张量重新组合为一个张量，准备传递给QKV的全连接层的反向传播</span>
<span class="linenos" data-linenos="31 "></span>    <span class="n">cam_qkv</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">([</span><span class="n">cam_q</span><span class="p">,</span> <span class="n">cam_k</span><span class="p">,</span> <span class="n">cam_v</span><span class="p">],</span> <span class="s1">&#39;qkv b h n d -&gt; b n (qkv h d)&#39;</span><span class="p">,</span> <span class="n">qkv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<span class="linenos" data-linenos="32 "></span>
<span class="linenos" data-linenos="33 "></span>    <span class="c1"># 对QKV全连接层进行相关性反向传播</span>
<span class="linenos" data-linenos="34 "></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam_qkv</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>然后组装成 Block</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">mlp_ratio</span><span class="o">=</span><span class="mf">4.</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">attn_drop</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
<span class="linenos" data-linenos=" 3 "></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos" data-linenos=" 4 "></span>        <span class="c1"># 第一个层归一化</span>
<span class="linenos" data-linenos=" 5 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span>        <span class="c1"># 注意力机制模块，包含前面定义的 Attention 类</span>
<span class="linenos" data-linenos=" 7 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span>
<span class="linenos" data-linenos=" 8 "></span>            <span class="n">dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">,</span> <span class="n">attn_drop</span><span class="o">=</span><span class="n">attn_drop</span><span class="p">,</span> <span class="n">proj_drop</span><span class="o">=</span><span class="n">drop</span><span class="p">)</span>
<span class="linenos" data-linenos=" 9 "></span>        <span class="c1"># 第二个层归一化</span>
<span class="linenos" data-linenos="10 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
<span class="linenos" data-linenos="11 "></span>        <span class="c1"># MLP模块，包含前面定义的 Mlp 类</span>
<span class="linenos" data-linenos="12 "></span>        <span class="n">mlp_hidden_dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dim</span> <span class="o">*</span> <span class="n">mlp_ratio</span><span class="p">)</span>
<span class="linenos" data-linenos="13 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">Mlp</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="n">mlp_hidden_dim</span><span class="p">,</span> <span class="n">drop</span><span class="o">=</span><span class="n">drop</span><span class="p">)</span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span>        <span class="c1"># 加法操作，用于实现残差连接</span>
<span class="linenos" data-linenos="16 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">add1</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()</span>
<span class="linenos" data-linenos="17 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">add2</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()</span>
<span class="linenos" data-linenos="18 "></span>        <span class="c1"># 克隆操作，用于复制输入</span>
<span class="linenos" data-linenos="19 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">clone1</span> <span class="o">=</span> <span class="n">Clone</span><span class="p">()</span>
<span class="linenos" data-linenos="20 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">clone2</span> <span class="o">=</span> <span class="n">Clone</span><span class="p">()</span>
<span class="linenos" data-linenos="21 "></span>
<span class="linenos" data-linenos="22 "></span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="linenos" data-linenos="23 "></span>        <span class="c1"># 克隆输入，准备进行第一次残差连接</span>
<span class="linenos" data-linenos="24 "></span>        <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos="25 "></span>        <span class="c1"># 第一次残差连接，注意力机制后的输出与原始输入相加</span>
<span class="linenos" data-linenos="26 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add1</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">x2</span><span class="p">))])</span>
<span class="linenos" data-linenos="27 "></span>        <span class="c1"># 克隆结果，准备进行第二次残差连接</span>
<span class="linenos" data-linenos="28 "></span>        <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos="29 "></span>        <span class="c1"># 第二次残差连接，MLP后的输出与上一步的输出相加</span>
<span class="linenos" data-linenos="30 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add2</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">x2</span><span class="p">))])</span>
<span class="linenos" data-linenos="31 "></span>        <span class="c1"># 返回最终结果</span>
<span class="linenos" data-linenos="32 "></span>        <span class="k">return</span> <span class="n">x</span>
<span class="linenos" data-linenos="33 "></span>
<span class="linenos" data-linenos="34 "></span>    <span class="k">def</span> <span class="nf">relprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="linenos" data-linenos="35 "></span>        <span class="c1"># 反向传播相关性传播，从第二个残差连接开始</span>
<span class="linenos" data-linenos="36 "></span>        <span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="n">cam2</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add2</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="37 "></span>        <span class="n">cam2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="38 "></span>        <span class="n">cam2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="39 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone2</span><span class="o">.</span><span class="n">relprop</span><span class="p">((</span><span class="n">cam1</span><span class="p">,</span> <span class="n">cam2</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="40 "></span>
<span class="linenos" data-linenos="41 "></span>        <span class="c1"># 反向传播相关性传播，处理第一个残差连接</span>
<span class="linenos" data-linenos="42 "></span>        <span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="n">cam2</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add1</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="43 "></span>        <span class="n">cam2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="44 "></span>        <span class="n">cam2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam2</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="45 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clone1</span><span class="o">.</span><span class="n">relprop</span><span class="p">((</span><span class="n">cam1</span><span class="p">,</span> <span class="n">cam2</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="46 "></span>        <span class="c1"># 返回最终的相关性传播结果</span>
<span class="linenos" data-linenos="47 "></span>        <span class="k">return</span> <span class="n">cam</span>
</code></pre></div>
<ul>
<li>初始化时，定义了两个层归一化层，一个注意力模块，和一个MLP模块。每个模块之间使用残差连接，通过加法操作来融合模块输出和输入</li>
<li>输入数据首先被克隆以用于残差连接。数据流经第一个层归一化和注意力模块，然后与原始输入相加。接着，结果再次经过层归一化和 MLP 处理，最后与之前的输出相加，形成最终输出</li>
</ul>
<p>然后是图像 embedding 模块</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">class</span> <span class="nc">PatchEmbed</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span><span class="w">    </span><span class="sd">&quot;&quot;&quot; 图像到块嵌入</span>
<span class="linenos" data-linenos=" 3 "></span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos" data-linenos=" 4 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">in_chans</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">):</span>
<span class="linenos" data-linenos=" 5 "></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos" data-linenos=" 6 "></span>        <span class="c1"># 确保图像尺寸和块尺寸是二元组形式</span>
<span class="linenos" data-linenos=" 7 "></span>        <span class="n">img_size</span> <span class="o">=</span> <span class="n">to_2tuple</span><span class="p">(</span><span class="n">img_size</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span>        <span class="n">patch_size</span> <span class="o">=</span> <span class="n">to_2tuple</span><span class="p">(</span><span class="n">patch_size</span><span class="p">)</span>
<span class="linenos" data-linenos=" 9 "></span>        <span class="c1"># 计算整个图像中的块数量</span>
<span class="linenos" data-linenos="10 "></span>        <span class="n">num_patches</span> <span class="o">=</span> <span class="p">(</span><span class="n">img_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">img_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">patch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="linenos" data-linenos="11 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">img_size</span> <span class="o">=</span> <span class="n">img_size</span>
<span class="linenos" data-linenos="12 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span> <span class="o">=</span> <span class="n">patch_size</span>
<span class="linenos" data-linenos="13 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_patches</span> <span class="o">=</span> <span class="n">num_patches</span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span>        <span class="c1"># 定义一个卷积层，用于从每个图像块中提取嵌入</span>
<span class="linenos" data-linenos="16 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">Conv2d</span><span class="p">(</span><span class="n">in_chans</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">patch_size</span><span class="p">)</span>
<span class="linenos" data-linenos="17 "></span>
<span class="linenos" data-linenos="18 "></span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="linenos" data-linenos="19 "></span>        <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
<span class="linenos" data-linenos="20 "></span>        <span class="c1"># 检查输入图像尺寸是否与模型预期匹配</span>
<span class="linenos" data-linenos="21 "></span>        <span class="k">assert</span> <span class="n">H</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">W</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> \
<span class="linenos" data-linenos="22 "></span>            <span class="sa">f</span><span class="s2">&quot;Input image size (</span><span class="si">{</span><span class="n">H</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="n">W</span><span class="si">}</span><span class="s2">) doesn&#39;t match model (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">*</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">).&quot;</span>
<span class="linenos" data-linenos="23 "></span>        <span class="c1"># 应用卷积层，然后重新排列输出以形成嵌入向量</span>
<span class="linenos" data-linenos="24 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos="25 "></span>        <span class="k">return</span> <span class="n">x</span>
<span class="linenos" data-linenos="26 "></span>
<span class="linenos" data-linenos="27 "></span>    <span class="k">def</span> <span class="nf">relprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="linenos" data-linenos="28 "></span>        <span class="c1"># 逆转换操作，用于相关性传播分析</span>
<span class="linenos" data-linenos="29 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="linenos" data-linenos="30 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">cam</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cam</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<span class="linenos" data-linenos="31 "></span>                     <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="linenos" data-linenos="32 "></span>        <span class="c1"># 将相关性传播应用到卷积层</span>
<span class="linenos" data-linenos="33 "></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>使用卷积层将每个块转换成嵌入向量，然后调整向量的排列顺序以适合后续的处理</p>
<p>接下来是一个完整的 ViT 实现</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">class</span> <span class="nc">VisionTransformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span><span class="w">    </span><span class="sd">&quot;&quot;&quot; 视觉 Transformer，支持补丁或混合 CNN 输入阶段</span>
<span class="linenos" data-linenos=" 3 "></span><span class="sd">    &quot;&quot;&quot;</span>
<span class="linenos" data-linenos=" 4 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_size</span><span class="o">=</span><span class="mi">224</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">in_chans</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
<span class="linenos" data-linenos=" 5 "></span>                 <span class="n">num_heads</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">mlp_ratio</span><span class="o">=</span><span class="mf">4.</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mlp_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_rate</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">attn_drop_rate</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
<span class="linenos" data-linenos=" 6 "></span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos" data-linenos=" 7 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>  <span class="c1"># 类别数</span>
<span class="linenos" data-linenos=" 8 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>  <span class="c1"># 特征数，与嵌入维度相同，用于与其他模型保持一致</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>        <span class="c1"># 初始化补丁嵌入模块</span>
<span class="linenos" data-linenos="11 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">patch_embed</span> <span class="o">=</span> <span class="n">PatchEmbed</span><span class="p">(</span>
<span class="linenos" data-linenos="12 "></span>                <span class="n">img_size</span><span class="o">=</span><span class="n">img_size</span><span class="p">,</span> <span class="n">patch_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span> <span class="n">in_chans</span><span class="o">=</span><span class="n">in_chans</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">)</span>
<span class="linenos" data-linenos="13 "></span>        <span class="n">num_patches</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embed</span><span class="o">.</span><span class="n">num_patches</span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span>        <span class="c1"># 初始化位置嵌入和类标记</span>
<span class="linenos" data-linenos="16 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">))</span>
<span class="linenos" data-linenos="17 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">))</span>
<span class="linenos" data-linenos="18 "></span>
<span class="linenos" data-linenos="19 "></span>        <span class="c1"># 初始化多个 Transformer 编码块</span>
<span class="linenos" data-linenos="20 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
<span class="linenos" data-linenos="21 "></span>            <span class="n">Block</span><span class="p">(</span>
<span class="linenos" data-linenos="22 "></span>                <span class="n">dim</span><span class="o">=</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">mlp_ratio</span><span class="o">=</span><span class="n">mlp_ratio</span><span class="p">,</span> <span class="n">qkv_bias</span><span class="o">=</span><span class="n">qkv_bias</span><span class="p">,</span>
<span class="linenos" data-linenos="23 "></span>                <span class="n">drop</span><span class="o">=</span><span class="n">drop_rate</span><span class="p">,</span> <span class="n">attn_drop</span><span class="o">=</span><span class="n">attn_drop_rate</span><span class="p">)</span>
<span class="linenos" data-linenos="24 "></span>            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">depth</span><span class="p">)])</span>
<span class="linenos" data-linenos="25 "></span>
<span class="linenos" data-linenos="26 "></span>        <span class="c1"># 最后的层归一化</span>
<span class="linenos" data-linenos="27 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span>
<span class="linenos" data-linenos="28 "></span>        <span class="c1"># 根据参数选择使用 MLP 或单个线性层作为分类头</span>
<span class="linenos" data-linenos="29 "></span>        <span class="k">if</span> <span class="n">mlp_head</span><span class="p">:</span>
<span class="linenos" data-linenos="30 "></span>            <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">Mlp</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">embed_dim</span> <span class="o">*</span> <span class="n">mlp_ratio</span><span class="p">),</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="linenos" data-linenos="31 "></span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos" data-linenos="32 "></span>            <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
<span class="linenos" data-linenos="33 "></span>
<span class="linenos" data-linenos="34 "></span>        <span class="c1"># 初始化权重</span>
<span class="linenos" data-linenos="35 "></span>        <span class="n">trunc_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">.02</span><span class="p">)</span>
<span class="linenos" data-linenos="36 "></span>        <span class="n">trunc_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">.02</span><span class="p">)</span>
<span class="linenos" data-linenos="37 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_weights</span><span class="p">)</span>
<span class="linenos" data-linenos="38 "></span>
<span class="linenos" data-linenos="39 "></span>        <span class="c1"># 辅助操作</span>
<span class="linenos" data-linenos="40 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">IndexSelect</span><span class="p">()</span>
<span class="linenos" data-linenos="41 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">add</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()</span>
<span class="linenos" data-linenos="42 "></span>
<span class="linenos" data-linenos="43 "></span>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="linenos" data-linenos="44 "></span>        <span class="n">B</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos" data-linenos="45 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embed</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="46 "></span>
<span class="linenos" data-linenos="47 "></span>        <span class="c1"># 扩展类标记和合并类标记和补丁嵌入</span>
<span class="linenos" data-linenos="48 "></span>        <span class="n">cls_tokens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_token</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos" data-linenos="49 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cls_tokens</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos" data-linenos="50 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span><span class="p">])</span>
<span class="linenos" data-linenos="51 "></span>
<span class="linenos" data-linenos="52 "></span>        <span class="c1"># 应用 Transformer 编码块</span>
<span class="linenos" data-linenos="53 "></span>        <span class="k">for</span> <span class="n">blk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
<span class="linenos" data-linenos="54 "></span>            <span class="n">x</span> <span class="o">=</span> <span class="n">blk</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="55 "></span>
<span class="linenos" data-linenos="56 "></span>        <span class="c1"># 应用层归一化和池化操作，然后通过分类头输出最终结果</span>
<span class="linenos" data-linenos="57 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="58 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
<span class="linenos" data-linenos="59 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos" data-linenos="60 "></span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos="61 "></span>        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">def</span> <span class="nf">relprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cam</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;transformer_attribution&quot;</span><span class="p">,</span> <span class="n">is_ablation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">start_layer</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="c1"># 基础的相关性传播，从分类头开始反向传播</span>
<span class="linenos" data-linenos=" 3 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 4 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span>    <span class="c1"># 反向通过所有 Transformer 编码块</span>
<span class="linenos" data-linenos=" 9 "></span>    <span class="k">for</span> <span class="n">blk</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">):</span>
<span class="linenos" data-linenos="10 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span>    <span class="c1"># 根据不同的方法参数，执行不同的相关性传播分析策略</span>
<span class="linenos" data-linenos="13 "></span>    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
<span class="linenos" data-linenos="14 "></span>        <span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="15 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="linenos" data-linenos="16 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patch_embed</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="17 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 在通道维度上求和</span>
<span class="linenos" data-linenos="18 "></span>        <span class="k">return</span> <span class="n">cam</span>
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span>    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;rollout&quot;</span><span class="p">:</span>
<span class="linenos" data-linenos="21 "></span>        <span class="c1"># 计算所有编码块的平均注意力权重，用于产生整体的注意力“rollout”图</span>
<span class="linenos" data-linenos="22 "></span>        <span class="n">attn_cams</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos" data-linenos="23 "></span>        <span class="k">for</span> <span class="n">blk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
<span class="linenos" data-linenos="24 "></span>            <span class="n">attn_heads</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">get_attn_cam</span><span class="p">()</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="linenos" data-linenos="25 "></span>            <span class="n">avg_heads</span> <span class="o">=</span> <span class="p">(</span><span class="n">attn_heads</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">attn_heads</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="linenos" data-linenos="26 "></span>            <span class="n">attn_cams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_heads</span><span class="p">)</span>
<span class="linenos" data-linenos="27 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">compute_rollout_attention</span><span class="p">(</span><span class="n">attn_cams</span><span class="p">,</span> <span class="n">start_layer</span><span class="o">=</span><span class="n">start_layer</span><span class="p">)</span>
<span class="linenos" data-linenos="28 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="linenos" data-linenos="29 "></span>        <span class="k">return</span> <span class="n">cam</span>
<span class="linenos" data-linenos="30 "></span>
<span class="linenos" data-linenos="31 "></span>    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;transformer_attribution&quot;</span> <span class="ow">or</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;grad&quot;</span><span class="p">:</span>
<span class="linenos" data-linenos="32 "></span>        <span class="c1"># 使用 Transformer 编码块的梯度和注意力权重计算最终的贡献图</span>
<span class="linenos" data-linenos="33 "></span>        <span class="n">cams</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos" data-linenos="34 "></span>        <span class="k">for</span> <span class="n">blk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">:</span>
<span class="linenos" data-linenos="35 "></span>            <span class="n">grad</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">get_attn_gradients</span><span class="p">()</span>
<span class="linenos" data-linenos="36 "></span>            <span class="n">cam</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">get_attn_cam</span><span class="p">()</span>
<span class="linenos" data-linenos="37 "></span>            <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cam</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">cam</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="linenos" data-linenos="38 "></span>            <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">grad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">grad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="linenos" data-linenos="39 "></span>            <span class="n">cam</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">*</span> <span class="n">cam</span>
<span class="linenos" data-linenos="40 "></span>            <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="linenos" data-linenos="41 "></span>            <span class="n">cams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cam</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="linenos" data-linenos="42 "></span>        <span class="n">rollout</span> <span class="o">=</span> <span class="n">compute_rollout_attention</span><span class="p">(</span><span class="n">cams</span><span class="p">,</span> <span class="n">start_layer</span><span class="o">=</span><span class="n">start_layer</span><span class="p">)</span>
<span class="linenos" data-linenos="43 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">rollout</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="linenos" data-linenos="44 "></span>        <span class="k">return</span> <span class="n">cam</span>
<span class="linenos" data-linenos="45 "></span>
<span class="linenos" data-linenos="46 "></span>    <span class="c1"># 分析特定层的注意力权重，可以选定最后一层或第二层</span>
<span class="linenos" data-linenos="47 "></span>    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;last_layer&quot;</span><span class="p">:</span>
<span class="linenos" data-linenos="48 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">get_attn_cam</span><span class="p">()</span>
<span class="linenos" data-linenos="49 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">cam</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">cam</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="linenos" data-linenos="50 "></span>        <span class="k">if</span> <span class="n">is_ablation</span><span class="p">:</span>
<span class="linenos" data-linenos="51 "></span>            <span class="n">grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">get_attn_gradients</span><span class="p">()</span>
<span class="linenos" data-linenos="52 "></span>            <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">grad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">grad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="linenos" data-linenos="53 "></span>            <span class="n">cam</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">*</span> <span class="n">cam</span>
<span class="linenos" data-linenos="54 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="linenos" data-linenos="55 "></span>        <span class="n">cam</span> <span class="o">=</span> <span class="n">cam</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span>
<span class="linenos" data-linenos="56 "></span>        <span class="k">return</span> <span class="n">cam</span>
</code></pre></div>
<p>书接上文，在定义了 <code>vit_LRP</code> 之后，定义了函数 <code>generate_visualization</code></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">def</span> <span class="nf">generate_visualization</span><span class="p">(</span><span class="n">original_image</span><span class="p">,</span> <span class="n">class_index</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="linenos" data-linenos="2 "></span>    <span class="c1"># 生成指定类索引的LRP属性图</span>
<span class="linenos" data-linenos="3 "></span>    <span class="n">transformer_attribution</span> <span class="o">=</span> <span class="n">attribution_generator</span><span class="o">.</span><span class="n">generate_LRP</span><span class="p">(</span><span class="n">original_image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;transformer_attribution&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">class_index</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">class</span> <span class="nc">LRP</span><span class="p">:</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="linenos" data-linenos=" 3 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
<span class="linenos" data-linenos=" 4 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># 将模型设置为评估模式</span>
<span class="linenos" data-linenos=" 5 "></span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="k">def</span> <span class="nf">generate_LRP</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;transformer_attribution&quot;</span><span class="p">,</span> <span class="n">is_ablation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">start_layer</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="linenos" data-linenos=" 7 "></span>        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>  <span class="c1"># 获得模型的输出</span>
<span class="linenos" data-linenos=" 8 "></span>        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>  <span class="c1"># 设置LRP方法的额外参数</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>        <span class="c1"># 如果没有指定index，则自动选择输出概率最大的类别</span>
<span class="linenos" data-linenos="11 "></span>        <span class="k">if</span> <span class="n">index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos" data-linenos="12 "></span>            <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="linenos" data-linenos="13 "></span>
<span class="linenos" data-linenos="14 "></span>        <span class="c1"># 创建一个one-hot编码的向量，用于指定感兴趣的输出类别</span>
<span class="linenos" data-linenos="15 "></span>        <span class="n">one_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="linenos" data-linenos="16 "></span>        <span class="n">one_hot</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="linenos" data-linenos="17 "></span>        <span class="n">one_hot_vector</span> <span class="o">=</span> <span class="n">one_hot</span>
<span class="linenos" data-linenos="18 "></span>        <span class="n">one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">one_hot</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos" data-linenos="19 "></span>        <span class="n">one_hot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">one_hot</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> <span class="o">*</span> <span class="n">output</span><span class="p">)</span>  <span class="c1"># 乘以模型的输出并求和，为反向传播准备</span>
<span class="linenos" data-linenos="20 "></span>
<span class="linenos" data-linenos="21 "></span>        <span class="c1"># 清除之前的梯度并进行反向传播</span>
<span class="linenos" data-linenos="22 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="linenos" data-linenos="23 "></span>        <span class="n">one_hot</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos" data-linenos="24 "></span>
<span class="linenos" data-linenos="25 "></span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">one_hot_vector</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">is_ablation</span><span class="o">=</span><span class="n">is_ablation</span><span class="p">,</span>
<span class="linenos" data-linenos="26 "></span>                                  <span class="n">start_layer</span><span class="o">=</span><span class="n">start_layer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>主要是这几点</p>
<ul>
<li><strong>One-hot 编码</strong>：创建一个 one-hot 编码的向量，标记目标类别的位置。</li>
<li><strong>梯度计算</strong>：将 one-hot 编码的结果与模型输出相乘并求和，以便在这个点上计算梯度。</li>
<li><strong>反向传播</strong>：对得到的结果执行反向传播，计算每个输入对输出类别的影响</li>
</ul>
<p>这样，我们就获得了最终的注意力分数，然后是对注意力分数以及图像的处理</p>
<p><div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="c1"># 将属性图的形状调整为 1x1x14x14，准备进行上采样</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="n">transformer_attribution</span> <span class="o">=</span> <span class="n">transformer_attribution</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">)</span>
<span class="linenos" data-linenos=" 3 "></span>    <span class="c1"># 使用双线性插值将属性图的尺寸上采样到原始图像的尺寸，这里假设原始图像尺寸为224x224</span>
<span class="linenos" data-linenos=" 4 "></span>    <span class="n">transformer_attribution</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">transformer_attribution</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>
<span class="linenos" data-linenos=" 5 "></span>    <span class="c1"># 调整属性图的形状到224x224，并将其移动到CPU内存中，转换为NumPy数组</span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="n">transformer_attribution</span> <span class="o">=</span> <span class="n">transformer_attribution</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="linenos" data-linenos=" 7 "></span>    <span class="c1"># 对属性图进行归一化处理，将其值归一化到0和1之间，以便更好地可视化</span>
<span class="linenos" data-linenos=" 8 "></span>    <span class="n">transformer_attribution</span> <span class="o">=</span> <span class="p">(</span><span class="n">transformer_attribution</span> <span class="o">-</span> <span class="n">transformer_attribution</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">transformer_attribution</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">transformer_attribution</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>    <span class="c1"># 将原始图像的维度从CxHxW转换为HxWxC，然后转换为NumPy数组</span>
<span class="linenos" data-linenos="11 "></span>    <span class="n">image_transformer_attribution</span> <span class="o">=</span> <span class="n">original_image</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="linenos" data-linenos="12 "></span>    <span class="c1"># 对原始图像也进行归一化处理，将其值归一化到0和1之间</span>
<span class="linenos" data-linenos="13 "></span>    <span class="n">image_transformer_attribution</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_transformer_attribution</span> <span class="o">-</span> <span class="n">image_transformer_attribution</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">image_transformer_attribution</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">image_transformer_attribution</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span>    <span class="c1"># 使用热图叠加函数将属性图覆盖在原始图像上，生成最终的可视化效果</span>
<span class="linenos" data-linenos="16 "></span>    <span class="n">vis</span> <span class="o">=</span> <span class="n">show_cam_on_image</span><span class="p">(</span><span class="n">image_transformer_attribution</span><span class="p">,</span> <span class="n">transformer_attribution</span><span class="p">)</span>
<span class="linenos" data-linenos="17 "></span>    <span class="c1"># 将最终的可视化结果转换为0-255的RGB格式，适合保存或显示</span>
<span class="linenos" data-linenos="18 "></span>    <span class="n">vis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="mi">255</span> <span class="o">*</span> <span class="n">vis</span><span class="p">)</span>
<span class="linenos" data-linenos="19 "></span>    <span class="c1"># 将图像从RGB格式转换为OpenCV使用的BGR格式</span>
<span class="linenos" data-linenos="20 "></span>    <span class="n">vis</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vis</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">)</span>
<span class="linenos" data-linenos="21 "></span>
<span class="linenos" data-linenos="22 "></span>    <span class="c1"># 返回最终的可视化图像</span>
<span class="linenos" data-linenos="23 "></span>    <span class="k">return</span> <span class="n">vis</span>
</code></pre></div>
这个方法的在整体的构建上是和 ViT 的模型构建一起建立的，众所周知，在建立 ViT 模型时，一般会分成下面几个模块来分别定义</p>
<ol>
<li>分类投影器</li>
</ol>
<p><div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">class</span> <span class="nc">Mlp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
</code></pre></div>
2. 注意力模块</p>
<p><div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
</code></pre></div>
3. 组装模块</p>
<p><div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">class</span> <span class="nc">Block</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
</code></pre></div>
4. 图像编码模块</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">class</span> <span class="nc">PatchEmbed</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
</code></pre></div>
<p>最后整合成完整的 ViT</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span><span class="k">class</span> <span class="nc">VisionTransforme</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
</code></pre></div>
<p>因此在进行相关性传播时也是如此，以 <code>Attention</code> 模块为例，首先定义了在前向传播和反向传播中的 hook</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">def</span> <span class="nf">forward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
<span class="linenos" data-linenos=" 3 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos" data-linenos=" 4 "></span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
<span class="linenos" data-linenos=" 5 "></span>            <span class="n">x</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="linenos" data-linenos=" 6 "></span>            <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="linenos" data-linenos=" 7 "></span>            <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos" data-linenos=" 9 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="linenos" data-linenos="10 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">output</span>
<span class="linenos" data-linenos="13 "></span>
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span><span class="k">def</span> <span class="nf">backward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
<span class="linenos" data-linenos="16 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">grad_input</span> <span class="o">=</span> <span class="n">grad_input</span>
<span class="linenos" data-linenos="17 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">grad_output</span> <span class="o">=</span> <span class="n">grad_output</span>
<span class="linenos" data-linenos="18 "></span>
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span><span class="k">class</span> <span class="nc">RelProp</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="linenos" data-linenos="21 "></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="linenos" data-linenos="22 "></span>        <span class="nb">super</span><span class="p">(</span><span class="n">RelProp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos" data-linenos="23 "></span>        <span class="c1"># if not self.training:</span>
<span class="linenos" data-linenos="24 "></span>        <span class="bp">self</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="n">forward_hook</span><span class="p">)</span>
<span class="linenos" data-linenos="25 "></span>
<span class="linenos" data-linenos="26 "></span>    <span class="k">def</span> <span class="nf">gradprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
<span class="linenos" data-linenos="27 "></span>        <span class="n">C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="linenos" data-linenos="28 "></span>        <span class="k">return</span> <span class="n">C</span>
<span class="linenos" data-linenos="29 "></span>
<span class="linenos" data-linenos="30 "></span>    <span class="k">def</span> <span class="nf">relprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="linenos" data-linenos="31 "></span>        <span class="k">return</span> <span class="n">R</span>
</code></pre></div>
<p>接着在每个模块中都重载这个函数，使得相关性传播同样会随着网络深度的加深而加深</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span><span class="k">def</span> <span class="nf">relprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="linenos" data-linenos=" 2 "></span>    <span class="c1"># 通过投影下降层传播相关性</span>
<span class="linenos" data-linenos=" 3 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj_drop</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 4 "></span>    <span class="c1"># 通过投影层传播相关性</span>
<span class="linenos" data-linenos=" 5 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos=" 6 "></span>    <span class="c1"># 重新排列 cam 张量，从 (batch, num_patches, num_heads*depth) 格式变为 (batch, heads, num_patches, depth)</span>
<span class="linenos" data-linenos=" 7 "></span>    <span class="n">cam</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="s1">&#39;b n (h d) -&gt; b h n d&#39;</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<span class="linenos" data-linenos=" 8 "></span>    <span class="c1"># attn = A*V，计算注意力得分与值的相关性</span>
<span class="linenos" data-linenos=" 9 "></span>    <span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="n">cam_v</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul2</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="10 "></span>    <span class="n">cam1</span> <span class="o">/=</span> <span class="mi">2</span>  <span class="c1"># 将 cam1 的相关性除以 2</span>
<span class="linenos" data-linenos="11 "></span>    <span class="n">cam_v</span> <span class="o">/=</span> <span class="mi">2</span>  <span class="c1"># 将 cam_v 的相关性除以 2</span>
<span class="linenos" data-linenos="12 "></span>    <span class="c1"># 存储 V 和注意力得分的相关性图</span>
<span class="linenos" data-linenos="13 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">save_v_cam</span><span class="p">(</span><span class="n">cam_v</span><span class="p">)</span>
<span class="linenos" data-linenos="14 "></span>    <span class="bp">self</span><span class="o">.</span><span class="n">save_attn_cam</span><span class="p">(</span><span class="n">cam1</span><span class="p">)</span>
<span class="linenos" data-linenos="15 "></span>    <span class="c1"># 通过注意力下降层进一步传播 cam1 的相关性</span>
<span class="linenos" data-linenos="16 "></span>    <span class="n">cam1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_drop</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="17 "></span>    <span class="c1"># 通过 softmax 层传播相关性</span>
<span class="linenos" data-linenos="18 "></span>    <span class="n">cam1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="19 "></span>    <span class="c1"># A = Q*K^T，计算查询和键的相关性</span>
<span class="linenos" data-linenos="20 "></span>    <span class="p">(</span><span class="n">cam_q</span><span class="p">,</span> <span class="n">cam_k</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">matmul1</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="linenos" data-linenos="21 "></span>    <span class="n">cam_q</span> <span class="o">/=</span> <span class="mi">2</span>  <span class="c1"># 将 cam_q 的相关性除以 2</span>
<span class="linenos" data-linenos="22 "></span>    <span class="n">cam_k</span> <span class="o">/=</span> <span class="mi">2</span>  <span class="c1"># 将 cam_k 的相关性除以 2</span>
<span class="linenos" data-linenos="23 "></span>    <span class="c1"># 将查询、键和值的相关性图重新排列为原始的 QKV 格式</span>
<span class="linenos" data-linenos="24 "></span>    <span class="n">cam_qkv</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">([</span><span class="n">cam_q</span><span class="p">,</span> <span class="n">cam_k</span><span class="p">,</span> <span class="n">cam_v</span><span class="p">],</span> <span class="s1">&#39;qkv b h n d -&gt; b n (qkv h d)&#39;</span><span class="p">,</span> <span class="n">qkv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
<span class="linenos" data-linenos="25 "></span>    <span class="c1"># 返回通过 QKV 层传播的相关性</span>
<span class="linenos" data-linenos="26 "></span>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">qkv</span><span class="o">.</span><span class="n">relprop</span><span class="p">(</span><span class="n">cam_qkv</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>









  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../Visualization%20Work%20Flow/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Visualization Work Flow">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Visualization Work Flow
              </div>
            </div>
          </a>
        
        
          
          <a href="../Autograd%20mechanics%20%E2%80%94%20PyTorch%202_3%20documentation/" class="md-footer__link md-footer__link--next" aria-label="Next: Autograd mechanics — PyTorch 2 3 documentation">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Autograd mechanics — PyTorch 2 3 documentation
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tooltips", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "header.autohide"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.525ec568.min.js"></script>
      
        <script src="../mathjax-config.js"></script>
      
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
        <script src="../extra.js"></script>
      
        <script src="../js/toggle_sidebar.js"></script>
      
    
  </body>
</html>