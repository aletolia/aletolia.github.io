
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://localhost:8000/Vision%20Transformer%20%28%E4%B8%80%29/">
      
      
        <link rel="prev" href="../Self-Supervised%20Learning%20MoCoV2%2C3/">
      
      
        <link rel="next" href="../Vision%20Transformer%20%20%28%E4%BA%8C%29/">
      
      
      <link rel="icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.39">
    
    
      
        <title>Vision Transformer  (一) - One Last Kiss</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8c3ca2c6.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../extra.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-M0R7V8QGQ7"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-M0R7V8QGQ7",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-M0R7V8QGQ7",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="One Last Kiss" class="md-header__button md-logo" aria-label="One Last Kiss" data-md-component="logo">
      
  <img src="../img/icon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            One Last Kiss
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Vision Transformer  (一)
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/aletolia/aletolia.github.io.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    aletolia/aletolia.github.io
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href=".." class="md-tabs__link">
          
  
    
  
  🏠 Home

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../Mygo/" class="md-tabs__link">
          
  
    
  
  ⛏️ CV and Multimodels

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../Session%201/" class="md-tabs__link">
          
  
    
  
  🚀 Re:0 Road to CPath & Visualization

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../1.1%20Single-cell%20RNA%20sequencing/" class="md-tabs__link">
          
  
    
  
  💤 Re:0 Road to scRNA-seq Analysis

        </a>
      </li>
    
  

    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../Large-scale%20foundation%20model%20on%20single-cell%20transcriptomics/" class="md-tabs__link">
          
  
    
  
  🧬 scRNA Analysis

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../%E7%AC%AC%201%20%E7%AB%A0%20python%20%E5%85%A5%E9%97%A8/" class="md-tabs__link">
          
  
    
  
  📐 Data Structures

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../Best%20practices%20for%20single-cell%20analysis%20across%20modalities/" class="md-tabs__link">
          
  
    
  
  💡 Reviews

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="One Last Kiss" class="md-nav__button md-logo" aria-label="One Last Kiss" data-md-component="logo">
      
  <img src="../img/icon.png" alt="logo">

    </a>
    One Last Kiss
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/aletolia/aletolia.github.io.git" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    aletolia/aletolia.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href=".." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    🏠 Home
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            🏠 Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    ⛏️ CV and Multimodels
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            ⛏️ CV and Multimodels
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Mygo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MyGO: Discrete Modality Information as Fine-Grained Tokens for Multi-modal Knowledge Graph Completion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GMM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GMM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DINO/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DINO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Mamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Mamba
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ViT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ViT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Self-Supervised%20Learning%20MoCo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MoCo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Self-Supervised%20Learning%20MoCoV2%2C3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MoCo V2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Vision Transformer  (一)
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Vision Transformer  (一)
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      目录
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      1 一切从 Self-attention 开始
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      2 Transformer 的实现和代码解读
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 Transformer 的实现和代码解读">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#3-transformerdetection-detr" class="md-nav__link">
    <span class="md-ellipsis">
      3 Transformer+Detection：引入视觉领域的首创 DETR
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      总结：
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      参考文献：
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%20%28%E4%BA%8C%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer (二)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%28%E4%B8%89%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer  (三)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%28%E5%9B%9B%29%20%28TNT%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer (四)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%28%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%20%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer (知识蒸馏 预训练）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Transformer%20%28PyramidTNT%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Transformer(Pyramid TNT)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0%E5%92%8C%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E4%B8%93%E9%A2%98/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    傅里叶级数和傅里叶变换专题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Python%20%E5%AD%98%E5%82%A8%E4%B8%8E%E8%AF%BB%E5%8F%96%20HDF5%20%E6%96%87%E4%BB%B6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python 存储与读取 HDF5 文件
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Segment%20Anything%20in%20Medical%20Images/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Segment Anything in Medical Images
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Vision%20Mamba%20Efficient%20Visual%20Representation%20Learning%20with%20Bidirectional%20State%20Space%20Model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vision Mamba Efficient Visual Representation Learning with Bidirectional State Space Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_18" >
        
          
          <label class="md-nav__link" for="__nav_2_18" id="__nav_2_18_label" tabindex="">
            
  
  <span class="md-ellipsis">
    🚑 医学影像相关
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_18">
            <span class="md-nav__icon md-icon"></span>
            🚑 医学影像相关
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Why%20is%20the%20winner%20the%20best/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Why is the winner the best
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PORPOISE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PORPOISE
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../HIPT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scaling Vision Transformers to Gigapixel Images via Hierarchical Self-Supervised Learning(HIPT)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Data-efficient%20and%20weakly%20supervised%20computational%20pathology%20on%20whole-slide%20images%28CLAM%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data efficient and weakly supervised computational pathology on whole slide images(CLAM)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Towards%20a%20general-purpose%20foundation%20model%20for%20computational%20pathology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Towards a general purpose foundation model for computational pathology
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20whole-slide%20foundation%20model%20for%20digital%20pathology%20from%20real-world%20data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A whole slide foundation model for digital pathology from real world data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20visual-language%20foundation%20model%20for%20computational%20pathology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A visual language foundation model for computational pathology
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Recurrent%20memory%20with%20optimal%20polynomial%20projections./" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recurrent memory with optimal polynomial projections.
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Modeling%20Dense%20Multimodal%20Interactions%20Between%20Biological%20Pathways%20and%20Histology%20for%20Survival%20Prediction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Inferring%20super-resolution%20tissue%20architecture%20by%20integrating%20spatial%20transcriptomics%20with%20histology/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inferring super resolution tissue architecture by integrating spatial transcriptomics with histology
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Prediction%20of%20recurrence%20risk%20in%20endometrial%20cancer%20with%20multimodal%20deep%20learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prediction of recurrence risk in endometrial cancer with multimodal deep learning
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🚀 Re:0 Road to CPath & Visualization
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            🚀 Re:0 Road to CPath & Visualization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Session%201/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    理解全幅切片图像
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Session%202/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在计算病理学中用于癌症诊断的弱监督深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Session%203/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于注意力的多示例学习可解释性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../How%20to%20visualize%20Attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to visualize Attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AttentionViz%20A%20Global%20View%20of%20Transformer%20Attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AttentionViz A Global View of Transformer Attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Transformer%20Interpretability%20Beyond%20Attention%20Visualization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer Interpretability Beyond Attention Visualization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Visualization%20Work%20Flow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualization Work Flow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Attention%20Generation%20Work%20Flow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Attention Generation Work Flow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_9" >
        
          
          <label class="md-nav__link" for="__nav_3_9" id="__nav_3_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🪛 PyTorch
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_9">
            <span class="md-nav__icon md-icon"></span>
            🪛 PyTorch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Autograd%20mechanics%20%E2%80%94%20PyTorch%202_3%20documentation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Autograd mechanics — PyTorch 2 3 documentation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PyTorch%20Autograd%20Explained%20-%20In-depth%20Tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch Autograd Explained   In depth Tutorial
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    💤 Re:0 Road to scRNA-seq Analysis
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            💤 Re:0 Road to scRNA-seq Analysis
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Using Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Using Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1_1" id="__nav_4_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ⏳ CHAPTER 1 简介
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_1">
            <span class="md-nav__icon md-icon"></span>
            ⏳ CHAPTER 1 简介
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.1%20Single-cell%20RNA%20sequencing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1.The building block of life
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.2%20Raw%20Data%20Processing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 Raw data processing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.3%20Analysis%20frameworks%20and%20tools/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.3 Analysis frameworks and tools
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_2" >
        
          
          <label class="md-nav__link" for="__nav_4_1_2" id="__nav_4_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🌏 CHAPTER 2 数据准备与可视化
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_2">
            <span class="md-nav__icon md-icon"></span>
            🌏 CHAPTER 2 数据准备与可视化
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.1%20quality_control/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.1 Quality Control
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.2%20normalization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.2 Normalization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.3_feature_selection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.3 Feature selection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.4_dimensionality_reduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.4 Dimensionality Reduction
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_3" >
        
          
          <label class="md-nav__link" for="__nav_4_1_3" id="__nav_4_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🍀 CHAPTER 3 识别细胞结构
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_3">
            <span class="md-nav__icon md-icon"></span>
            🍀 CHAPTER 3 识别细胞结构
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.1clustering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 Clustering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.2annotation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 Annotation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.3integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 Data integration
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_4" >
        
          
          <label class="md-nav__link" for="__nav_4_1_4" id="__nav_4_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ⏱️ CHAPTER 4 推断细胞轨迹
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_4">
            <span class="md-nav__icon md-icon"></span>
            ⏱️ CHAPTER 4 推断细胞轨迹
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pseudotemporal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 Pseudotemporal ordering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rna_velocity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 RNA velocity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lineage_tracing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.3 Lineage tracing
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_5" >
        
          
          <label class="md-nav__link" for="__nav_4_1_5" id="__nav_4_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🎁 CHAPTER 5 应对特殊情况
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_5">
            <span class="md-nav__icon md-icon"></span>
            🎁 CHAPTER 5 应对特殊情况
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../differential_gene_expression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 Differential gene expression analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../compositional/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.2 Compositional analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gsea_pathway/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.3 Gene set enrichment and pathway analysis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../perturbation_modeling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.4 Perturbation modeling
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_6" >
        
          
          <label class="md-nav__link" for="__nav_4_1_6" id="__nav_4_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    ⚙️ CHAPTER 6 机制建模
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_6">
            <span class="md-nav__icon md-icon"></span>
            ⚙️ CHAPTER 6 机制建模
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gene_regulatory_networks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 Gene regulatory networks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cell_cell_communication/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 Cell-cell communication
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_1_7" >
        
          
          <label class="md-nav__link" for="__nav_4_1_7" id="__nav_4_1_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🔓 CHAPTER 7 反卷积
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_1_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1_7">
            <span class="md-nav__icon md-icon"></span>
            🔓 CHAPTER 7 反卷积
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bulk_deconvolution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.1 Bulk deconvolution
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    简明易懂的单细胞分析流程（使用 R 语言）
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            简明易懂的单细胞分析流程（使用 R 语言）
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%89%8D%E8%A8%80/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前言
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    环境配置
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.1%20%E6%9E%84%E5%BB%BA%E5%8D%95%E7%BB%86%E8%83%9E%20RNA-seq%20%E5%88%86%E6%9E%90%E7%8E%AF%E5%A2%83/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1 构建单细胞 RNA seq 分析环境
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.2%20R%20%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 R 环境安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.3%20Docker%20%E5%AE%89%E8%A3%85/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.3 Docker 安装
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.4%20%E5%9C%A8%20Docker%20%E4%B8%AD%E5%90%AF%E5%8A%A8%20Rstudio/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.4 在 Docker 中启动 Rstudio
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1.5%20%E6%9C%89%E5%85%B3%20Bioconductor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.5 有关 Bioconductor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.1%20R%20%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.1 R 的基本用法
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.2%20%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%20DataFrame%EF%BC%9F/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.2 如何处理 DataFrame？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2.3%20%E4%BD%BF%E7%94%A8%20ggplot2%20%E5%8F%AF%E8%A7%86%E5%8C%96%E6%95%B0%E6%8D%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.3 使用 ggplot2 可视化数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.1%20PCA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 PCA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.2%20%E4%BD%BF%E7%94%A8%20clusterPlofiler%20%E8%BF%9B%E8%A1%8C%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 使用 clusterPlofiler 进行富集分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.3%20%E5%9F%BA%E5%9B%A0%E6%9C%AC%E4%BD%93%EF%BC%88GO%EF%BC%89%E4%B8%AD%E5%90%84%20BP%E3%80%81MF%20%E5%92%8C%20CC%20%E7%9A%84%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 基因本体（GO）中各 BP、MF 和 CC 的富集分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.3%20%E4%BD%BF%E7%94%A8%20DEseq2%20%E6%8F%90%E5%8F%96%20RNA-seq%20%E5%88%86%E6%9E%90%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%20DEG/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 使用 DEseq2 提取 RNA seq 分析数据中的 DEG
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3.4%20%E4%BD%BF%E7%94%A8%E5%85%B6%E4%BB%96%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%88KEGG%E3%80%81Reactome%20%E7%AD%89%EF%BC%89%E8%BF%9B%E8%A1%8C%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.4 使用其他数据库（KEGG、Reactome 等）进行富集分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.1%20scRNA-seq%20%E6%A6%82%E8%A6%81/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 scRNA seq 概要
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.2%20%E5%87%86%E5%A4%87%E4%BD%BF%E7%94%A8%20Seurat%20%E8%BF%9B%E8%A1%8C%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 准备使用 Seurat 进行分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.3%20%E4%BD%BF%E7%94%A8%20Seurat%20%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.3 使用 Seurat 进行数据预处理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4.4%20%E4%BD%BF%E7%94%A8%20Seurat%20%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%9A%84%E4%B8%80%E8%88%AC%E9%A1%BA%E5%BA%8F/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.4 使用 Seurat 进行数据分析的一般顺序
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.1%20%E5%A6%82%E4%BD%95%E6%9F%A5%E6%89%BE%E5%8D%95%E7%BB%86%E8%83%9E%20RNA-seq%20%E6%95%B0%E6%8D%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 如何查找单细胞 RNA seq 数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.2%20%E4%B8%BA%E6%AF%8F%E4%B8%AA%E7%B0%87%E8%87%AA%E5%8A%A8%E6%B7%BB%E5%8A%A0%E7%BB%86%E8%83%9E%E6%B3%A8%E9%87%8A%E6%A0%87%E7%AD%BE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.2 为每个簇自动添加细胞注释标签
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.3%20%E4%BD%BF%E7%94%A8%20FeaturePlot%20%E6%A3%80%E6%9F%A5%E5%9F%BA%E5%9B%A0%E8%A1%A8%E8%BE%BE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.3 使用 FeaturePlot 检查基因表达
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.4%20%E5%B0%86%E5%8D%95%E7%BB%86%E8%83%9E%20RNA-seq%20%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E4%BA%92%E7%BB%93%E5%90%88/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.4 将单细胞 RNA seq 数据集相互结合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.5%20%E7%BA%A0%E6%AD%A3%E6%89%B9%E6%AC%A1%E6%95%88%E5%BA%94%EF%BC%8C%E6%AF%94%E8%BE%83%E5%AF%B9%E7%85%A7%E7%BB%84%E5%92%8C%E5%88%BA%E6%BF%80%E7%BB%84/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.5 纠正批次效应，比较对照组和刺激组
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../5.6%20%E7%A1%AE%E5%AE%9A%E6%AF%8F%E4%B8%AA%E7%BE%A4%E7%BB%84%E7%9A%84%E6%A0%87%E8%AE%B0%E5%9F%BA%E5%9B%A0/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.6 确定每个群组的标记基因
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6.1%20%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%20Cell%20Ranger%20%E7%BB%9F%E8%AE%A1%20scRNA-seq%20%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%E5%9F%BA%E5%9B%A0%E8%A1%A8%E8%BE%BE%E6%B0%B4%E5%B9%B3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 如何使用 Cell Ranger 统计 scRNA seq 数据中的基因表达水平
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../6.2%20%E4%BD%BF%E7%94%A8%20Cell%20Ranger%20%E5%A4%84%E7%90%86%20NCBI%20Sequence%20Read%20Archive%20%28SRA%29%20%E6%95%B0%E6%8D%AE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 使用 Cell Ranger 处理 NCBI Sequence Read Archive (SRA) 数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7.1%20%E5%85%B3%E4%BA%8E%20scRNA-seq%20%E6%95%B0%E6%8D%AE%E7%9A%84%E8%B4%A8%E9%87%8F%E6%8E%A7%E5%88%B6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.1 关于 scRNA seq 数据的质量控制
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7.2%20%E4%BD%BF%E7%94%A8%20DoubleFinder%20%E6%A3%80%E6%B5%8B%E5%8F%8C%E9%87%8D%E7%BB%86%E8%83%9E/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.2 使用 DoubleFinder 检测双重细胞
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../7.3%20%E7%94%A8%20CellBender%20%E5%8E%BB%E9%99%A4%E8%83%8C%E6%99%AF%20RNA/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7.3 用 CellBender 去除背景 RNA
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🧬 scRNA Analysis
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            🧬 scRNA Analysis
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🐍 Using Python
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            🐍 Using Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Large-scale%20foundation%20model%20on%20single-cell%20transcriptomics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Large scale foundation model on single cell transcriptomics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scGPT%20toward%20building%20a%20foundation%20model%20for%20single-cell%20multi-omics%20using%20generative%20AI/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scGPT toward building a foundation model for single cell multi omics using generative AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scBERT%20as%20a%20large-scale%20pretrained%20deep%20language%20model%20for%20cell%20type%20annotation%20of%20single-cell%20RNA-seq%20data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scBERT as a large scale pretrained deep language model for cell type annotation of single cell RNA seq data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../RNA%20velocity%20of%20single%20cells/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RNA velocity of single cells
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../TFvelo_gene%20regulation%20inspired%20RNA%20velocity%20estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TFvelo gene regulation inspired RNA velocity estimation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Disentanglement%20of%20single-cell%20data%20with%20biolord/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Disentanglement of single cell data with biolord
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E2%AD%90%E2%AD%90%E2%AD%90C5aR1%20inhibition%20reprograms%20tumor%20associated%20macrophages%20and%20reverses%20PARP%20inhibitor%20resistance%20in%20breast%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ⭐⭐⭐C5aR1 inhibition reprograms tumor associated macrophages and reverses PARP inhibitor resistance in breast cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Spatial%20transition%20tensor%20of%20single%20cells/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Spatial transition tensor of single cells
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Statistical%20method%20scDEED%20for%20detecting%20dubious%202D%20single-cell%20embeddings%20and%20optimizing%20t-SNE%20and%20UMAP%20hyperparameters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Statistical method scDEED for detecting dubious 2D single cell embeddings and optimizing t SNE and UMAP hyperparameters
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scRank%20infers%20drug-responsive%20cell%20types%20from%20untreated%20scRNA-seq%20data%20using%20a%20target-perturbed%20gene%20regulatory%20network/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scRank infers drug responsive cell types from untreated scRNA seq data using a target perturbed gene regulatory network
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    📔 文献
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            📔 文献
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ZNF689%20deficiency%20promotes%20intratumor%20heterogeneity%20and%20immunotherapy%20resistance%20in%20triple-negative%20breast%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ZNF689 deficiency promotes intratumor heterogeneity and immunotherapy resistance in triple negative breast cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Tumour%20vasculature%20at%20single-cell%20resolution/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tumour vasculature at single-cell resolution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scRNA-seq%20of%20gastric%20tumor%20shows%20complex%20intercellular%20interaction%20with%20an%20alternative%20T%20cell%20exhaustion%20trajectory%EF%BC%88%E5%8F%82%E8%80%83%EF%BC%89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    scRNA seq of gastric tumor shows complex intercellular interaction with an alternative T cell exhaustion trajectory（参考）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20analysis%20reveals%20new%20evolutionary%20complexity%20in%20uveal%20melanoma%EF%BC%88%E5%8F%82%E8%80%83%202%EF%BC%89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell analysis reveals new evolutionary complexity in uveal melanoma（参考 2）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20characterization%20of%20macrophages%20in%20uveal%20melanoma%20uncovers%20transcriptionally%20heterogeneous%20subsets%20conferring%20poor%20prognosis%20and%20aggressive%20behavior%EF%BC%88%E8%8C%83%E4%BE%8B%201%EF%BC%89/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell characterization of macrophages in uveal melanoma uncovers transcriptionally heterogeneous subsets conferring poor prognosis and aggressive behavior（范例 1）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ScRNA-seq%20of%20gastric%20cancer%20tissues%20reveals%20differences%20in%20the%20immune%20microenvironment%20of%20primary%20tumors%20and%20metastases/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ScRNA seq of gastric cancer tissues reveals differences in the immune microenvironment of primary tumors and metastases
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Blimp-1%20and%20c-Maf%20regulate%20immune%20gene%20networks%20to%20protect%20against%20distinct%20pathways%20of%20pathobiont-induced%20colitis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Blimp 1 and c Maf regulate immune gene networks to protect against distinct pathways of pathobiont induced colitis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single%20cell%20analysis%20unveils%20B%20cell-dominated%20immune%20subtypes%20in%20HNSCC%20for%20enhanced%20prognostic%20and%20therapeutic%20stratification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell analysis unveils B cell dominated immune subtypes in HNSCC for enhanced prognostic and therapeutic stratification
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20spatial%20multi-omics%20and%20deep%20learning%20dissect%20enhancer-driven%20gene%20regulatory%20networks%20in%20liver%20zonation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell spatial multi omics and deep learning dissect enhancer driven gene regulatory networks in liver zonation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Neutrophil%20profiling%20illuminates%20anti-tumor%20antigen%20presenting%20potency/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Neutrophil profiling illuminates anti tumor antigen presenting potency
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20blueprint%20for%20tumor-infiltrating%20B%20cells%20across%20human%20cancers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A blueprint for tumor infiltrating B cells across human cancers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20transcriptomic%20analyses%20reveal%20distinct%20immune%20cell%20contributions%20to%20epithelial%20barrier%20dysfunction%20in%20checkpoint%20inhibitor%20colitis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell transcriptomic analyses reveal distinct immune cell contributions to epithelial barrier dysfunction in checkpoint inhibitor colitis
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Systematic%20dissection%20of%20tumor-normal%20single-cell%20ecosystems%20across%20a%20thousand%20tumors%20of%2030%20cancer%20types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Systematic dissection of tumor normal single cell ecosystems across a thousand tumors of 30 cancer types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../The%20aged%20tumor%20microenvironment%20limits%20T%20cell%20control%20of%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The aged tumor microenvironment limits T cell control of cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../TIM-3%2B%20CD8%20T%20cells%20with%20a%20terminally%20exhausted%20phenotype%20retain%20functional%20capacity%20in%20hematological%20malignancies/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TIM 3+ CD8 T cells with a terminally exhausted phenotype retain functional capacity in hematological malignancies
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20lactate-SREBP2%20signaling%20axis%20drives%20tolerogenic%20dendritic%20cell%20maturation%20and%20promotes%20cancer%20progression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A lactate SREBP2 signaling axis drives tolerogenic dendritic cell maturation and promotes cancer progression
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20human%20omentum-specific%20mesothelial-like%20stromal%20population%20inhibits%20adipogenesis%20through%20IGFBP2%20secretion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A human omentum specific mesothelial like stromal population inhibits adipogenesis through IGFBP2 secretion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Interferon-stimulated%20neutrophils%20as%20a%20predictor%20of%20immunotherapy%20response/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Interferon stimulated neutrophils as a predictor of immunotherapy response
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Repression%20of%20latent%20NF-%CE%BAB%20enhancers%20by%20PDX1%20regulates%20%CE%B2%20cell%20functional%20heterogeneity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Repression of latent NF κB enhancers by PDX1 regulates β cell functional heterogeneity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20systematic%20pan-cancer%20study%20on%20deep%20learning-based%20prediction%20of%20multi-omic%20biomarkers%20from%20routine%20pathology%20images/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A systematic pan cancer study on deep learning based prediction of multi omic biomarkers from routine pathology images
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20and%20spatial%20transcriptomics%20analysis%20of%20non-small%20cell%20lung%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell and spatial transcriptomics analysis of non small cell lung cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Seeing%20data%20as%20t-SNE%20and%20UMAP%20do/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Seeing data as t SNE and UMAP do
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Mapping%20the%20cellular%20biogeography%20of%20human%20bone%20marrow%20niches%20using%20single-cell%20transcriptomics%20and%20proteomic%20imaging/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Mapping the cellular biogeography of human bone marrow niches using single cell transcriptomics and proteomic imaging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Onco-fetal%20Reprogramming%20of%20Endothelial%20Cells%20Drives%20Immunosuppressive%20Macrophages%20in%20Hepatocellular%20Carcinoma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Onco fetal Reprogramming of Endothelial Cells Drives Immunosuppressive Macrophages in Hepatocellular Carcinoma
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20analysis%20of%20anti-BCMA%20CAR%20T%20cell%20therapy%20in%20patients%20with%20central%20nervous%20system%20autoimmunity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell analysis of anti BCMA CAR T cell therapy in patients with central nervous system autoimmunity
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Single-cell%20sequencing%20depicts%20tumor%20architecture%20and%20empowers%20clinical%20decision%20in%20metastatic%20conjunctival%20melanoma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single cell sequencing depicts tumor architecture and empowers clinical decision in metastatic conjunctival melanoma
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../PR-SET7%20epigenetically%20restrains%20uterine%20interferon%20response%20and%20cell%20death%20governing%20proper%20postnatal%20stromal%20development/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PR SET7 epigenetically restrains uterine interferon response and cell death governing proper postnatal stromal development
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Clonal%20associations%20between%20lymphocyte%20subsets%20and%20functional%20states%20in%20rheumatoid%20arthritis%20synovium/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Clonal associations between lymphocyte subsets and functional states in rheumatoid arthritis synovium
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    📐 Data Structures
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            📐 Data Structures
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%201%20%E7%AB%A0%20python%20%E5%85%A5%E9%97%A8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 1 章 python 入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%202%20%E7%AB%A0%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 2 章 面向对象编程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%203%20%E7%AB%A0%20%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 3 章 算法分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%204%20%E7%AB%A0%20%E9%80%92%E5%BD%92/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 4 章 递归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%205%20%E7%AB%A0%20%E5%9F%BA%E4%BA%8E%E6%95%B0%E7%BB%84%E7%9A%84%E5%BA%8F%E5%88%97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 5 章 基于数组的序列
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%206%20%E7%AB%A0%20%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E5%8F%8C%E7%AB%AF%E9%98%9F%E5%88%97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 6 章 栈、队列和双端队列
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%207%20%E7%AB%A0%20%E9%93%BE%E8%A1%A8%28Linked%20Lists%29/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 7 章 链表(Linked Lists)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%208%20%E7%AB%A0%20%E6%A0%91%20%E2%98%85/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 8 章 树 ★
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%AC%AC%209%20%E7%AB%A0%20%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第 9 章 优先级队列
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    💡 Reviews
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            💡 Reviews
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_1" >
        
          
          <label class="md-nav__link" for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🧭 scRNA analysis
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            🧭 scRNA analysis
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Best%20practices%20for%20single-cell%20analysis%20across%20modalities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Best practices for single cell analysis across modalities
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Multi-omics%20integration%20in%20biomedical%20research%20%E2%80%93%20A%20metabolomics-centric%20review/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multi omics integration in biomedical research – A metabolomics centric review
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Museum%20of%20spatial%20transcriptomics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Museum of spatial transcriptomics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20guide%20to%20artificial%20intelligence%20for%20cancer%20researchers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    A guide to artificial intelligence for cancer researchers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_2" >
        
          
          <label class="md-nav__link" for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    🦠 Metabolism
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            🦠 Metabolism
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Metabolic%20analysis%20as%20a%20driver%20for%20discovery%2C%20diagnosis%2C%20and%20therapy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metabolic analysis as a driver for discovery, diagnosis, and therapy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Metabolic%20heterogeneity%20in%20cancer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metabolic heterogeneity in cancer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Toward%20modeling%20metabolic%20state%20from%20single-cell%20transcriptomics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Toward modeling metabolic state from single cell transcriptomics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Metabolic%20reprogramming%20and%20cancer%20progression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metabolic reprogramming and cancer progression
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_3" >
        
          
          <label class="md-nav__link" for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Protein
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_3">
            <span class="md-nav__icon md-icon"></span>
            Protein
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Proteomic%20and%20interactomic%20insights%20into%20the%20molecular%20basis%20of%20cell%20functional%20diversity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Proteomic and interactomic insights into the molecular basis of cell functional diversity
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      目录
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      1 一切从 Self-attention 开始
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-transformer" class="md-nav__link">
    <span class="md-ellipsis">
      2 Transformer 的实现和代码解读
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2 Transformer 的实现和代码解读">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#3-transformerdetection-detr" class="md-nav__link">
    <span class="md-ellipsis">
      3 Transformer+Detection：引入视觉领域的首创 DETR
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      总结：
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      参考文献：
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/aletolia/aletolia.github.io.git/edit/master/docs/Vision Transformer (一).md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/aletolia/aletolia.github.io.git/raw/master/docs/Vision Transformer (一).md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


  <h1>Vision Transformer  (一)</h1>

<div class="admonition note">
<p class="admonition-title">Attention</p>
<p>原文地址：https://zhuanlan.zhihu.com/p/340149804</p>
</div>
<h2 id="_1">目录<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<p>Transformer 是 Google 的团队在 2017 年提出的一种 NLP 经典模型，现在比较火热的 Bert 也是基于 Transformer。Transformer 模型使用了 Self-Attention 机制，<strong>不采用</strong> RNN 的<strong>顺序结构</strong>，使得模型<strong>可以并行化训练</strong>，而且能够<strong>拥有全局信息。</strong></p>
<h2 id="1-self-attention">1 一切从 Self-attention 开始<a class="headerlink" href="#1-self-attention" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>1.1 处理 Sequence 数据的模型：</strong></li>
</ul>
<p>Transformer 是一个 Sequence to Sequence model，特别之处在于它大量用到了 self-attention。</p>
<p>要处理一个 Sequence，最常想到的就是使用 RNN，它的输入是一串 vector sequence，输出是另一串 vector sequence，如下图 1 左所示。</p>
<p>如果假设是一个 single directional 的 RNN，那当输出 <span class="arithmatex">\(b_4\)</span> 时，默认 <span class="arithmatex">\(a_1,a_2,a_3,a_4\)</span> 都已经看过了。如果假设是一个 bi-directional 的 RNN，那当输出 <span class="arithmatex">\(b_{任意}\)</span> 时，默认 <span class="arithmatex">\(a_1,a_2,a_3,a_4\)</span> 都已经看过了。RNN 非常擅长于处理 input 是一个 sequence 的状况。</p>
<p>那 RNN 有什么样的问题呢？它的问题就在于：RNN 很不容易并行化 (hard to parallel)。</p>
<p>为什么说 RNN 很不容易并行化呢？假设在 single directional 的 RNN 的情形下，你今天要算出 <span class="arithmatex">\(b_4\)</span> ，就必须要先看 <span class="arithmatex">\(a_1\)</span> 再看 <span class="arithmatex">\(a_2\)</span> 再看 <span class="arithmatex">\(a_3\)</span> 再看 <span class="arithmatex">\(a_4\)</span> ，所以这个过程很难平行处理。</p>
<p>所以今天就有人提出把 CNN 拿来取代 RNN，如下图 1 右所示。其中，橘色的三角形表示一个 filter，每次扫过 3 个向量 <span class="arithmatex">\(a\)</span> ，扫过一轮以后，就输出了一排结果，使用橘色的小圆点表示。</p>
<p>这是第一个橘色的 filter 的过程，还有其他的 filter，比如图 2 中的黄色的 filter，它经历着与橘色的 filter 相似的过程，又输出一排结果，使用黄色的小圆点表示。</p>
<p><img alt="" src="https://pic2.zhimg.com/v2-7a6a6f0977b06b3372b129a09a3ccb31_r.jpg" /></p>
<p><img alt="" src="https://pic2.zhimg.com/v2-cabda788832922a8f141542a334ccb61_r.jpg" /></p>
<p>所以，用 CNN，你确实也可以做到跟 RNN 的输入输出类似的关系，也可以做到输入是一个 sequence，输出是另外一个 sequence。</p>
<p>但是，表面上 CNN 和 RNN 可以做到相同的输入和输出，但是 CNN 只能考虑非常有限的内容。比如在我们右侧的图中 CNN 的 filter 只考虑了 3 个 vector，不像 RNN 可以考虑之前的所有 vector。但是 CNN 也不是没有办法考虑很长时间的 dependency 的，你只需要堆叠 filter，多堆叠几层，上层的 filter 就可以考虑比较多的资讯，比如，第二层的 filter (蓝色的三角形) 看了 6 个 vector，所以，只要叠很多层，就能够看很长时间的资讯。</p>
<p>而 CNN 的一个好处是：它是可以并行化的 (can parallel)，不需要等待红色的 filter 算完，再算黄色的 filter。但是必须要叠很多层 filter，才可以看到长时的资讯。所以今天有一个想法：self-attention，如下图 3 所示，目的是使用 self-attention layer 取代 RNN 所做的事情。</p>
<p><img alt="" src="https://pic2.zhimg.com/v2-e3ef96ccae817226577ee7a3c28fa16d_r.jpg" /></p>
<p><strong>所以重点是：我们有一种新的 layer，叫 self-attention，它的输入和输出和 RNN 是一模一样的，输入一个 sequence，输出一个 sequence，它的每一个输出 <span class="arithmatex">\(b_1-b_4\)</span> 都看过了整个的输入 sequence，这一点与 bi-directional RNN 相同。但是神奇的地方是：它的每一个输出 <span class="arithmatex">\(b_1-b_4\)</span> 可以并行化计算。</strong></p>
<ul>
<li><strong>1.2 Self-attention：</strong></li>
</ul>
<p><strong>那么 self-attention 具体是怎么做的呢？</strong></p>
<p><img alt="" src="https://pic3.zhimg.com/v2-8537e0996a586b7c37d5e345b6c4402a_r.jpg" /></p>
<p>首先假设我们的 input 是图 4 的 <span class="arithmatex">\(x_1-x_4\)</span> ，是一个 sequence，每一个 input (vector) 先乘上一个矩阵 <span class="arithmatex">\(W\)</span> 得到 embedding，即向量 <span class="arithmatex">\(a_1-a_4\)</span> 。接着这个 embedding 进入 self-attention 层，每一个向量 <span class="arithmatex">\(a_1-a_4\)</span> 分别乘上 3 个不同的 transformation matrix <span class="arithmatex">\(W_q,W_k,W_v\)</span> ，以向量 <span class="arithmatex">\(a_1\)</span> 为例，分别得到 3 个不同的向量 <span class="arithmatex">\(q_1,k_1,v_1\)</span> 。</p>
<p><img alt="" src="https://pic4.zhimg.com/v2-197b4f81d688e4bc40843fbe41c96787_r.jpg" /></p>
<p>接下来使用每个 query <span class="arithmatex">\(q\)</span> 去对每个 key <span class="arithmatex">\(k\)</span> 做 attention，attention 就是匹配这 2 个向量有多接近，比如我现在要对 <span class="arithmatex">\(q^1\)</span> 和 <span class="arithmatex">\(k^1\)</span> 做 attention，我就可以把这 2 个向量做 <strong>scaled inner product</strong>，得到 <span class="arithmatex">\(\alpha_{1,1}\)</span> 。接下来你再拿 <span class="arithmatex">\(q^1\)</span> 和 <span class="arithmatex">\(k^2\)</span> 做 attention，得到 <span class="arithmatex">\(\alpha_{1,2}\)</span> ，你再拿 <span class="arithmatex">\(q^1\)</span> 和 <span class="arithmatex">\(k^3\)</span> 做 attention，得到 <span class="arithmatex">\(\alpha_{1,3}\)</span> ，你再拿 <span class="arithmatex">\(q^1\)</span> 和 <span class="arithmatex">\(k^4\)</span> 做 attention，得到 <span class="arithmatex">\(\alpha_{1,4}\)</span> 。那这个 scaled inner product 具体是怎么计算的呢？</p>
<div class="arithmatex">\[\alpha_{1,i}=q^1\cdot k^i/\sqrt{d} \tag{1}\]</div>
<p>式中， <span class="arithmatex">\(d\)</span> 是 <span class="arithmatex">\(q\)</span> 跟 <span class="arithmatex">\(k\)</span> 的维度。因为 <span class="arithmatex">\(q\cdot k\)</span> 的数值会随着 dimension 的增大而增大，所以要除以 <span class="arithmatex">\(\sqrt{\text{dimension}}\)</span> 的值，相当于归一化的效果。</p>
<p>接下来要做的事如图 6 所示，把计算得到的所有 <span class="arithmatex">\(\alpha_{1,i}\)</span> 值取 <span class="arithmatex">\(\text{softmax}\)</span> 操作。</p>
<p><img alt="" src="https://pic2.zhimg.com/v2-58f7bf32a29535b57205ac2dab557be1_r.jpg" /></p>
<p>取完 <span class="arithmatex">\(\text{softmax}\)</span> 操作以后，我们得到了 <span class="arithmatex">\(\hat \alpha_{1,i}\)</span> ，我们用它和所有的 <span class="arithmatex">\(v^i\)</span> 值进行相乘。具体来讲，把 <span class="arithmatex">\(\hat \alpha_{1,1}\)</span> 乘上 <span class="arithmatex">\(v^1\)</span> ，把 <span class="arithmatex">\(\hat \alpha_{1,2}\)</span> 乘上 <span class="arithmatex">\(v^2\)</span> ，把 <span class="arithmatex">\(\hat \alpha_{1,3}\)</span> 乘上 <span class="arithmatex">\(v^3\)</span> ，把 <span class="arithmatex">\(\hat \alpha_{1,4}\)</span> 乘上 <span class="arithmatex">\(v^4\)</span> ，把结果通通加起来得到 <span class="arithmatex">\(b^1\)</span> ，所以，今天在产生 <span class="arithmatex">\(b^1\)</span> 的过程中用了整个 sequence 的资讯 (Considering the whole sequence)。如果要考虑 local 的 information，则只需要学习出相应的 <span class="arithmatex">\(\hat \alpha_{1,i}=0\)</span> ， <span class="arithmatex">\(b^1\)</span> 就不再带有那个对应分支的信息了；如果要考虑 global 的 information，则只需要学习出相应的 <span class="arithmatex">\(\hat \alpha_{1,i}\ne0\)</span> ， <span class="arithmatex">\(b^1\)</span> 就带有全部的对应分支的信息了。</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-b7e1ffade85d4dbe3350f23e6854c272_r.jpg" /></p>
<p>同样的方法，也可以计算出 <span class="arithmatex">\(b^2,b^3,b^4\)</span> ，如下图 8 所示， <span class="arithmatex">\(b^2\)</span> 就是拿 query <span class="arithmatex">\(q^2\)</span> 去对其他的 <span class="arithmatex">\(k\)</span> 做 attention，得到 <span class="arithmatex">\(\hat \alpha_{2,i}\)</span> ，再与 value 值 <span class="arithmatex">\(v^i\)</span> 相乘取 weighted sum 得到的。</p>
<p><img alt="" src="https://pic2.zhimg.com/v2-f7b03e1979c6ccd1dab4b579654c8cd5_r.jpg" /></p>
<p>经过了以上一连串计算，self-attention layer 做的事情跟 RNN 是一样的，只是它可以并行的得到 layer 输出的结果，如图 9 所示。现在我们要用矩阵表示上述的计算过程。</p>
<p><img alt="" src="https://pic2.zhimg.com/v2-67bc90b683b40488e922dcd5abcaa089_r.jpg" /></p>
<p>首先输入的 embedding 是 <span class="arithmatex">\(I=[a^1,a^2,a^3,a^4]\)</span> ，然后用 <span class="arithmatex">\(I\)</span> 乘以 transformation matrix <span class="arithmatex">\(W^q\)</span> 得到 <span class="arithmatex">\(Q=[q^1,q^2,q^3,q^4]\)</span> ，它的每一列代表着一个 vector <span class="arithmatex">\(q\)</span> 。同理，用 <span class="arithmatex">\(I\)</span> 乘以 transformation matrix <span class="arithmatex">\(W^k\)</span> 得到 <span class="arithmatex">\(K=[k^1,k^2,k^3,k^4]\)</span> ，它的每一列代表着一个 vector <span class="arithmatex">\(k\)</span> 。用 <span class="arithmatex">\(I\)</span> 乘以 transformation matrix <span class="arithmatex">\(W^v\)</span> 得到 <span class="arithmatex">\(V=[v^1,v^2,v^3,v^4]\)</span> ，它的每一列代表着一个 vector <span class="arithmatex">\(v\)</span> 。</p>
<p><img alt="" src="https://pic2.zhimg.com/v2-b081f7cbc5ecd2471567426e696bde15_r.jpg" /></p>
<p>接下来是 <span class="arithmatex">\(k\)</span> 与 <span class="arithmatex">\(q\)</span> 的 attention 过程，我们可以把 vector <span class="arithmatex">\(k\)</span> 横过来变成行向量，与列向量 <span class="arithmatex">\(q\)</span> 做内积，这里省略了 <span class="arithmatex">\(\sqrt{d}\)</span> 。这样， <span class="arithmatex">\(\alpha\)</span> 就成为了 <span class="arithmatex">\(4\times4\)</span> 的矩阵，它由 4 个行向量拼成的矩阵和 4 个列向量拼成的矩阵做内积得到，如图 11 所示。</p>
<p>在得到 <span class="arithmatex">\(\hat A\)</span> 以后，如上文所述，要得到 <span class="arithmatex">\(b^1\)</span>， 就要使用 <span class="arithmatex">\(\hat \alpha_{1,i}\)</span> 分别与 <span class="arithmatex">\(v^i\)</span> 相乘再求和得到，所以 <span class="arithmatex">\(\hat A\)</span> 要再左乘 <span class="arithmatex">\(V\)</span> 矩阵。</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-6cc342a83d25ac76b767b5bbf27d9d6e_r.jpg" /></p>
<p><img alt="" src="https://pic2.zhimg.com/v2-52a5e6b928dc44db73f85001b2d1133d_r.jpg" /></p>
<p><img alt="" src="https://pic4.zhimg.com/v2-1b7d30f098f02488c48c3601f8e13033_r.jpg" /></p>
<p>到这里你会发现这个过程可以被表示为，如图 12 所示：输入矩阵 <span class="arithmatex">\(I\in R (d,N)\)</span> 分别乘上 3 个不同的矩阵 <span class="arithmatex">\(W_q,W_k,W_v \in R (d,d)\)</span> 得到 3 个中间矩阵 <span class="arithmatex">\(Q,K,V\in R (d,N)\)</span> 。它们的维度是相同的。把 <span class="arithmatex">\(K\)</span> 转置之后与 <span class="arithmatex">\(Q\)</span> 相乘得到 Attention 矩阵 <span class="arithmatex">\(A\in R (N,N)\)</span> ，代表每一个位置两两之间的 attention。再将它取 <span class="arithmatex">\(\text{softmax}\)</span> 操作得到 <span class="arithmatex">\(\hat A\in R (N,N)\)</span> ，最后将它乘以 <span class="arithmatex">\(V\)</span> 矩阵得到输出 vector <span class="arithmatex">\(O\in R (d,N)\)</span> 。</p>
<div class="arithmatex">\[\hat A=\text{softmax}(A)=K^T\cdot Q \tag{2}\]</div>
<div class="arithmatex">\[O=V\cdot\hat A\tag{3}\]</div>
<p><img alt="" src="https://pic2.zhimg.com/v2-8628bf2c2bb9a7ee2c4a0fb870ab32b9_r.jpg" /></p>
<ul>
<li><strong>1.3 Multi-head Self-attention：</strong></li>
</ul>
<p>还有一种 multi-head 的 self-attention，以 2 个 head 的情况为例：由 <span class="arithmatex">\(a^i\)</span> 生成的 <span class="arithmatex">\(q^i\)</span> 进一步乘以 2 个转移矩阵变为 <span class="arithmatex">\(q^{i,1}\)</span> 和 <span class="arithmatex">\(q^{i,2}\)</span> ，同理由 <span class="arithmatex">\(a^i\)</span> 生成的 <span class="arithmatex">\(k^i\)</span> 进一步乘以 2 个转移矩阵变为 <span class="arithmatex">\(k^{i,1}\)</span> 和 <span class="arithmatex">\(k^{i,2}\)</span> ，由 <span class="arithmatex">\(a^i\)</span> 生成的 <span class="arithmatex">\(v^i\)</span> 进一步乘以 2 个转移矩阵变为 <span class="arithmatex">\(v^{i,1}\)</span> 和 <span class="arithmatex">\(v^{i,2}\)</span> 。接下来 <span class="arithmatex">\(q^{i,1}\)</span> 再与 <span class="arithmatex">\(k^{i,1}\)</span> 做 attention，得到 weighted sum 的权重 <span class="arithmatex">\(\alpha\)</span> ，再与 <span class="arithmatex">\(v^{i,1}\)</span> 做 weighted sum 得到最终的 <span class="arithmatex">\(b^{i,1}(i=1,2,...,N)\)</span> 。同理得到 <span class="arithmatex">\(b^{i,2}(i=1,2,...,N)\)</span> 。现在我们有了 <span class="arithmatex">\(b^{i,1}(i=1,2,...,N)\in R(d,1)\)</span> 和 <span class="arithmatex">\(b^{i,2}(i=1,2,...,N)\in R(d,1)\)</span> ，可以把它们 concat 起来，再通过一个 transformation matrix 调整维度，使之与刚才的 <span class="arithmatex">\(b^{i}(i=1,2,...,N)\in R(d,1)\)</span> 维度一致 (这步如图 13 所示)。</p>
<p><img alt="" src="https://pic1.zhimg.com/v2-688516477ad57f01a4abe5fd1a36e510_r.jpg" /></p>
<p><img alt="" src="https://pic3.zhimg.com/v2-b0891e9352874c9eee469372b85ecbe2_r.jpg" /></p>
<p><img alt="" src="https://pic1.zhimg.com/v2-df5d332304c2fd217705f210edd18bf4_r.jpg" /></p>
<p>从下图 14 可以看到 Multi-Head Attention 包含多个 Self-Attention 层，首先将输入 <span class="arithmatex">\(X\)</span> 分别传递到 2 个不同的 Self-Attention 中，计算得到 2 个输出结果。得到 2 个输出矩阵之后，Multi-Head Attention 将它们拼接在一起 (Concat)，然后传入一个 Linear 层，得到 Multi-Head Attention 最终的输出 <span class="arithmatex">\(Z\)</span> 。可以看到 Multi-Head Attention 输出的矩阵 <span class="arithmatex">\(Z\)</span> 与其输入的矩阵 <span class="arithmatex">\(X\)</span> 的维度是一样的。</p>
<p><img alt="" src="https://pic2.zhimg.com/v2-f784c73ae6eb34a00108b64e3db394fd_r.jpg" /></p>
<p>这里有一组 Multi-head Self-attention 的解果，其中绿色部分是一组 query 和 key，红色部分是另外一组 query 和 key，可以发现绿色部分其实更关注 global 的信息，而红色部分其实更关注 local 的信息。</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-6b6c906cfca399506d324cac3292b04a_r.jpg" /></p>
<ul>
<li><strong>1.4 Positional Encoding：</strong></li>
</ul>
<p>以上是 multi-head self-attention 的原理，但是还有一个问题是：现在的 self-attention 中没有位置的信息，一个单词向量的 “近在咫尺” 位置的单词向量和 “远在天涯” 位置的单词向量效果是一样的，没有表示位置的信息(No position information in self attention)。所以你输入 "A 打了 B" 或者 "B 打了 A" 的效果其实是一样的，因为并没有考虑位置的信息。所以在 self-attention 原来的 paper 中，作者为了解决这个问题所做的事情是如下图 16 所示：</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-b8886621fc841085300f5bb21de26f0e_r.jpg" /></p>
<p><img alt="" src="https://pic4.zhimg.com/v2-7814595d02ef37cb762b3ef998fae267_r.jpg" /></p>
<p>具体的做法是：给每一个位置规定一个表示位置信息的向量 <span class="arithmatex">\(e^i\)</span> ，让它与 <span class="arithmatex">\(a^i\)</span> 加在一起之后作为新的 <span class="arithmatex">\(a^i\)</span> 参与后面的运算过程，但是这个向量 <span class="arithmatex">\(e^i\)</span> 是由人工设定的，而不是神经网络学习出来的。每一个位置都有一个不同的 <span class="arithmatex">\(e^i\)</span> 。</p>
<p>那到这里一个自然而然的问题是：<strong>为什么是 <span class="arithmatex">\(e^i\)</span> 与 <span class="arithmatex">\(a^i\)</span> 相加？为什么不是 concatenate？加起来以后，原来表示位置的资讯不就混到 <span class="arithmatex">\(a^i\)</span> 里面去了吗？不就很难被找到了吗？</strong></p>
<p><strong>这里提供一种解答这个问题的思路：</strong></p>
<p>如图 15 所示，我们先给每一个位置的 <span class="arithmatex">\(x^i\in R(d,1)\)</span> append 一个 one-hot 编码的向量 <span class="arithmatex">\(p^i\in R(N,1)\)</span> ，得到一个新的输入向量 <span class="arithmatex">\(x_p^i\in R(d+N,1)\)</span> ，这个向量作为新的输入，乘以一个 transformation matrix <span class="arithmatex">\(W=[W^I,W^P]\in R(d,d+N)\)</span> 。那么：</p>
<div class="arithmatex">\[W\cdot x_p^i=[W^I,W^P]\cdot\begin{bmatrix}x^i\\p^i \end{bmatrix}=W^I\cdot x^i+W^P\cdot p^i=a^i+e^i \tag{4}\]</div>
<p><strong>所以，<span class="arithmatex">\(e^i\)</span> 与 <span class="arithmatex">\(a^i\)</span> 相加就等同于把原来的输入 <span class="arithmatex">\(x^i\)</span> concat 一个表示位置的独热编码 <span class="arithmatex">\(p^i\)</span> ，再做 transformation。</strong></p>
<p><strong>这个与位置编码乘起来的矩阵</strong> <span class="arithmatex">\(W^P\)</span> 是手工设计的，如图 17 所示 (黑色框代表一个位置的编码)。</p>
<p><img alt="" src="https://pic4.zhimg.com/v2-8b7cf3525520292bdfa159463d9717db_r.jpg" /></p>
<p>Transformer 中除了单词的 Embedding，还需要使用位置 Embedding 表示单词出现在句子中的位置。因为 Transformer 不采用 RNN 的结构，而是使用全局信息，不能利用单词的顺序信息，而这部分信息对于 NLP 来说非常重要。所以 Transformer 中使用位置 Embedding 保存单词在序列中的相对或绝对位置。</p>
<p>位置 Embedding 用 PE 表示，PE 的维度与单词 Embedding 是一样的。PE 可以通过训练得到，也可以使用某种公式计算得到。在 Transformer 中采用了后者，计算公式如下：</p>
<div class="arithmatex">\[\begin{align}PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}}) \\ PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}}) \end{align}\tag{5}\]</div>
<p>式中， <span class="arithmatex">\(pos\)</span> 表示 token 在 sequence 中的位置，例如第一个 token "我" 的 <span class="arithmatex">\(pos=0\)</span> 。</p>
<p><span class="arithmatex">\(i\)</span> ，或者准确意义上是 <span class="arithmatex">\(2i\)</span> 和 <span class="arithmatex">\(2i+1\)</span> 表示了 Positional Encoding 的维度，<span class="arithmatex">\(i\)</span> 的取值范围是： <span class="arithmatex">\(\left[ 0,\ldots ,{{{d}_{model}}}/{2}\; \right)\)</span> 。所以当 <span class="arithmatex">\(pos\)</span> 为 1 时，对应的 Positional Encoding 可以写成：</p>
<p><span class="arithmatex">\(PE\left( 1 \right)=\left[ \sin \left( {1}/{{{10000}^{{0}/{512}\;}}}\; \right),\cos \left( {1}/{{{10000}^{{0}/{512}\;}}}\; \right),\sin \left( {1}/{{{10000}^{{2}/{512}\;}}}\; \right),\cos \left( {1}/{{{10000}^{{2}/{512}\;}}}\; \right),\ldots \right]\)</span></p>
<p>式中， <span class="arithmatex">\({{d}_{model}}=512\)</span>。底数是 10000。为什么要使用 10000 呢，这个就类似于玄学了，原论文中完全没有提啊，这里不得不说说论文的 readability 的问题，即便是很多高引的文章，最基本的内容都讨论不清楚，所以才出现像上面提问里的讨论，说实话这些论文还远远没有做到 easy to follow。这里我给出一个假想：<span class="arithmatex">\({{10000}^{{1}/{512}}}\)</span> 是一个比较接近 1 的数（1.018），如果用 100000，则是 1.023。这里只是猜想一下，其实大家应该完全可以使用另一个底数。</p>
<p>这个式子的好处是：</p>
<ul>
<li>每个位置有一个唯一的 positional encoding。</li>
<li>使 <span class="arithmatex">\(PE\)</span> 能够适应比训练集里面所有句子更长的句子，假设训练集里面最长的句子是有 20 个单词，突然来了一个长度为 21 的句子，则使用公式计算的方法可以计算出第 21 位的 Embedding。</li>
<li>可以让模型容易地计算出相对位置，对于固定长度的间距 <span class="arithmatex">\(k\)</span> ，任意位置的 <span class="arithmatex">\(PE_{pos+k}\)</span> 都可以被 <span class="arithmatex">\(PE_{pos}\)</span> 的线性函数表示，因为三角函数特性：</li>
</ul>
<div class="arithmatex">\[cos(\alpha+\beta) = cos(\alpha)cos(\beta)-sin(\alpha)sin(\beta) \\
\]</div>
<div class="arithmatex">\[sin(\alpha+\beta) = sin(\alpha)cos(\beta) + cos(\alpha)sins(\beta) \\
\]</div>
<p>除了以上的固定位置编码以外，还有其他的很多表示方法：</p>
<p>比如下图 18a 就是 sin-cos 的固定位置编码。图 b 就是可学习的位置编码。图 c 和 d 分别 FLOATER 和 RNN 模型学习的位置编码。</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-4ef2648c2bebe2621c0c03001c0e1b92_r.jpg" /></p>
<p>接下来我们看看 self-attention 在 sequence2sequence model 里面是怎么使用的，我们可以把 Encoder-Decoder 中的 RNN 用 self-attention 取代掉。</p>
<p><img alt="" src="https://pic4.zhimg.com/v2-287ebca58558012f9459f3f1d5bc3827_r.jpg" /></p>
<p>在 self-attention 的最后一部分我们来对比下 self-attention 和 CNN 的关系。如图 19，今天在使用 self-attention 去处理一张图片的时候，1 的那个 pixel 产生 query，其他的各个 pixel 产生 key。在做 inner-product 的时候，考虑的不是一个小的范围，而是一整张图片。</p>
<p>但是在做 CNN 的时候是只考虑感受野红框里面的资讯，而不是图片的全局信息。所以 CNN 可以看作是一种简化版本的 self-attention。</p>
<p>或者可以反过来说，self-attention 是一种复杂化的 CNN，在做 CNN 的时候是只考虑感受野红框里面的资讯，而感受野的范围和大小是由人决定的。但是 self-attention 由 attention 找到相关的 pixel，就好像是感受野的范围和大小是自动被学出来的，所以 CNN 可以看做是 self-attention 的特例，如图 20 所示。</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-f28a8b0295863ab78d92a281ae55fce2_r.jpg" /></p>
<p><img alt="" src="https://pic4.zhimg.com/v2-f268035371aa22a350a317fc237a04f7_r.jpg" /></p>
<p>既然 self-attention 是更广义的 CNN，则这个模型更加 flexible。而我们认为，一个模型越 flexible，训练它所需要的数据量就越多，所以在训练 self-attention 模型时就需要更多的数据，这一点在下面介绍的论文 ViT 中有印证，它需要的数据集是有 3 亿张图片的 JFT-300，而如果不使用这么多数据而只使用 ImageNet，则性能不如 CNN。</p>
<h2 id="2-transformer">2 Transformer 的实现和代码解读<a class="headerlink" href="#2-transformer" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>2.1 Transformer 原理分析：</strong></li>
</ul>
<p><img alt="" src="https://pic4.zhimg.com/v2-1719966a223d98ad48f98c2e4d71add7_r.jpg" /></p>
<p><strong>Encoder：</strong></p>
<p>这个图 21 讲的是一个 seq2seq 的 model，左侧为 Encoder block，右侧为 Decoder block。红色圈中的部分为 Multi-Head Attention，是由多个 Self-Attention 组成的，可以看到 Encoder block 包含一个 Multi-Head Attention，而 Decoder block 包含两个 Multi-Head Attention (其中有一个用到 Masked)。Multi-Head Attention 上方还包括一个 Add &amp; Norm 层，Add 表示残差连接 (Residual Connection) 用于防止网络退化，Norm 表示 Layer Normalization，用于对每一层的激活值进行归一化。比如说在 Encoder Input 处的输入是机器学习，在 Decoder Input 处的输入是 &lt; BOS&gt;，输出是 machine。再下一个时刻在 Decoder Input 处的输入是 machine，输出是 learning。不断重复知道输出是句点 (.) 代表翻译结束。</p>
<p>接下来我们看看这个 Encoder 和 Decoder 里面分别都做了什么事情，先看左半部分的 Encoder：首先输入 <span class="arithmatex">\(X\in R (n_x,N)\)</span> 通过一个 Input Embedding 的转移矩阵 <span class="arithmatex">\(W^X\in R (d,n_x)\)</span> 变为了一个张量，即上文所述的 <span class="arithmatex">\(I\in R (d,N)\)</span> ，再加上一个表示位置的 Positional Encoding <span class="arithmatex">\(E\in R (d,N)\)</span> ，得到一个张量，去往后面的操作。</p>
<p>它进入了这个绿色的 block，这个绿色的 block 会重复 <span class="arithmatex">\(N\)</span> 次。这个绿色的 block 里面有什么呢？它的第 1 层是一个上文讲的 multi-head 的 attention。你现在一个 sequence <span class="arithmatex">\(I\in R (d,N)\)</span> ，经过一个 multi-head 的 attention，你会得到另外一个 sequence <span class="arithmatex">\(O\in R (d,N)\)</span> 。</p>
<p>下一个 Layer 是 Add &amp; Norm，这个意思是说：把 multi-head 的 attention 的 layer 的输入 <span class="arithmatex">\(I\in R (d,N)\)</span> 和输出 <span class="arithmatex">\(O\in R (d,N)\)</span> 进行相加以后，再做 Layer Normalization，至于 Layer Normalization 和我们熟悉的 Batch Normalization 的区别是什么，请参考图 20 和 21。</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-53267aa305030eb71376296a6fd14cde_r.jpg" /></p>
<p>其中，Batch Normalization 和 Layer Normalization 的对比可以概括为图 22，Batch Normalization 强行让一个 batch 的数据的某个 channel 的 <span class="arithmatex">\(\mu=0,\sigma=1\)</span> ，而 Layer Normalization 让一个数据的所有 channel 的 <span class="arithmatex">\(\mu=0,\sigma=1\)</span> 。</p>
<p><img alt="" src="https://pic1.zhimg.com/v2-4c13b36ec9a6a2d2f4911d2d9e7122b8_r.jpg" /></p>
<p>接着是一个 Feed Forward 的前馈网络和一个 Add &amp; Norm Layer。</p>
<p>所以，这一个绿色的 block 的前 2 个 Layer 操作的表达式为：</p>
<div class="arithmatex">\[\color{darkgreen}{O_1}=\color{green}{\text{Layer Normalization}}(\color{teal}{I}+\color{crimson}{\text{Multi-head Self-Attention}}(\color{teal}{I}))\tag{6}\]</div>
<p>这一个绿色的 block 的后 2 个 Layer 操作的表达式为：</p>
<div class="arithmatex">\[\color{darkgreen}{O_2}=\color{green}{\text{Layer Normalization}}(\color{teal}{O_1}+\color{crimson}{\text{Feed Forward Network}}(\color{teal}{O_1}))\tag{7}\]</div>
<div class="arithmatex">\[\color{green}{\text{Block}}(\color{teal}{I})=\color{green}{O_2} \tag{8}\]</div>
<p>所以 Transformer 的 Encoder 的整体操作为：</p>
<p><span class="arithmatex">\(\color{purple}{\text{Encoder}}(\color{darkgreen}{I})=\color{darkgreen}{\text{Block}}(...\color{darkgreen}{\text{Block}}(\color{darkgreen}{\text{Block}})(\color{teal}{I}))\\\quad N\;times \tag{9}\)</span></p>
<p><strong>Decoder：</strong></p>
<p>现在来看 Decoder 的部分，输入包括 2 部分，下方是前一个 time step 的输出的 embedding，即上文所述的 <span class="arithmatex">\(I\in R (d,N)\)</span> ，再加上一个表示位置的 Positional Encoding <span class="arithmatex">\(E\in R (d,N)\)</span> ，得到一个张量，去往后面的操作。它进入了这个绿色的 block，这个绿色的 block 会重复 <span class="arithmatex">\(N\)</span> 次。这个绿色的 block 里面有什么呢？</p>
<p>首先是 Masked Multi-Head Self-attention，masked 的意思是使 attention 只会 attend on 已经产生的 sequence，这个很合理，因为还没有产生出来的东西不存在，就无法做 attention。</p>
<p><strong>输出是：</strong> 对应 <span class="arithmatex">\(\color{crimson}{i}\)</span> 位置的输出词的概率分布。</p>
<p><strong>输入是：</strong> <span class="arithmatex">\(\color{purple}{Encoder}\)</span> <strong>的输出</strong> 和 <strong>对应</strong> <span class="arithmatex">\(\color{crimson}{i-1}\)</span> <strong>位置 decoder 的输出</strong>。所以中间的 attention 不是 self-attention，它的 Key 和 Value 来自 encoder，Query 来自上一位置 <span class="arithmatex">\(\color{crimson}{Decoder}\)</span> 的输出。</p>
<p><strong>解码：这里要特别注意一下，编码可以并行计算，一次性全部 Encoding 出来，但解码不是一次把所有序列解出来的，而是像</strong> <span class="arithmatex">\(RNN\)</span> <strong>一样一个一个解出来的</strong>，因为要用上一个位置的输入当作 attention 的 query。</p>
<p>明确了解码过程之后最上面的图就很好懂了，这里主要的不同就是新加的另外要说一下新加的 attention 多加了一个 mask，因为训练时的 output 都是 Ground Truth，这样可以确保预测第 <span class="arithmatex">\(\color{crimson}{i}\)</span> 个位置时不会接触到未来的信息。</p>
<ul>
<li>包含两个 Multi-Head Attention 层。</li>
<li>第一个 Multi-Head Attention 层采用了 Masked 操作。</li>
<li>第二个 Multi-Head Attention 层的 Key，Value 矩阵使用 Encoder 的编码信息矩阵 <span class="arithmatex">\(C\)</span> 进行计算，而 Query 使用上一个 Decoder block 的输出计算。</li>
<li>最后有一个 Softmax 层计算下一个翻译单词的概率。</li>
</ul>
<p>下面详细介绍下 Masked Multi-Head Self-attention 的具体操作，<strong>Masked 在 Scale 操作之后，softmax 操作之前</strong>。</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-58ac6e864d336abce052cf36d480cfee_b.jpg" /></p>
<p>因为在翻译的过程中是顺序翻译的，即翻译完第 <span class="arithmatex">\(i\)</span> 个单词，才可以翻译第 <span class="arithmatex">\(i+1\)</span> 个单词。通过 Masked 操作可以防止第 <span class="arithmatex">\(i\)</span> 个单词知道第 <span class="arithmatex">\(i+1\)</span> 个单词之后的信息。下面以 "我有一只猫" 翻译成 "I have a cat" 为例，了解一下 Masked 操作。在 Decoder 的时候，是需要根据之前的翻译，求解当前最有可能的翻译，如下图所示。首先根据输入 "<Begin>" 预测出第一个单词为 "I"，然后根据输入 "<Begin> I" 预测下一个单词 "have"。</p>
<p>Decoder 可以在训练的过程中使用 Teacher Forcing <strong>并且并行化训练，即将正确的单词序列 (<Begin> I have a cat) 和对应输出 (I have a cat <end>) 传递到 Decoder。那么在预测第</strong> <span class="arithmatex">\(i\)</span> <strong>个输出时，就要将第</strong> <span class="arithmatex">\(i+1\)</span> <strong>之后的单词掩盖住，</strong>注意 Mask 操作是在 Self-Attention 的 Softmax 之前使用的，下面用 0 1 2 3 4 5 分别表示 "<Begin> I have a cat <end>"。</p>
<p><img alt="" src="https://pic1.zhimg.com/v2-20d6a9f4b3cc8cbae05778816d1af414_r.jpg" /></p>
<p>注意这里 transformer 模型训练和测试的方法不同：</p>
<p><strong>测试时：</strong></p>
<ol>
<li>输入 <Begin>，解码器输出 I 。</li>
<li>输入前面已经解码的 <Begin> 和 I，解码器输出 have。</li>
<li>输入已经解码的 <Begin>，I, have, a, cat，解码器输出解码结束标志位 &lt; end&gt;，每次解码都会利用前面已经解码输出的所有单词嵌入信息。</li>
</ol>
<p><strong>Transformer 测试时的解码过程：</strong></p>
<p><strong>训练时：</strong></p>
<p><strong>不采用上述类似 RNN 的方法</strong>一个一个目标单词嵌入向量顺序输入训练，想采用<strong>类似编码器中的矩阵并行算法，一步就把所有目标单词预测出来</strong>。要实现这个功能就可以参考编码器的操作，把目标单词嵌入向量组成矩阵一次输入即可。即：<strong>并行化训练。</strong></p>
<p>但是在解码 have 时候，不能利用到后面单词 a 和 cat 的目标单词嵌入向量信息，否则这就是作弊 (测试时候不可能能未卜先知)。为此引入 mask。具体是：在解码器中，self-attention 层只被允许处理输出序列中更靠前的那些位置，在 softmax 步骤前，它会把后面的位置给隐去。</p>
<p><strong>Masked Multi-Head Self-attention 的具体操作</strong>如图 26 所示。</p>
<p><strong>Step1：</strong>输入矩阵包含 "<Begin> I have a cat" (0, 1, 2, 3, 4) 五个单词的表示向量，Mask 是一个 5×5 的矩阵。在 Mask 可以发现单词 0 只能使用单词 0 的信息，而单词 1 可以使用单词 0, 1 的信息，即只能使用之前的信息。输入矩阵 <span class="arithmatex">\(X\in R_{N,d_x}\)</span> 经过 transformation matrix 变为 3 个矩阵：Query <span class="arithmatex">\(Q\in R_{N,d}\)</span> ，Key <span class="arithmatex">\(K\in R_{N,d}\)</span> 和 Value <span class="arithmatex">\(V\in R_{N,d}\)</span> 。</p>
<p><strong>Step2：</strong> <span class="arithmatex">\(Q^T\cdot K\)</span> 得到 Attention 矩阵 <span class="arithmatex">\(A\in R_{N,N}\)</span> ，此时先不急于做 softmax 的操作，而是先于一个 <span class="arithmatex">\(\text{Mask}\in R_{N,N}\)</span> 矩阵相乘，使得 attention 矩阵的有些位置 归 0，得到 Masked Attention 矩阵 <span class="arithmatex">\(\text{Mask Attention}\in R_{N,N}\)</span> 。 <span class="arithmatex">\(\text{Mask}\in R_{N,N}\)</span> 矩阵是个下三角矩阵，为什么这样设计？是因为想在计算 <span class="arithmatex">\(Z\)</span> 矩阵的某一行时，只考虑它前面 token 的作用。即：在计算 <span class="arithmatex">\(Z\)</span> 的第一行时，刻意地把 <span class="arithmatex">\(\text{Attention}\)</span> 矩阵第一行的后面几个元素屏蔽掉，只考虑 <span class="arithmatex">\(\text{Attention}_{0,0}\)</span> 。在产生 have 这个单词时，只考虑 I，不考虑之后的 have a cat，即只会 attend on 已经产生的 sequence，这个很合理，因为还没有产生出来的东西不存在，就无法做 attention。</p>
<p><strong>Step3：</strong>Masked Attention 矩阵进行 Softmax，每一行的和都为 1。但是单词 0 在单词 1, 2, 3, 4 上的 attention score 都为 0。得到的结果再与 <span class="arithmatex">\(V\)</span> 矩阵相乘得到最终的 self-attention 层的输出结果 <span class="arithmatex">\(Z_1\in R_{N,d}\)</span> 。</p>
<p><strong>Step4：</strong> <span class="arithmatex">\(Z_1\in R_{N,d}\)</span> 只是某一个 head 的结果，将多个 head 的结果 concat 在一起之后再最后进行 Linear Transformation 得到最终的 Masked Multi-Head Self-attention 的输出结果 <span class="arithmatex">\(Z\in R_{N,d}\)</span> 。</p>
<p><img alt="" src="https://pic4.zhimg.com/v2-b32b3c632a20f8daf12103dd05587fd7_r.jpg" /></p>
<p>第 1 个 <strong>Masked Multi-Head Self-attention</strong> 的 <span class="arithmatex">\(\text{Query, Key, Value}\)</span> 均来自 Output Embedding。</p>
<p>第 2 个 <strong>Multi-Head Self-attention</strong> 的 <span class="arithmatex">\(\text{Query}\)</span> 来自第 1 个 Self-attention layer 的输出， <span class="arithmatex">\(\text{Key, Value}\)</span> 来自 Encoder 的输出。</p>
<p><strong>为什么这么设计？</strong>这里提供一种个人的理解：</p>
<p><span class="arithmatex">\(\text{Key, Value}\)</span> 来自 Transformer Encoder 的输出，所以可以看做<strong>句子 (Sequence)/ 图片 (image)</strong> 的<strong>内容信息 (content，比如句意是："我有一只猫"，图片内容是："有几辆车，几个人等等")</strong>。</p>
<p><span class="arithmatex">\(\text{Query}\)</span> 表达了一种诉求：希望得到什么，可以看做<strong>引导信息 (guide)</strong>。</p>
<p>通过 Multi-Head Self-attention 结合在一起的过程就相当于是<strong>把我们需要的内容信息指导表达出来</strong>。</p>
<p>Decoder 的最后是 Softmax 预测输出单词。因为 Mask 的存在，使得单词 0 的输出 <span class="arithmatex">\(Z(0,)\)</span> 只包含单词 0 的信息。Softmax 根据输出矩阵的每一行预测下一个单词，如下图 27 所示。</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-585526f8bfb9b4dfc691dfeb42562962_r.jpg" /></p>
<p>如下图 28 所示为 Transformer 的整体结构。</p>
<p><img alt="" src="https://pic2.zhimg.com/v2-b9372cc3b3a810dba41e1a64d3b296d5_r.jpg" /></p>
<ul>
<li><strong>2.2 Transformer 代码解读：</strong></li>
</ul>
<p>代码来自：</p>
<p><a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch">https://github.com/jadore801120/attention-is-all-you-need-pytorch</a><strong>ScaledDotProductAttention：</strong><br />
实现的是图 22 的操作，先令 <span class="arithmatex">\(Q\cdot K^T\)</span> ，再对结果按位乘以 <span class="arithmatex">\(\text{Mask}\)</span> 矩阵，再做 <span class="arithmatex">\(\text{Softmax}\)</span> 操作，最后的结果与 <span class="arithmatex">\(V\)</span> 相乘，得到 self-attention 的输出。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class ScaledDotProductAttention(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &#39;&#39;&#39; Scaled Dot-Product Attention &#39;&#39;&#39;
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>    def __init__(self, temperature, attn_dropout=0.1):
<span class="linenos" data-linenos=" 5 "></span>        super().__init__()
<span class="linenos" data-linenos=" 6 "></span>        self.temperature = temperature
<span class="linenos" data-linenos=" 7 "></span>        self.dropout = nn.Dropout(attn_dropout)
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span>    def forward(self, q, k, v, mask=None):
<span class="linenos" data-linenos="10 "></span>
<span class="linenos" data-linenos="11 "></span>        attn = torch.matmul(q / self.temperature, k.transpose(2, 3))
<span class="linenos" data-linenos="12 "></span>
<span class="linenos" data-linenos="13 "></span>        if mask is not None:
<span class="linenos" data-linenos="14 "></span>            attn = attn.masked_fill(mask == 0, -1e9)
<span class="linenos" data-linenos="15 "></span>
<span class="linenos" data-linenos="16 "></span>        attn = self.dropout(F.softmax(attn, dim=-1))
<span class="linenos" data-linenos="17 "></span>        output = torch.matmul(attn, v)
<span class="linenos" data-linenos="18 "></span>
<span class="linenos" data-linenos="19 "></span>        return output, attn
</code></pre></div>
<p><strong>位置编码 PositionalEncoding：</strong><br />
实现的是式 (5) 的位置编码。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class PositionalEncoding(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>
<span class="linenos" data-linenos=" 3 "></span>    def __init__(self, d_hid, n_position=200):
<span class="linenos" data-linenos=" 4 "></span>        super(PositionalEncoding, self).__init__()
<span class="linenos" data-linenos=" 5 "></span>
<span class="linenos" data-linenos=" 6 "></span>        # Not a parameter
<span class="linenos" data-linenos=" 7 "></span>        self.register_buffer(&#39;pos_table&#39;, self._get_sinusoid_encoding_table(n_position, d_hid))
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span>    def _get_sinusoid_encoding_table(self, n_position, d_hid):
<span class="linenos" data-linenos="10 "></span>        &#39;&#39;&#39; Sinusoid position encoding table &#39;&#39;&#39;
<span class="linenos" data-linenos="11 "></span>        # TODO: make it with torch instead of numpy
<span class="linenos" data-linenos="12 "></span>
<span class="linenos" data-linenos="13 "></span>        def get_position_angle_vec(position):
<span class="linenos" data-linenos="14 "></span>            return [position / np.power(10000, 2 * (hid_j // 2) / d_hid) for hid_j in range(d_hid)]
<span class="linenos" data-linenos="15 "></span>
<span class="linenos" data-linenos="16 "></span>        sinusoid_table = np.array([get_position_angle_vec(pos_i) for pos_i in range(n_position)])
<span class="linenos" data-linenos="17 "></span>        sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i
<span class="linenos" data-linenos="18 "></span>        sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span>        return torch.FloatTensor(sinusoid_table).unsqueeze(0)#(1,N,d)
<span class="linenos" data-linenos="21 "></span>
<span class="linenos" data-linenos="22 "></span>    def forward(self, x):
<span class="linenos" data-linenos="23 "></span>        # x(B,N,d)
<span class="linenos" data-linenos="24 "></span>        return x + self.pos_table[:, :x.size(1)].clone().detach()
</code></pre></div>
<p><strong>MultiHeadAttention：</strong><br />
实现图 13，14 的多头 self-attention。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class MultiHeadAttention(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &#39;&#39;&#39; Multi-Head Attention module &#39;&#39;&#39;
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):
<span class="linenos" data-linenos=" 5 "></span>        super().__init__()
<span class="linenos" data-linenos=" 6 "></span>
<span class="linenos" data-linenos=" 7 "></span>        self.n_head = n_head
<span class="linenos" data-linenos=" 8 "></span>        self.d_k = d_k
<span class="linenos" data-linenos=" 9 "></span>        self.d_v = d_v
<span class="linenos" data-linenos="10 "></span>
<span class="linenos" data-linenos="11 "></span>        self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)
<span class="linenos" data-linenos="12 "></span>        self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False)
<span class="linenos" data-linenos="13 "></span>        self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False)
<span class="linenos" data-linenos="14 "></span>        self.fc = nn.Linear(n_head * d_v, d_model, bias=False)
<span class="linenos" data-linenos="15 "></span>
<span class="linenos" data-linenos="16 "></span>        self.attention = ScaledDotProductAttention(temperature=d_k ** 0.5)
<span class="linenos" data-linenos="17 "></span>
<span class="linenos" data-linenos="18 "></span>        self.dropout = nn.Dropout(dropout)
<span class="linenos" data-linenos="19 "></span>        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)
<span class="linenos" data-linenos="20 "></span>
<span class="linenos" data-linenos="21 "></span>
<span class="linenos" data-linenos="22 "></span>    def forward(self, q, k, v, mask=None):
<span class="linenos" data-linenos="23 "></span>
<span class="linenos" data-linenos="24 "></span>        d_k, d_v, n_head = self.d_k, self.d_v, self.n_head
<span class="linenos" data-linenos="25 "></span>        sz_b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)
<span class="linenos" data-linenos="26 "></span>
<span class="linenos" data-linenos="27 "></span>        residual = q
<span class="linenos" data-linenos="28 "></span>
<span class="linenos" data-linenos="29 "></span>
<span class="linenos" data-linenos="30 "></span>        # Pass through the pre-attention projection: b x lq x (n*dv)
<span class="linenos" data-linenos="31 "></span>        # Separate different heads: b x lq x n x dv
<span class="linenos" data-linenos="32 "></span>        q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)
<span class="linenos" data-linenos="33 "></span>        k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)
<span class="linenos" data-linenos="34 "></span>        v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)
<span class="linenos" data-linenos="35 "></span>
<span class="linenos" data-linenos="36 "></span>        # Transpose for attention dot product: b x n x lq x dv
<span class="linenos" data-linenos="37 "></span>        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)
<span class="linenos" data-linenos="38 "></span>
<span class="linenos" data-linenos="39 "></span>        if mask is not None:
<span class="linenos" data-linenos="40 "></span>            mask = mask.unsqueeze(1)   # For head axis broadcasting.
<span class="linenos" data-linenos="41 "></span>
<span class="linenos" data-linenos="42 "></span>        q, attn = self.attention(q, k, v, mask=mask)
<span class="linenos" data-linenos="43 "></span>
<span class="linenos" data-linenos="44 "></span>        #q (sz_b,n_head,N=len_q,d_k)
<span class="linenos" data-linenos="45 "></span>        #k (sz_b,n_head,N=len_k,d_k)
<span class="linenos" data-linenos="46 "></span>        #v (sz_b,n_head,N=len_v,d_v)
<span class="linenos" data-linenos="47 "></span>
<span class="linenos" data-linenos="48 "></span>        # Transpose to move the head dimension back: b x lq x n x dv
<span class="linenos" data-linenos="49 "></span>        # Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)
<span class="linenos" data-linenos="50 "></span>        q = q.transpose(1, 2).contiguous().view(sz_b, len_q, -1)
<span class="linenos" data-linenos="51 "></span>
<span class="linenos" data-linenos="52 "></span>        #q (sz_b,len_q,n_head,N * d_k)
<span class="linenos" data-linenos="53 "></span>        q = self.dropout(self.fc(q))
<span class="linenos" data-linenos="54 "></span>        q += residual
<span class="linenos" data-linenos="55 "></span>
<span class="linenos" data-linenos="56 "></span>        q = self.layer_norm(q)
<span class="linenos" data-linenos="57 "></span>
<span class="linenos" data-linenos="58 "></span>        return q, attn
</code></pre></div>
<p><strong>前向传播 Feed Forward Network：</strong></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class PositionwiseFeedForward(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &#39;&#39;&#39; A two-feed-forward-layer module &#39;&#39;&#39;
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>    def __init__(self, d_in, d_hid, dropout=0.1):
<span class="linenos" data-linenos=" 5 "></span>        super().__init__()
<span class="linenos" data-linenos=" 6 "></span>        self.w_1 = nn.Linear(d_in, d_hid) # position-wise
<span class="linenos" data-linenos=" 7 "></span>        self.w_2 = nn.Linear(d_hid, d_in) # position-wise
<span class="linenos" data-linenos=" 8 "></span>        self.layer_norm = nn.LayerNorm(d_in, eps=1e-6)
<span class="linenos" data-linenos=" 9 "></span>        self.dropout = nn.Dropout(dropout)
<span class="linenos" data-linenos="10 "></span>
<span class="linenos" data-linenos="11 "></span>    def forward(self, x):
<span class="linenos" data-linenos="12 "></span>
<span class="linenos" data-linenos="13 "></span>        residual = x
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span>        x = self.w_2(F.relu(self.w_1(x)))
<span class="linenos" data-linenos="16 "></span>        x = self.dropout(x)
<span class="linenos" data-linenos="17 "></span>        x += residual
<span class="linenos" data-linenos="18 "></span>
<span class="linenos" data-linenos="19 "></span>        x = self.layer_norm(x)
<span class="linenos" data-linenos="20 "></span>
<span class="linenos" data-linenos="21 "></span>        return x
</code></pre></div>
<p><strong>EncoderLayer：</strong><br />
实现图 26 中的一个 EncoderLayer，具体的结构如图 19 所示。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class EncoderLayer(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &#39;&#39;&#39; Compose with two layers &#39;&#39;&#39;
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):
<span class="linenos" data-linenos=" 5 "></span>        super(EncoderLayer, self).__init__()
<span class="linenos" data-linenos=" 6 "></span>        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)
<span class="linenos" data-linenos=" 7 "></span>        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout)
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span>    def forward(self, enc_input, slf_attn_mask=None):
<span class="linenos" data-linenos="10 "></span>        enc_output, enc_slf_attn = self.slf_attn(
<span class="linenos" data-linenos="11 "></span>            enc_input, enc_input, enc_input, mask=slf_attn_mask)
<span class="linenos" data-linenos="12 "></span>        enc_output = self.pos_ffn(enc_output)
<span class="linenos" data-linenos="13 "></span>        return enc_output, enc_slf_attn
</code></pre></div>
<p><strong>DecoderLayer：</strong><br />
实现图 28 中的一个 DecoderLayer，具体的结构如图 21 所示。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class DecoderLayer(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &#39;&#39;&#39; Compose with three layers &#39;&#39;&#39;
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>    def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):
<span class="linenos" data-linenos=" 5 "></span>        super(DecoderLayer, self).__init__()
<span class="linenos" data-linenos=" 6 "></span>        self.slf_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)
<span class="linenos" data-linenos=" 7 "></span>        self.enc_attn = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout)
<span class="linenos" data-linenos=" 8 "></span>        self.pos_ffn = PositionwiseFeedForward(d_model, d_inner, dropout=dropout)
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>    def forward(
<span class="linenos" data-linenos="11 "></span>            self, dec_input, enc_output,
<span class="linenos" data-linenos="12 "></span>            slf_attn_mask=None, dec_enc_attn_mask=None):
<span class="linenos" data-linenos="13 "></span>        dec_output, dec_slf_attn = self.slf_attn(
<span class="linenos" data-linenos="14 "></span>            dec_input, dec_input, dec_input, mask=slf_attn_mask)
<span class="linenos" data-linenos="15 "></span>        dec_output, dec_enc_attn = self.enc_attn(
<span class="linenos" data-linenos="16 "></span>            dec_output, enc_output, enc_output, mask=dec_enc_attn_mask)
<span class="linenos" data-linenos="17 "></span>        dec_output = self.pos_ffn(dec_output)
<span class="linenos" data-linenos="18 "></span>        return dec_output, dec_slf_attn, dec_enc_attn
</code></pre></div>
<p><strong>Encoder：</strong><br />
实现图 28,21 左侧的 Encoder：</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class Encoder(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &#39;&#39;&#39; A encoder model with self attention mechanism. &#39;&#39;&#39;
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>    def __init__(
<span class="linenos" data-linenos=" 5 "></span>            self, n_src_vocab, d_word_vec, n_layers, n_head, d_k, d_v,
<span class="linenos" data-linenos=" 6 "></span>            d_model, d_inner, pad_idx, dropout=0.1, n_position=200):
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span>        super().__init__()
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>        self.src_word_emb = nn.Embedding(n_src_vocab, d_word_vec, padding_idx=pad_idx)
<span class="linenos" data-linenos="11 "></span>        self.position_enc = PositionalEncoding(d_word_vec, n_position=n_position)
<span class="linenos" data-linenos="12 "></span>        self.dropout = nn.Dropout(p=dropout)
<span class="linenos" data-linenos="13 "></span>        self.layer_stack = nn.ModuleList([
<span class="linenos" data-linenos="14 "></span>            EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout)
<span class="linenos" data-linenos="15 "></span>            for _ in range(n_layers)])
<span class="linenos" data-linenos="16 "></span>        self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)
<span class="linenos" data-linenos="17 "></span>
<span class="linenos" data-linenos="18 "></span>    def forward(self, src_seq, src_mask, return_attns=False):
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span>        enc_slf_attn_list = []
<span class="linenos" data-linenos="21 "></span>
<span class="linenos" data-linenos="22 "></span>        # -- Forward
<span class="linenos" data-linenos="23 "></span>
<span class="linenos" data-linenos="24 "></span>        enc_output = self.dropout(self.position_enc(self.src_word_emb(src_seq)))
<span class="linenos" data-linenos="25 "></span>        enc_output = self.layer_norm(enc_output)
<span class="linenos" data-linenos="26 "></span>
<span class="linenos" data-linenos="27 "></span>        for enc_layer in self.layer_stack:
<span class="linenos" data-linenos="28 "></span>            enc_output, enc_slf_attn = enc_layer(enc_output, slf_attn_mask=src_mask)
<span class="linenos" data-linenos="29 "></span>            enc_slf_attn_list += [enc_slf_attn] if return_attns else []
<span class="linenos" data-linenos="30 "></span>
<span class="linenos" data-linenos="31 "></span>        if return_attns:
<span class="linenos" data-linenos="32 "></span>            return enc_output, enc_slf_attn_list
<span class="linenos" data-linenos="33 "></span>        return enc_output,
</code></pre></div>
<p><strong>Decoder：</strong><br />
实现图 28,21 右侧的 Decoder：</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class Decoder(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &#39;&#39;&#39; A decoder model with self attention mechanism. &#39;&#39;&#39;
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>    def forward(self, trg_seq, trg_mask, enc_output, src_mask, return_attns=False):
<span class="linenos" data-linenos=" 5 "></span>
<span class="linenos" data-linenos=" 6 "></span>        dec_slf_attn_list, dec_enc_attn_list = [], []
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span>        # -- Forward
<span class="linenos" data-linenos=" 9 "></span>        dec_output = self.dropout(self.position_enc(self.trg_word_emb(trg_seq)))
<span class="linenos" data-linenos="10 "></span>        dec_output = self.layer_norm(dec_output)
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span>        for dec_layer in self.layer_stack:
<span class="linenos" data-linenos="13 "></span>            dec_output, dec_slf_attn, dec_enc_attn = dec_layer(
<span class="linenos" data-linenos="14 "></span>                dec_output, enc_output, slf_attn_mask=trg_mask, dec_enc_attn_mask=src_mask)
<span class="linenos" data-linenos="15 "></span>            dec_slf_attn_list += [dec_slf_attn] if return_attns else []
<span class="linenos" data-linenos="16 "></span>            dec_enc_attn_list += [dec_enc_attn] if return_attns else []
<span class="linenos" data-linenos="17 "></span>
<span class="linenos" data-linenos="18 "></span>        if return_attns:
<span class="linenos" data-linenos="19 "></span>            return dec_output, dec_slf_attn_list, dec_enc_attn_list
<span class="linenos" data-linenos="20 "></span>        return dec_output,
</code></pre></div>
<p><strong>整体结构：</strong><br />
实现图 28,21 整体的 Transformer：</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class Transformer(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &#39;&#39;&#39; A sequence to sequence model with attention mechanism. &#39;&#39;&#39;
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>    def __init__(
<span class="linenos" data-linenos=" 5 "></span>            self, n_src_vocab, n_trg_vocab, src_pad_idx, trg_pad_idx,
<span class="linenos" data-linenos=" 6 "></span>            d_word_vec=512, d_model=512, d_inner=2048,
<span class="linenos" data-linenos=" 7 "></span>            n_layers=6, n_head=8, d_k=64, d_v=64, dropout=0.1, n_position=200,
<span class="linenos" data-linenos=" 8 "></span>            trg_emb_prj_weight_sharing=True, emb_src_trg_weight_sharing=True):
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>        super().__init__()
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span>        self.src_pad_idx, self.trg_pad_idx = src_pad_idx, trg_pad_idx
<span class="linenos" data-linenos="13 "></span>
<span class="linenos" data-linenos="14 "></span>        self.encoder = Encoder(
<span class="linenos" data-linenos="15 "></span>            n_src_vocab=n_src_vocab, n_position=n_position,
<span class="linenos" data-linenos="16 "></span>            d_word_vec=d_word_vec, d_model=d_model, d_inner=d_inner,
<span class="linenos" data-linenos="17 "></span>            n_layers=n_layers, n_head=n_head, d_k=d_k, d_v=d_v,
<span class="linenos" data-linenos="18 "></span>            pad_idx=src_pad_idx, dropout=dropout)
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span>        self.decoder = Decoder(
<span class="linenos" data-linenos="21 "></span>            n_trg_vocab=n_trg_vocab, n_position=n_position,
<span class="linenos" data-linenos="22 "></span>            d_word_vec=d_word_vec, d_model=d_model, d_inner=d_inner,
<span class="linenos" data-linenos="23 "></span>            n_layers=n_layers, n_head=n_head, d_k=d_k, d_v=d_v,
<span class="linenos" data-linenos="24 "></span>            pad_idx=trg_pad_idx, dropout=dropout)
<span class="linenos" data-linenos="25 "></span>
<span class="linenos" data-linenos="26 "></span>        self.trg_word_prj = nn.Linear(d_model, n_trg_vocab, bias=False)
<span class="linenos" data-linenos="27 "></span>
<span class="linenos" data-linenos="28 "></span>        for p in self.parameters():
<span class="linenos" data-linenos="29 "></span>            if p.dim() &gt; 1:
<span class="linenos" data-linenos="30 "></span>                nn.init.xavier_uniform_(p) 
<span class="linenos" data-linenos="31 "></span>
<span class="linenos" data-linenos="32 "></span>        assert d_model == d_word_vec, \
<span class="linenos" data-linenos="33 "></span>        &#39;To facilitate the residual connections, \
<span class="linenos" data-linenos="34 "></span>         the dimensions of all module outputs shall be the same.&#39;
<span class="linenos" data-linenos="35 "></span>
<span class="linenos" data-linenos="36 "></span>        self.x_logit_scale = 1.
<span class="linenos" data-linenos="37 "></span>        if trg_emb_prj_weight_sharing:
<span class="linenos" data-linenos="38 "></span>            # Share the weight between target word embedding &amp; last dense layer
<span class="linenos" data-linenos="39 "></span>            self.trg_word_prj.weight = self.decoder.trg_word_emb.weight
<span class="linenos" data-linenos="40 "></span>            self.x_logit_scale = (d_model ** -0.5)
<span class="linenos" data-linenos="41 "></span>
<span class="linenos" data-linenos="42 "></span>        if emb_src_trg_weight_sharing:
<span class="linenos" data-linenos="43 "></span>            self.encoder.src_word_emb.weight = self.decoder.trg_word_emb.weight
<span class="linenos" data-linenos="44 "></span>
<span class="linenos" data-linenos="45 "></span>
<span class="linenos" data-linenos="46 "></span>    def forward(self, src_seq, trg_seq):
<span class="linenos" data-linenos="47 "></span>
<span class="linenos" data-linenos="48 "></span>        src_mask = get_pad_mask(src_seq, self.src_pad_idx)
<span class="linenos" data-linenos="49 "></span>        trg_mask = get_pad_mask(trg_seq, self.trg_pad_idx) &amp; get_subsequent_mask(trg_seq)
<span class="linenos" data-linenos="50 "></span>
<span class="linenos" data-linenos="51 "></span>        enc_output, *_ = self.encoder(src_seq, src_mask)
<span class="linenos" data-linenos="52 "></span>        dec_output, *_ = self.decoder(trg_seq, trg_mask, enc_output, src_mask)
<span class="linenos" data-linenos="53 "></span>        seq_logit = self.trg_word_prj(dec_output) * self.x_logit_scale
<span class="linenos" data-linenos="54 "></span>
<span class="linenos" data-linenos="55 "></span>        return seq_logit.view(-1, seq_logit.size(2))
</code></pre></div>
<p><strong>产生 Mask：</strong></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos="1 "></span>def get_pad_mask(seq, pad_idx):
<span class="linenos" data-linenos="2 "></span>    return (seq != pad_idx).unsqueeze(-2)
<span class="linenos" data-linenos="3 "></span>
<span class="linenos" data-linenos="4 "></span>def get_subsequent_mask(seq):
<span class="linenos" data-linenos="5 "></span>    &#39;&#39;&#39; For masking out the subsequent info. &#39;&#39;&#39;
<span class="linenos" data-linenos="6 "></span>    sz_b, len_s = seq.size()
<span class="linenos" data-linenos="7 "></span>    subsequent_mask = (1 - torch.triu(
<span class="linenos" data-linenos="8 "></span>        torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()
<span class="linenos" data-linenos="9 "></span>    return subsequent_mask
</code></pre></div>
<p>src_mask = get_pad_mask(src_seq, self.src_pad_idx)<br />
用于产生 Encoder 的 Mask，它是一列 Bool 值，负责把标点 mask 掉。<br />
trg_mask = get_pad_mask(trg_seq, self.trg_pad_idx) &amp; get_subsequent_mask(trg_seq)<br />
用于产生 Decoder 的 Mask。它是一个矩阵，如图 24 中的 Mask 所示，功能已在上文介绍。</p>
<h3 id="3-transformerdetection-detr">3 Transformer+Detection：引入视觉领域的首创 DETR<a class="headerlink" href="#3-transformerdetection-detr" title="Permanent link">&para;</a></h3>
<p><strong>论文名称：End-to-End Object Detection with Transformers</strong></p>
<p><strong>论文地址：</strong></p>
<p><a href="https://arxiv.org/abs/2005.12872">https://arxiv.org/abs/2005.12872</a></p>
<ul>
<li><strong>3.1 DETR 原理分析：</strong></li>
</ul>
<p><span class="arithmatex">\(\color{indianred}{\text{网络架构部分解读:}}\)</span></p>
<p>本文的任务是 Object detection，用到的工具是 Transformers，特点是 End-to-end。</p>
<p>目标检测的任务是要去预测一系列的 Bounding Box 的坐标以及 Label， 现代大多数检测器通过定义一些 proposal，anchor 或者 windows，把问题构建成为一个分类和回归问题来间接地完成这个任务。<strong>文章所做的工作，就是将 transformers 运用到了 object detection 领域，取代了现在的模型需要手工设计的工作，并且取得了不错的结果。</strong>在 object detection 上 DETR 准确率和运行时间上和 Faster RCNN 相当；将模型 generalize 到 panoptic segmentation 任务上，DETR 表现甚至还超过了其他的 baseline。DETR 第一个使用 End to End 的方式解决检测问题，解决的方法是把检测问题视作是一个 set prediction problem，如下图 29 所示。</p>
<p><img alt="" src="https://pic1.zhimg.com/v2-772984ccd82a0e0a279ea6a09c3c34c0_r.jpg" /></p>
<p>网络的主要组成是 CNN 和 Transformer，Transformer 借助第 1 节讲到的 self-attention 机制，可以显式地对一个序列中的所有 elements 两两之间的 interactions 进行建模，使得这类 transformer 的结构非常适合带约束的 set prediction 的问题。DETR 的特点是：一次预测，端到端训练，set loss function 和二分匹配。</p>
<p><strong>文章的主要有两个关键的部分。</strong></p>
<p><strong>第一个是用 transformer 的 encoder-decoder 架构一次性生成</strong> <span class="arithmatex">\(N\)</span> <strong>个 box prediction。其中</strong> <span class="arithmatex">\(N\)</span> <strong>是一个事先设定的、比远远大于 image 中 object 个数的一个整数。</strong></p>
<p><strong>第二个是设计了 bipartite matching loss，基于预测的 boxex 和 ground truth boxes 的二分图匹配计算 loss 的大小，从而使得预测的 box 的位置和类别更接近于 ground truth。</strong></p>
<p>DETR 整体结构可以分为四个部分：backbone，encoder，decoder 和 FFN，如下图 30 所示，以下分别解释这四个部分：</p>
<p><img alt="" src="https://pic4.zhimg.com/v2-3d43474df51c545ad6bafc19b3c8ccc3_r.jpg" /></p>
<p><strong>1 首先看 backbone：</strong>CNN backbone 处理 <span class="arithmatex">\(x_{\text{img}}\in B\times 3\times H_0 \times W_0\)</span> 维的图像，把它转换为<span class="arithmatex">\(f\in R^{B\times C\times H\times W}\)</span> 维的 feature map（一般来说 <span class="arithmatex">\(C = 2048或256, H = \frac{H_0}{32}, W = \frac{W_0}{32}\)</span>），backbone 只做这一件事。</p>
<p><strong>2 再看 encoder：</strong>encoder 的输入是<span class="arithmatex">\(f\in R^{B\times C\times H\times W}\)</span> 维的 feature map，接下来依次进行以下过程：</p>
<ul>
<li><strong>通道数压缩：</strong>先用 <span class="arithmatex">\(1\times 1\)</span> convolution 处理，将 channels 数量从 <span class="arithmatex">\(C\)</span> 压缩到 <span class="arithmatex">\(d\)</span>，即得到<span class="arithmatex">\(z_0\in R^{B\times d\times H\times W}\)</span> 维的新 feature map。</li>
<li><strong>转化为序列化数据：</strong>将空间的维度（高和宽）压缩为一个维度，即把上一步得到的<span class="arithmatex">\(z_0\in R^{B\times d\times H\times W}(d=256)\)</span> 维的 feature map 通过 reshape 成<span class="arithmatex">\((HW,B,256)\)</span> 维的 feature map。</li>
<li><strong>位置编码：</strong>在得到了<span class="arithmatex">\(z_0\in R^{B\times d\times H\times W}\)</span> 维的 feature map 之后，正式输入 encoder 之前，需要进行 <strong>Positional Encoding</strong>。这一步在第 2 节讲解 transformer 的时候已经提到过，因为<strong>在 self-attention 中需要有表示位置的信息</strong>，否则你的 sequence = "A 打了 B" 还是 sequence = "B 打了 A" 的效果是一样的。<strong>但是 transformer encoder 这个结构本身却无法体现出位置信息。</strong>也就是说，我们需要对这个 <span class="arithmatex">\(z_0\in R^{B\times d\times H\times W}\)</span> 维的 feature map 做 positional encoding。</li>
</ul>
<p>进行完位置编码以后根据 paper 中的图片会有个相加的过程，如下图问号处所示。很多读者有疑问的地方是：论文图 31 示中相加的 2 个张量，一个是 input embedding，另一个是位置编码维度看上去不一致，是怎么相加的？后面会解答。</p>
<p><img alt="" src="https://pic1.zhimg.com/v2-a7e4de7ab9cc0d3015ca04cc251ee460_r.jpg" /></p>
<p>原版 Transformer 和 Vision Transformer (第 4 节讲述) 的 Positional Encoding 的表达式为：</p>
<div class="arithmatex">\[\begin{align}PE_{(pos, 2i)} = sin(pos/10000^{2i/d}) \\ PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d}) \end{align}\tag{10}\]</div>
<p>式中， <span class="arithmatex">\(d\)</span> 就是这个 <span class="arithmatex">\(d\times HW\)</span> 维的 feature map 的第一维， <span class="arithmatex">\(pos\in [1,HW]\)</span> 。表示 token 在 sequence 中的位置，sequence 的长度是 <span class="arithmatex">\(HW\)</span> ，例如第一个 token 的 <span class="arithmatex">\(pos=0\)</span> 。</p>
<p><span class="arithmatex">\(i\)</span> ，或者准确意义上是 <span class="arithmatex">\(2i\)</span> 和 <span class="arithmatex">\(2i+1\)</span> 表示了 Positional Encoding 的维度，<span class="arithmatex">\(i\)</span> 的取值范围是： <span class="arithmatex">\(\left[ 0,\ldots ,{{{d}}}/{2}\; \right)\)</span> 。所以当 <span class="arithmatex">\(pos\)</span> 为 1 时，对应的 Positional Encoding 可以写成：</p>
<p><span class="arithmatex">\(PE\left( 1 \right)=\left[ \sin \left( {1}/{{{10000}^{{0}/{256}\;}}}\; \right),\cos \left( {1}/{{{10000}^{{0}/{256}\;}}}\; \right),\sin \left( {1}/{{{10000}^{{2}/{256}\;}}}\; \right),\cos \left( {1}/{{{10000}^{{2}/{256}\;}}}\; \right),\ldots \right]\)</span></p>
<p>式中， <span class="arithmatex">\({{d}_{}}=256\)</span>。</p>
<p><strong>第一点不同的是</strong>，原版 Transformer 只考虑 <span class="arithmatex">\(x\)</span> 方向的位置编码，但是 DETR 考虑了 <span class="arithmatex">\(xy\)</span> 方向的位置编码，因为图像特征是 2-D 特征。采用的依然是 <span class="arithmatex">\(\text{sin cos}\)</span> 模式，但是需要考虑 <span class="arithmatex">\(xy\)</span> 两个方向。不是类似 vision transoformer 做法简单的将其拉伸为 <span class="arithmatex">\(d\times HW\)</span> ，然后从 <span class="arithmatex">\([1,HW]\)</span> 进行长度为 256 的位置编码，而是考虑了 <span class="arithmatex">\(xy\)</span> 方向同时编码，每个方向各编码 128 维向量，这种编码方式更符合图像特点。</p>
<p>Positional Encoding 的输出张量是： <span class="arithmatex">\((B,d,H,W),d=256\)</span> ，其中 <span class="arithmatex">\(d\)</span> 代表位置编码的长度， <span class="arithmatex">\(H,W\)</span> 代表张量的位置。意思是说，这个特征图上的任意一个点 <span class="arithmatex">\((H_1,W_1)\)</span> 有个位置编码，这个编码的长度是 256，其中，前 128 维代表 <span class="arithmatex">\(H_1\)</span> 的位置编码，后 128 维代表 <span class="arithmatex">\(W_1\)</span> 的位置编码。</p>
<div class="arithmatex">\[\begin{align}a)\quad PE_{(pos_x, 2i)} = sin(pos_x/10000^{2i/128}) \\ b)\quad PE_{(pos_x, 2i+1)} = cos(pos_x/10000^{2i/128}) \\c)\quad PE_{(pos_y, 2i)} = sin(pos_y/10000^{2i/128}) \\ d)\quad PE_{(pos_y, 2i+1)} = cos(pos_y/10000^{2i/128}) \end{align}\tag{11}\]</div>
<p>假设你想计算任意一个位置 <span class="arithmatex">\((pos_x,pos_y),pos_x\in [1,HW],pos_y\in [1,HW]\)</span> 的 Positional Encoding，把 <span class="arithmatex">\(pos_x\)</span> 代入 (11) 式的 <span class="arithmatex">\(a\)</span> 式和 <span class="arithmatex">\(b\)</span> 式可以计算得到 <strong>128 维的向量</strong>，它代表 <span class="arithmatex">\(pos_x\)</span> 的位置编码，再把 <span class="arithmatex">\(pos_y\)</span> 代入 (11) 式的 <span class="arithmatex">\(c\)</span> 式和 <span class="arithmatex">\(d\)</span> 式可以计算得到 <strong>128 维的向量</strong>，它代表 <span class="arithmatex">\(pos_y\)</span> 的位置编码，把这 2 个 128 维的向量拼接起来，就得到了一个 <strong>256 维的向量</strong>，它代表 <span class="arithmatex">\((pos_x,pos_y)\)</span> 的位置编码。</p>
<p>计算所有位置的编码，就得到了 <span class="arithmatex">\((256,H,W)\)</span> 的张量，代表这个 batch 的位置编码。编码矩阵的维度是 <span class="arithmatex">\((B,256,H,W)\)</span> ，也把它<strong>序列化成维度为</strong> <span class="arithmatex">\((HW,B,256)\)</span> 维的张量。</p>
<p><strong>准备与<span class="arithmatex">\((HW,B,256)\)</span> 维的 feature map 相加以后输入 Encoder。</strong></p>
<p>值得注意的是，网上许多解读文章没有搞清楚 "转化为序列化数据" 这一步和 "位置编码" 的顺序关系，以及变量的 shape 到底是怎样变化的，这里我用一个图 32 表达，终结这个问题。</p>
<p><img alt="" src="https://pic1.zhimg.com/v2-89d23b461169c6ab25ea64389fe8d86c_r.jpg" /></p>
<p>所以，了解了 DETR 的位置编码之后，你应该明白了其实 input embedding 和位置编码维度其实是一样的，只是论文图示为了突出二位编码所以画的不一样罢了，如下图 33 所示：</p>
<p><img alt="" src="https://pic4.zhimg.com/v2-464b4196c273afbe67445d21b7bedc77_r.jpg" /></p>
<p><strong>另一点不同的是，原版 Transformer</strong> 只在 Encoder 之前使用了 Positional Encoding，而且是<strong>在输入上进行 Positional Encoding，再把输入经过 transformation matrix 变为 Query，Key 和 Value 这几个张量。但是 DETR</strong> 在 Encoder 的每一个 Multi-head Self-attention 之前都使用了 Positional Encoding，且<strong>只对 Query 和 Key 使用了 Positional Encoding，即：只把维度为<span class="arithmatex">\((HW,B,256)\)</span> 维的位置编码与维度为<span class="arithmatex">\((HW,B,256)\)</span> 维的 Query 和 Key 相加，而不与 Value 相加。</strong></p>
<p>如图 34 所示为 DETR 的 Transformer 的详细结构，读者可以对比下原版 Transformer 的结构，如图 21 所示，为了阅读的方便我把图 21 又贴在下面了。</p>
<p>可以发现，除了 Positional Encoding 设置的不一样外，Encoder 其他的结构是一致的。每个 Encoder Layer 包含一个 multi-head self-attention 的 module 和一个前馈网络 Feed Forward Network。</p>
<p><strong>Encoder 最终输出的是 <span class="arithmatex">\((H\cdot W,b,256)\)</span> 维的编码矩阵 Embedding，按照原版 Transformer 的做法，把这个东西给 Decoder。</strong></p>
<p><strong>总结下和原始 transformer 编码器不同的地方：</strong></p>
<ul>
<li>输入编码器的位置编码需要考虑 2-D 空间位置。</li>
<li>位置编码向量需要加入到每个 Encoder Layer 中。</li>
<li>在编码器内部位置编码 Positional Encoding 仅仅作用于 Query 和 Key，即只与 Query 和 Key 相加，Value 不做任何处理。</li>
</ul>
<p><img alt="" src="https://pic3.zhimg.com/v2-c158521c7a602382dfa4d85243672df2_r.jpg" /></p>
<p><img alt="" src="https://pic4.zhimg.com/v2-1719966a223d98ad48f98c2e4d71add7_r.jpg" /></p>
<p><strong>3 再看 decoder：</strong></p>
<p>DETR 的 Decoder 和原版 Transformer 的 decoder 是不太一样的，如下图 34 和 21 所示。</p>
<p>先回忆下原版 Transformer，看下图 21 的 decoder 的最后一个框：output probability，代表我们一次只产生一个单词的 softmax，根据这个 softmax 得到这个单词的预测结果。这个过程我们表达为：<strong>predicts the output sequence one element at a time</strong>。</p>
<p>不同的是，DETR 的 Transformer Decoder 是一次性处理全部的 object queries，即一次性输出全部的 predictions；而不像原始的 Transformer 是 auto-regressive 的，从左到右一个词一个词地输出。这个过程我们表达为：<strong>decodes the N objects in parallel at each decoder layer。</strong></p>
<p>DETR 的 Decoder 主要有两个输入：</p>
<ol>
<li><strong>Transformer Encoder 输出的 Embedding 与 position encoding 之和。</strong></li>
<li><strong>Object queries。</strong></li>
</ol>
<p>其中，Embedding 就是上文提到的 <span class="arithmatex">\((H\cdot W,b,256)\)</span> 的编码矩阵。这里着重讲一下 Object queries。</p>
<p>Object queries 是一个维度为 <span class="arithmatex">\((100,b,256)\)</span> 维的张量，数值类型是 nn.Embedding，说明这个张量是可以学习的，即：我们的 Object queries 是可学习的。Object queries 矩阵内部通过学习建模了 100 个物体之间的全局关系，例如房间里面的桌子旁边 (A 类) 一般是放椅子(B 类)，而不会是放一头大象(C 类)，那么在推理时候就可以利用该全局注意力更好的进行解码预测输出。</p>
<p>Decoder 的输入一开始也初始化成维度为 <span class="arithmatex">\((100,b,256)\)</span> 维的全部元素都为 0 的张量，和 Object queries 加在一起之后<strong>充当第 1 个 multi-head self-attention 的 Query 和 Key。第一个 multi-head self-attention 的 Value 为 Decoder 的输入</strong>，也就是全 0 的张量。</p>
<p>到了每个 Decoder 的第 2 个 multi-head self-attention，它的 Key 和 Value 来自 Encoder 的输出张量，维度为 <span class="arithmatex">\((hw,b,256)\)</span> ，其中 Key 值还进行位置编码。Query 值一部分来自第 1 个 Add and Norm 的输出，维度为 <span class="arithmatex">\((100,b,256)\)</span> 的张量，另一部分来自 Object queries，充当可学习的位置编码。所以，第 2 个 multi-head self-attention 的 Key 和 Value 的维度为 <span class="arithmatex">\((hw,b,256)\)</span> ，而 Query 的维度为<span class="arithmatex">\((100,b,256)\)</span>。</p>
<p>每个 Decoder 的输出维度为 <span class="arithmatex">\((1,b,100,256)\)</span> ，送入后面的前馈网络，具体的变量维度的变化见图 30。</p>
<p>到这里你会发现：Object queries 充当的其实是位置编码的作用，只不过它是可以学习的位置编码，所以，我们对 Encoder 和 Decoder 的每个 self-attention 的 Query 和 Key 的位置编码做个归纳，如图 35 所示，Value 没有位置编码：</p>
<p><img alt="" src="https://pic1.zhimg.com/v2-6b9de32f5e1174eb3ecfecc2f0335d48_r.jpg" /></p>
<p><span class="arithmatex">\(\color{indianred}{\text{损失函数部分解读:}}\)</span></p>
<p>得到了 Decoder 的输出以后，如前文所述，应该是输出维度为 <span class="arithmatex">\((b,100,256)\)</span> 的张量。接下来要送入 2 个前馈网络 FFN 得到 class 和 Bounding Box。它们会得到 <span class="arithmatex">\(N=100\)</span> 个预测目标，包含类别和 Bounding Box，当然这个 100 肯定是大于图中的目标总数的。如果不够 100，则采用背景填充，计算 loss 时候回归分支分支仅仅计算有物体位置，背景集合忽略。所以，DETR 输出张量的维度为输出的张量的维度是 <span class="arithmatex">\((b,100,\color{crimson}{\text{class}+1})\)</span> 和 <span class="arithmatex">\((b,100,\color{purple}{4})\)</span>。对应 COCO 数据集来说， <span class="arithmatex">\(\color{crimson}{\text{class}+1=92}\)</span> ， <span class="arithmatex">\(\color{purple}{4}\)</span> 指的是每个预测目标归一化的 <span class="arithmatex">\((c_x,c_y,w,h)\)</span> 。归一化就是除以图片宽高进行归一化。</p>
<p>到这里我们了解了 DETR 的网络架构，我们发现，它输出的张量的维度是 <strong>分类分支：</strong><span class="arithmatex">\((b,100,\color{crimson}{\text{class}+1})\)</span> 和<strong>回归分支：</strong> <span class="arithmatex">\((b,100,\color{purple}{4})\)</span> ，其中，前者是指 100 个预测框的类型，后者是指 100 个预测框的 Bounding Box，但是读者可能会有疑问：预测框和真值是怎么一一对应的？换句话说：你怎么知道第 47 个预测框对应图片里的狗，第 88 个预测框对应图片里的车？等等。</p>
<p>我们下面就来聊聊这个问题。</p>
<p>相比 Faster R-CNN 等做法，DETR 最大特点是将目标检测问题转化为无序集合预测问题 (set prediction)。论文中特意指出 Faster R-CNN 这种设置一大堆 anchor，然后基于 anchor 进行分类和回归其实属于代理做法即不是最直接做法，<strong>目标检测任务就是输出无序集合</strong>，而 Faster R-CNN 等算法通过各种操作，并结合复杂后处理最终才得到无序集合属于绕路了，而 DETR 就比较纯粹了。现在核心问题来了：输出的 <span class="arithmatex">\((b,100)\)</span> 个检测结果是无序的，如何和 <span class="arithmatex">\(GT \; \text{Bounding Box}\)</span> 计算 loss？这就需要用到经典的双边匹配算法了，也就是常说的匈牙利算法，该算法广泛应用于最优分配问题。</p>
<p>一幅图片，我们把第 <span class="arithmatex">\(i\)</span> 个物体的真值表达为 <span class="arithmatex">\(y_i=(c_i,b_i)\)</span> ，其中， <span class="arithmatex">\(c_i\)</span> 表示它的 <span class="arithmatex">\(\color{crimson}{\text{class}}\)</span> ， <span class="arithmatex">\(b_i\)</span> 表示它的 <span class="arithmatex">\(\color{purple}{\text{Bounding Box}}\)</span> 。我们定义 <span class="arithmatex">\(\hat y = \{\hat y_i\}_{i=1}^{N}\)</span> 为网络输出的 <span class="arithmatex">\(N\)</span> 个预测值。</p>
<p>假设我们已经了解了什么是匈牙利算法 (先假装了解了)，对于第 <span class="arithmatex">\(i\)</span> 个 <span class="arithmatex">\(GT\)</span> ， <span class="arithmatex">\(\sigma(i)\)</span> 为匈牙利算法得到的与 <span class="arithmatex">\(GT_i\)</span> 对应的 prediction 的索引。我举个栗子，比如 <span class="arithmatex">\(i=3,\sigma(i)=18\)</span> ，意思就是：与第 3 个真值对应的预测值是第 18 个。</p>
<p>那我能根据 <span class="arithmatex">\(\color{green}{\text{匈牙利算法}}\)</span> ，找到 <span class="arithmatex">\(\color{green}{\text{与每个真值对应的预测值是哪个}}\)</span> ，<strong>那究竟是如何找到呢？</strong></p>
<div class="arithmatex">\[\begin{equation} \label{eq:matching} \hat{\sigma} = \arg\min_{\sigma\in\Sigma_N} \sum_{i}^{N} L_{match}(y_i, \hat y_{\sigma(i)}), \end{equation} \tag{12}\]</div>
<p>我们看看这个表达式是甚么意思，对于某一个真值 <span class="arithmatex">\(y_i\)</span> ，假设我们已经找到这个真值对应的预测值 <span class="arithmatex">\(\hat y_{\sigma(i)}\)</span> ，这里的 <span class="arithmatex">\(\Sigma_N\)</span> 是所有可能的排列，代表<strong>从真值索引到预测值索引的所有的映射</strong>，然后用 <span class="arithmatex">\(L_{match}\)</span> 最小化 <span class="arithmatex">\(y_i\)</span> 和 <span class="arithmatex">\(\hat y_{\sigma(i)}\)</span> 的距离。这个 <span class="arithmatex">\(L_{match}\)</span> 具体是：</p>
<div class="arithmatex">\[-\mathbb{1}_{\left\{ c_i\neq\varnothing \right\}}\hat p_{\sigma(i)}(c_i) + \mathbb{1}_{\left\{ c_i\neq\varnothing \right\}} L_{box}({b_{i}, \hat b_{\sigma(i)}}) \tag{13}\]</div>
<p>意思是：假设当前从真值索引到预测值索引的所有的映射为 <span class="arithmatex">\(\sigma\)</span> ，对于图片中的每个真值 <span class="arithmatex">\(i\)</span> ，先找到对应的预测值 <span class="arithmatex">\(\sigma(i)\)</span> ，再看看分类网络的结果 <span class="arithmatex">\(\hat p_{\sigma(i)}(c_i)\)</span> ，取反作为 <span class="arithmatex">\(L_{match}\)</span> 的第 1 部分。再计算回归网络的结果 <span class="arithmatex">\(\hat b_{\sigma(i)}\)</span> 与真值的 <span class="arithmatex">\(\color{purple}{\text{Bounding Box}}\)</span> 的差异，即 <span class="arithmatex">\(L_{box}({b_{i}, \hat b_{\sigma(i)}})\)</span> ，作为 <span class="arithmatex">\(L_{match}\)</span> 的第 2 部分。</p>
<p>所以，可以使得 <span class="arithmatex">\(L_{match}\)</span> 最小的排列 <span class="arithmatex">\(\hat\sigma\)</span> 就是我们要找的排列，<strong>即：对于图片中的每个真值 <span class="arithmatex">\(i\)</span> 来讲， <span class="arithmatex">\(\hat\sigma(i)\)</span> 就是这个真值所对应的预测值的索引。</strong></p>
<p>请读者细品这个 寻找匹配的过程 ，这就是匈牙利算法的过程。是不是与 Anchor 或 Proposal 有异曲同工的地方，只是此时我们找的是一对一匹配。</p>
<p>接下来就是使用上一步得到的排列 <span class="arithmatex">\(\hat\sigma\)</span> ，计算匈牙利损失：</p>
<div class="arithmatex">\[L_{\text{Hungarian}}({y, \hat y}) = \sum_{i=1}^N \left[-\log \hat p_{\hat{\sigma}(i)}(c_{i}) + \mathbb{1}_{\left\{ c_i\neq\varnothing \right\}} \ L_{box}{(b_{i}, \hat b_{\hat{\sigma}(i)}})\right] \tag{14}\]</div>
<p>式中的 <span class="arithmatex">\(L_{box}\)</span> 具体为：</p>
<div class="arithmatex">\[L_{box}{(b_{i}, \hat b_{\hat{\sigma}(i)}}) = \lambda_{\rm iou}L_{iou}({b_{i}, \hat b_{\sigma(i)}})+ \lambda_{\rm L1}||b_{i}- \hat b_{\sigma(i)}||_1 ,\; where \;\lambda_{\rm iou}, \lambda_{\rm L1}\in R \tag{15}\]</div>
<p>最常用的 <span class="arithmatex">\(L_1 \;loss\)</span> 对于大小 <span class="arithmatex">\(\color{purple}{\text{Bounding Box}}\)</span> 会有不同的标度，即使它们的相对误差是相似的。为了缓解这个问题，作者使用了 <span class="arithmatex">\(L_1 \;loss\)</span> 和广义 IoU 损耗 <span class="arithmatex">\(L_{iou}\)</span> 的线性组合，它是比例不变的。</p>
<p>Hungarian 意思就是匈牙利，也就是前面的 <span class="arithmatex">\(L_{match}\)</span> ，上述意思是需要计算 <span class="arithmatex">\(M\)</span> 个 <span class="arithmatex">\(\text{GT}\;\color{purple}{\text{Bounding Box}}\)</span> 和 <span class="arithmatex">\(N\)</span> 个输预测出集合两两之间的广义距离，<strong>距离越近表示越可能是最优匹配关系</strong>，也就是两者最密切。广义距离的计算考虑了分类分支和回归分支。</p>
<p><strong>最后，再概括一下 DETR 的 End-to-End 的原理，前面那么多段话就是为了讲明白这个事情，如果你对前面的论述还存在疑问的话，把下面一直到 Experiments 之前的这段话看懂就能解决你的困惑。</strong></p>
<p><strong>DETR 是怎么训练的？</strong></p>
<p>训练集里面的任何一张图片，假设第 1 张图片，我们通过模型产生 100 个预测框 <span class="arithmatex">\(\text{Predict}\;\color{purple}{\text{Bounding Box}}\)</span> ，假设这张图片有只 3 个 <span class="arithmatex">\(\text{GT}\;\color{purple}{\text{Bounding Box}}\)</span> ，它们分别是 <span class="arithmatex">\(\color{orange}{\text{Car}},\color{green}{\text{Dog}},\color{darkturquoise}{\text{Horse}}\)</span> 。</p>
<div class="arithmatex">\[(\text{label}_{\color{orange}{\text{Car}}}=3,\text{label}_{\color{green}{\text{Dog}}}=24,\text{label}_{\color{orange}{\color{darkturquoise}{\text{Horse}}}}=75)\\\]</div>
<p>问题是：我怎么知道这 100 个预测框哪个是对应 <span class="arithmatex">\(\color{orange}{\text{Car}}\)</span> ，哪个是对应 <span class="arithmatex">\(\color{green}{\text{Dog}}\)</span> ，哪个是对应 <span class="arithmatex">\(\color{darkturquoise}{\text{Horse}}\)</span> ？</p>
<p>我们建立一个 <span class="arithmatex">\((100,3)\)</span> 的矩阵，矩阵里面的元素就是 <span class="arithmatex">\((13)\)</span> 式的计算结果，举个例子：比如左上角的 <span class="arithmatex">\((1,1)\)</span> 号元素的含义是：第 1 个预测框对应 <span class="arithmatex">\(\color{orange}{\text{Car}}(\text{label}=3)\)</span> 的情况下的 <span class="arithmatex">\(L_{match}\)</span> 值。我们用 <strong>scipy.optimize</strong> 这个库中的 <strong>linear_sum_assignment</strong> 函数找到最优的匹配，这个过程我们称之为：<strong>"匈牙利算法 (Hungarian Algorithm)"</strong>。</p>
<p>假设 <strong>linear_sum_assignment</strong> 做完以后的结果是：第 <span class="arithmatex">\(23\)</span> 个预测框对应 <span class="arithmatex">\(\color{orange}{\text{Car}}\)</span> ，第 <span class="arithmatex">\(44\)</span> 个预测框对应 <span class="arithmatex">\(\color{green}{\text{Dog}}\)</span> ，第 <span class="arithmatex">\(95\)</span> 个预测框对应 <span class="arithmatex">\(\color{darkturquoise}{\text{Horse}}\)</span> 。</p>
<p>现在把第 <span class="arithmatex">\(23,44,95\)</span> 个预测框挑出来，按照 <span class="arithmatex">\((14)\)</span> 式计算 Loss，得到这个图片的 Loss。</p>
<p>把所有的图片按照这个模式去训练模型。</p>
<p><strong>训练完以后怎么用？</strong></p>
<p>训练完以后，你的模型学习到了一种能力，即：模型产生的 100 个预测框，它知道某个预测框该对应什么 <span class="arithmatex">\(\text{Object}\)</span> ，比如，模型学习到：第 1 个 <span class="arithmatex">\(\text{Predict}\;\color{purple}{\text{Bounding Box}}\)</span> 对应 <span class="arithmatex">\(\color{orange}{\text{Car}}(\text{label}=3)\)</span> ，第 2 个 <span class="arithmatex">\(\text{Predict}\;\color{purple}{\text{Bounding Box}}\)</span> 对应 <span class="arithmatex">\(\color{chocolate}{\text{Bus}}(\text{label}=16)\)</span> ，第 3 个 <span class="arithmatex">\(\text{Predict}\;\color{purple}{\text{Bounding Box}}\)</span> 对应 <span class="arithmatex">\(\color{lightskyblue}{\text{Sky}}(\text{label}=21)\)</span> ，第 4 个 <span class="arithmatex">\(\text{Predict}\;\color{purple}{\text{Bounding Box}}\)</span> 对应 <span class="arithmatex">\(\color{green}{\text{Dog}}(\text{label}=24)\)</span> ，第 5 个 <span class="arithmatex">\(\text{Predict}\;\color{purple}{\text{Bounding Box}}\)</span> 对应 <span class="arithmatex">\(\color{darkturquoise}{\text{Horse}}(\text{label}=75)\)</span> ，第 6-100 个 <span class="arithmatex">\(\text{Predict}\;\color{purple}{\text{Bounding Box}}\)</span> 对应 <span class="arithmatex">\(\color{dimgray}{\varnothing }(\text{label}=92)\)</span> ，等等。</p>
<p>以上只是我举的一个例子，意思是说：模型知道了自己的 100 个预测框每个该做什么事情，即：每个框该预测什么样的 <span class="arithmatex">\(\text{Object}\)</span> 。</p>
<p><strong>为什么训练完以后，模型学习到了一种能力，即：模型产生的 100 个预测框，它知道某个预测框该对应什么 <span class="arithmatex">\(\text{Object}\)</span> ？</strong></p>
<p>还记得前面说的 Object queries 吗？它是一个维度为 <span class="arithmatex">\((100,b,256)\)</span> 维的张量，初始时元素全为 <span class="arithmatex">\(0\)</span> 。实现方式是 <strong>nn.Embedding(num_queries, hidden_dim)</strong>，这里 num_queries=100，hidden_dim=256，它是可训练的。这里的 <span class="arithmatex">\(b\)</span> 指的是 batch size，我们考虑单张图片，所以假设 Object queries 是一个维度为 <span class="arithmatex">\((100,256)\)</span> 维的张量。我们训练完模型以后，这个张量已经训练完了，那<strong>此时的 Object queries 究竟代表什么？</strong></p>
<p>我们把此时的 Object queries <strong>看成 100 个格子，每个格子是个 256 维的向量。</strong>训练完以后，这 100 个格子里面<strong>注入了不同 <span class="arithmatex">\(\text{Object}\)</span> 的位置信息和类别信息</strong>。<strong>比如第 1 个格子里面的这个 256 维的向量代表着 <span class="arithmatex">\(\color{orange}{\text{Car}}\)</span> 这种 <span class="arithmatex">\(\text{Object}\)</span> 的位置信息，</strong>这种信息是通过训练，考虑了所有图片的某个位置附近的 <span class="arithmatex">\(\color{orange}{\text{Car}}\)</span> 编码特征，属于和位置有关的全局 <span class="arithmatex">\(\color{orange}{\text{Car}}\)</span> 统计信息。</p>
<p>测试时，假设图片中有 <span class="arithmatex">\(\color{orange}{\text{Car}},\color{green}{\text{Dog}},\color{darkturquoise}{\text{Horse}}\)</span> 三种物体，该图片会输入到编码器中进行特征编码，假设特征没有丢失，Decoder 的 <strong>Key</strong> 和 <strong>Value</strong> 就是编码器输出的编码向量 (如图 30 所示)，而 Query 就是 Object queries，就是我们的 100 个格子。</p>
<p><strong>Query 可以视作代表不同 <span class="arithmatex">\(\text{Object}\)</span> 的信息，而 Key 和 Value 可以视作代表图像的全局信息。</strong></p>
<p>现在通过注意力模块将 <strong>Query</strong> 和 <strong>Key</strong> 计算，然后加权 <strong>Value</strong> 得到解码器输出。对于第 1 个格子的 <strong>Query</strong> 会和 <strong>Key</strong> 中的所有向量进行计算，目的是查找某个位置附近有没有 <span class="arithmatex">\(\color{orange}{\text{Car}}\)</span> ，如果有那么该特征就会加权输出，对于第 3 个格子的 <strong>Query</strong> 会和 <strong>Key</strong> 中的所有向量进行计算，目的是查找某个位置附近有没有 <span class="arithmatex">\(\color{lightskyblue}{\text{Sky}}\)</span> ，很遗憾，这个没有，所以输出的信息里面没有 <span class="arithmatex">\(\color{lightskyblue}{\text{Sky}}\)</span> 。</p>
<p>整个过程计算完成后就可以把编码向量中的 <span class="arithmatex">\(\color{orange}{\text{Car}},\color{green}{\text{Dog}},\color{darkturquoise}{\text{Horse}}\)</span> 的编码嵌入信息提取出来，然后后面接 <span class="arithmatex">\(FFN\)</span> 进行分类和回归就比较容易，因为特征已经对齐了。</p>
<p>发现了吗？Object queries 在训练过程中对于 <span class="arithmatex">\(N\)</span> 个格子会压缩入对应的和位置和类别相关的统计信息，在测试阶段就可以利用该 <strong>Query</strong> 去和<strong>某个图像的编码特征 Key，Value</strong> 计算，<strong>若图片中刚好有 Query 想找的特征，比如</strong> <span class="arithmatex">\(\color{orange}{\text{Car}}\)</span> <strong>，则这个特征就能提取出来，最后通过 2 个</strong> <span class="arithmatex">\(FFN\)</span> <strong>进行分类和回归。</strong>所以前面才会说 Object queries 作用非常类似 Faster R-CNN 中的 anchor，这个 anchor 是可学习的，由于维度比较高，故可以表征的东西丰富，当然维度越高，训练时长就会越长。</p>
<p><strong>这就是 DETR 的 End-to-End 的原理，可以简单归结为上面的几段话，你读懂了上面的话，也就明白了 DETR 以及 End-to-End 的 Detection 模型原理。</strong></p>
<p><strong>Experiments：</strong></p>
<p><strong>1. 性能对比：</strong></p>
<p><img alt="" src="https://pic4.zhimg.com/v2-a82446719e7ebd58ac2b3680bd096b6b_r.jpg" /></p>
<p><strong>2. 编码器层数对比实验：</strong></p>
<p><img alt="" src="https://pic2.zhimg.com/v2-35d68162e148aa1457e7f91d135cfdf1_r.jpg" /></p>
<p>可以发现，编码器层数越多越好，最后就选择 6。</p>
<p>下图 38 为最后一个 Encoder Layer 的 attention 可视化，Encoder 已经分离了 instances，简化了 Decoder 的对象提取和定位。</p>
<p><img alt="" src="https://pic3.zhimg.com/v2-dffe148c6e78f7b67cf6aa5c8bbbc316_r.jpg" /></p>
<p><strong>3. 解码器层数对比实验：</strong></p>
<p><img alt="" src="https://pic4.zhimg.com/v2-87f7c11d6b088af0d0351e3e4808e4b7_b.jpg" /></p>
<p>可以发现，性能随着解码器层数的增加而提升，DETR 本不需要 NMS，但是作者也进行了，上图中的 NMS 操作是指 DETR 的每个解码层都可以输入无序集合，那么将所有解码器无序集合全部保留，然后进行 NMS 得到最终输出，可以发现性能稍微有提升，特别是 AP50。这可以通过以下事实来解释：Transformer 的单个 Decoder Layer 不能计算输出元素之间的任何互相关，因此它易于对同一对象进行多次预测。在第 2 个和随后的 Decoder Layer 中，self-attention 允许模型抑制重复预测。所以 NMS 带来的改善随着 Decoder Layer 的增加而减少。在最后几层，作者观察到 AP 的一个小损失，因为 NMS 错误地删除了真实的 positive prediction。  </p>
<p><img alt="" src="https://pic1.zhimg.com/v2-6b80634bf88e496f035945ec25c40764_r.jpg" /></p>
<p>类似于可视化编码器注意力，作者在图 40 中可视化解码器注意力，用不同的颜色给每个预测对象的注意力图着色。观察到，解码器的 attention 相当局部，这意味着它主要关注对象的四肢，如头部或腿部。我们假设，在编码器通过全局关注分离实例之后，<strong>解码器只需要关注极端来提取类和对象边界。</strong></p>
<ul>
<li><strong>3.2 DETR 代码解读：</strong></li>
</ul>
<p><a href="https://github.com/facebookresearch/detr">https://github.com/facebookresearch/detr</a></p>
<p>分析都注释在了代码中。</p>
<p><strong>二维位置编码：</strong><br />
DETR 的二维位置编码：<br />
首先构造位置矩阵 x_embed 和 y_embed，这里用到了 python 函数 cumsum，作用是对一个矩阵的元素进行累加，那么累加以后最后一个元素就是所有累加元素的和，省去了求和的步骤，直接用这个和做归一化，对应 x_embed[:, :, -1:] 和 y_embed[:, -1:, :]。<br />
<strong>这里我想着重强调下代码中一些变量的 shape，方便读者掌握作者编程的思路：</strong><br />
值得注意的是，tensor_list 的类型是 NestedTensor，内部自动附加了 mask，用于表示动态 shape，是 pytorch 中 tensor 新特性 <a href="https://github.com/pytorch/nestedtensor">https://github.com/pytorch/nestedtensor</a>。全是 false。<br />
x：(b,c,H,W)<br />
mask：(b,H,W)，全是 False。<br />
not_mask：(b,H,W)，全是 True。<br />
首先出现的 y_embed：(b,H,W)，具体是 1,1,1,1,......,2,2,2,2,......3,3,3,3,......<br />
首先出现的 x_embed：(b,H,W)，具体是 1,2,3,4,......,1,2,3,4,......1,2,3,4,......<br />
self.num_pos_feats = 128<br />
首先出现的 dim_t = [0,1,2,3,.....,127]<br />
pos_x：(b,H,W,128)<br />
pos_y：(b,H,W,128)<br />
flatten 后面的数字指的是：flatten() 方法应从哪个轴开始展开操作。<br />
torch.stack((pos_x[:, :, :, 0::2].sin(), pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3)<br />
pos_y = torch.stack((pos_y[:, :, :, 0::2].sin(), pos_y[:, :, :, 1::2].cos()), dim=4)<br />
这一步执行完以后变成 (b,H,W,2,64) 通过 flatten()方法从第 3 个轴开始展平，变为：(b,H,W,128)<br />
torch.cat((pos_y, pos_x), dim=3) 之后变为 (b,H,W,256)，再最后 permute 为 (b,256，H,W)。<br />
PositionEmbeddingSine 类继承 nn.Module 类。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class PositionEmbeddingSine(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>
<span class="linenos" data-linenos=" 3 "></span>    def forward(self, tensor_list: NestedTensor):
<span class="linenos" data-linenos=" 4 "></span>#输入是b,c,h,w
<span class="linenos" data-linenos=" 5 "></span>#tensor_list的类型是NestedTensor，内部自动附加了mask，
<span class="linenos" data-linenos=" 6 "></span>#用于表示动态shape，是pytorch中tensor新特性https://github.com/pytorch/nestedtensor
<span class="linenos" data-linenos=" 7 "></span>        x = tensor_list.tensors
<span class="linenos" data-linenos=" 8 "></span># 附加的mask，shape是b,h,w 全是false
<span class="linenos" data-linenos=" 9 "></span>        mask = tensor_list.mask
<span class="linenos" data-linenos="10 "></span>        assert mask is not None
<span class="linenos" data-linenos="11 "></span>        not_mask = ~mask
<span class="linenos" data-linenos="12 "></span># 因为图像是2d的，所以位置编码也分为x,y方向
<span class="linenos" data-linenos="13 "></span># 1 1 1 1 ..  2 2 2 2... 3 3 3...
<span class="linenos" data-linenos="14 "></span>        y_embed = not_mask.cumsum(1, dtype=torch.float32)
<span class="linenos" data-linenos="15 "></span># 1 2 3 4 ... 1 2 3 4...
<span class="linenos" data-linenos="16 "></span>        x_embed = not_mask.cumsum(2, dtype=torch.float32)
<span class="linenos" data-linenos="17 "></span>        if self.normalize:
<span class="linenos" data-linenos="18 "></span>            eps = 1e-6
<span class="linenos" data-linenos="19 "></span>            y_embed = y_embed / (y_embed[:, -1:, :] + eps) * self.scale
<span class="linenos" data-linenos="20 "></span>            x_embed = x_embed / (x_embed[:, :, -1:] + eps) * self.scale
<span class="linenos" data-linenos="21 "></span> # num_pos_feats = 128
<span class="linenos" data-linenos="22 "></span># 0~127 self.num_pos_feats=128,因为前面输入向量是256，编码是一半sin，一半cos
<span class="linenos" data-linenos="23 "></span>        dim_t = torch.arange(self.num_pos_feats, dtype=torch.float32, device=x.device)
<span class="linenos" data-linenos="24 "></span>        dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)
<span class="linenos" data-linenos="25 "></span> # 输出shape=b,h,w,128
<span class="linenos" data-linenos="26 "></span>        pos_x = x_embed[:, :, :, None] / dim_t
<span class="linenos" data-linenos="27 "></span>        pos_y = y_embed[:, :, :, None] / dim_t
<span class="linenos" data-linenos="28 "></span>        pos_x = torch.stack((pos_x[:, :, :, 0::2].sin(), pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3)
<span class="linenos" data-linenos="29 "></span>        pos_y = torch.stack((pos_y[:, :, :, 0::2].sin(), pos_y[:, :, :, 1::2].cos()), dim=4).flatten(3)
<span class="linenos" data-linenos="30 "></span>        pos = torch.cat((pos_y, pos_x), dim=3).permute(0, 3, 1, 2)
<span class="linenos" data-linenos="31 "></span># 每个特征图的xy位置都编码成256的向量，其中前128是y方向编码，而128是x方向编码
<span class="linenos" data-linenos="32 "></span>        return pos
<span class="linenos" data-linenos="33 "></span># b,n=256,h,w
</code></pre></div>
<p>作者定义了一种数据结构：NestedTensor，里面打包存了两个变量：x 和 mask。</p>
<p><strong>NestedTensor：</strong><br />
里面打包存了两个变量：x 和 mask。<br />
to() 函数：把变量移到 GPU 中。<strong>Backbone：</strong></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class BackboneBase(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>
<span class="linenos" data-linenos=" 3 "></span>    def __init__(self, backbone: nn.Module, train_backbone: bool, num_channels: int, return_interm_layers: bool):
<span class="linenos" data-linenos=" 4 "></span>        super().__init__()
<span class="linenos" data-linenos=" 5 "></span>        for name, parameter in backbone.named_parameters():
<span class="linenos" data-linenos=" 6 "></span>            if not train_backbone or &#39;layer2&#39; not in name and &#39;layer3&#39; not in name and &#39;layer4&#39; not in name:
<span class="linenos" data-linenos=" 7 "></span>                parameter.requires_grad_(False)
<span class="linenos" data-linenos=" 8 "></span>        if return_interm_layers:
<span class="linenos" data-linenos=" 9 "></span>            return_layers = {&quot;layer1&quot;: &quot;0&quot;, &quot;layer2&quot;: &quot;1&quot;, &quot;layer3&quot;: &quot;2&quot;, &quot;layer4&quot;: &quot;3&quot;}
<span class="linenos" data-linenos="10 "></span>        else:
<span class="linenos" data-linenos="11 "></span>            return_layers = {&#39;layer4&#39;: &quot;0&quot;}
<span class="linenos" data-linenos="12 "></span>
<span class="linenos" data-linenos="13 "></span>#作用的模型：定义BackboneBase时传入的nn.Moduleclass的backbone，返回的layer：来自bool变量return_interm_layers
<span class="linenos" data-linenos="14 "></span>        self.body = IntermediateLayerGetter(backbone, return_layers=return_layers)
<span class="linenos" data-linenos="15 "></span>        self.num_channels = num_channels
<span class="linenos" data-linenos="16 "></span>
<span class="linenos" data-linenos="17 "></span>    def forward(self, tensor_list: NestedTensor):
<span class="linenos" data-linenos="18 "></span>#BackboneBase的输入是一个NestedTensor
<span class="linenos" data-linenos="19 "></span>#xs中间层的输出，
<span class="linenos" data-linenos="20 "></span>        xs = self.body(tensor_list.tensors)
<span class="linenos" data-linenos="21 "></span>        out: Dict[str, NestedTensor] = {}
<span class="linenos" data-linenos="22 "></span>        for name, x in xs.items():
<span class="linenos" data-linenos="23 "></span>            m = tensor_list.mask
<span class="linenos" data-linenos="24 "></span>            assert m is not None
<span class="linenos" data-linenos="25 "></span>#F.interpolate上下采样，调整mask的size
<span class="linenos" data-linenos="26 "></span>#to(torch.bool)  把mask转化为Bool型变量
<span class="linenos" data-linenos="27 "></span>            mask = F.interpolate(m[None].float(), size=x.shape[-2:]).to(torch.bool)[0]
<span class="linenos" data-linenos="28 "></span>            out[name] = NestedTensor(x, mask)
<span class="linenos" data-linenos="29 "></span>        return out
<span class="linenos" data-linenos="30 "></span>
<span class="linenos" data-linenos="31 "></span>class Backbone(BackboneBase):
<span class="linenos" data-linenos="32 "></span>    &quot;&quot;&quot;ResNet backbone with frozen BatchNorm.&quot;&quot;&quot;
<span class="linenos" data-linenos="33 "></span>    def __init__(self, name: str,
<span class="linenos" data-linenos="34 "></span>                 train_backbone: bool,
<span class="linenos" data-linenos="35 "></span>                 return_interm_layers: bool,
<span class="linenos" data-linenos="36 "></span>                 dilation: bool):
<span class="linenos" data-linenos="37 "></span>#根据name选择backbone, num_channels, return_interm_layers等，传入BackboneBase初始化
<span class="linenos" data-linenos="38 "></span>        backbone = getattr(torchvision.models, name)(
<span class="linenos" data-linenos="39 "></span>            replace_stride_with_dilation=[False, False, dilation],
<span class="linenos" data-linenos="40 "></span>            pretrained=is_main_process(), norm_layer=FrozenBatchNorm2d)
<span class="linenos" data-linenos="41 "></span>        num_channels = 512 if name in (&#39;resnet18&#39;, &#39;resnet34&#39;) else 2048
<span class="linenos" data-linenos="42 "></span>        super().__init__(backbone, train_backbone, num_channels, return_interm_layers)
</code></pre></div>
<p><strong>把 Backbone 和之前的 PositionEmbeddingSine 连在一起：</strong><br />
Backbone 完以后输出 (b,c,h,w)，再经过 PositionEmbeddingSine 输出 (b,H,W,256)。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class Joiner(nn.Sequential):
<span class="linenos" data-linenos=" 2 "></span>    def __init__(self, backbone, position_embedding):
<span class="linenos" data-linenos=" 3 "></span>        super().__init__(backbone, position_embedding)
<span class="linenos" data-linenos=" 4 "></span>
<span class="linenos" data-linenos=" 5 "></span>    def forward(self, tensor_list: NestedTensor):
<span class="linenos" data-linenos=" 6 "></span>        xs = self[0](tensor_list)
<span class="linenos" data-linenos=" 7 "></span>        out: List[NestedTensor] = []
<span class="linenos" data-linenos=" 8 "></span>        pos = []
<span class="linenos" data-linenos=" 9 "></span>        for name, x in xs.items():
<span class="linenos" data-linenos="10 "></span>            out.append(x)
<span class="linenos" data-linenos="11 "></span>            # position encoding
<span class="linenos" data-linenos="12 "></span>            pos.append(self[1](x).to(x.tensors.dtype))
<span class="linenos" data-linenos="13 "></span>
<span class="linenos" data-linenos="14 "></span>        return out, pos
<span class="linenos" data-linenos="15 "></span>
<span class="linenos" data-linenos="16 "></span>def build_backbone(args):
<span class="linenos" data-linenos="17 "></span>#position_embedding是个nn.module
<span class="linenos" data-linenos="18 "></span>    position_embedding = build_position_encoding(args)
<span class="linenos" data-linenos="19 "></span>    train_backbone = args.lr_backbone &gt; 0
<span class="linenos" data-linenos="20 "></span>    return_interm_layers = args.masks
<span class="linenos" data-linenos="21 "></span>#backbone是个nn.module
<span class="linenos" data-linenos="22 "></span>    backbone = Backbone(args.backbone, train_backbone, return_interm_layers, args.dilation)
<span class="linenos" data-linenos="23 "></span>#nn.Sequential在一起
<span class="linenos" data-linenos="24 "></span>    model = Joiner(backbone, position_embedding)
<span class="linenos" data-linenos="25 "></span>    model.num_channels = backbone.num_channels
<span class="linenos" data-linenos="26 "></span>    return model
</code></pre></div>
<p><strong>Transformer 的一个 Encoder Layer：</strong></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class TransformerEncoderLayer(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>
<span class="linenos" data-linenos=" 3 "></span>    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,
<span class="linenos" data-linenos=" 4 "></span>                 activation=&quot;relu&quot;, normalize_before=False):
<span class="linenos" data-linenos=" 5 "></span>        super().__init__()
<span class="linenos" data-linenos=" 6 "></span>        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)
<span class="linenos" data-linenos=" 7 "></span>        # Implementation of Feedforward model
<span class="linenos" data-linenos=" 8 "></span>        self.linear1 = nn.Linear(d_model, dim_feedforward)
<span class="linenos" data-linenos=" 9 "></span>        self.dropout = nn.Dropout(dropout)
<span class="linenos" data-linenos="10 "></span>        self.linear2 = nn.Linear(dim_feedforward, d_model)
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span>        self.norm1 = nn.LayerNorm(d_model)
<span class="linenos" data-linenos="13 "></span>        self.norm2 = nn.LayerNorm(d_model)
<span class="linenos" data-linenos="14 "></span>        self.dropout1 = nn.Dropout(dropout)
<span class="linenos" data-linenos="15 "></span>        self.dropout2 = nn.Dropout(dropout)
<span class="linenos" data-linenos="16 "></span>
<span class="linenos" data-linenos="17 "></span>        self.activation = _get_activation_fn(activation)
<span class="linenos" data-linenos="18 "></span>        self.normalize_before = normalize_before
<span class="linenos" data-linenos="19 "></span>
<span class="linenos" data-linenos="20 "></span>    def with_pos_embed(self, tensor, pos: Optional[Tensor]):
<span class="linenos" data-linenos="21 "></span>        return tensor if pos is None else tensor + pos
<span class="linenos" data-linenos="22 "></span>
<span class="linenos" data-linenos="23 "></span>    def forward_post(self,
<span class="linenos" data-linenos="24 "></span>                     src,
<span class="linenos" data-linenos="25 "></span>                     src_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="26 "></span>                     src_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="27 "></span>                     pos: Optional[Tensor] = None):
<span class="linenos" data-linenos="28 "></span>    # 和标准做法有点不一样，src加上位置编码得到q和k，但是v依然还是src，
<span class="linenos" data-linenos="29 "></span>    # 也就是v和qk不一样
<span class="linenos" data-linenos="30 "></span>        q = k = self.with_pos_embed(src, pos)
<span class="linenos" data-linenos="31 "></span>        src2 = self.self_attn(q, k, value=src, attn_mask=src_mask,
<span class="linenos" data-linenos="32 "></span>                              key_padding_mask=src_key_padding_mask)[0]
<span class="linenos" data-linenos="33 "></span>#Add and Norm
<span class="linenos" data-linenos="34 "></span>        src = src + self.dropout1(src2)
<span class="linenos" data-linenos="35 "></span>        src = self.norm1(src)
<span class="linenos" data-linenos="36 "></span>#FFN
<span class="linenos" data-linenos="37 "></span>        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))
<span class="linenos" data-linenos="38 "></span>#Add and Norm
<span class="linenos" data-linenos="39 "></span>        src = src + self.dropout2(src2)
<span class="linenos" data-linenos="40 "></span>        src = self.norm2(src)
<span class="linenos" data-linenos="41 "></span>        return src
<span class="linenos" data-linenos="42 "></span>
<span class="linenos" data-linenos="43 "></span>    def forward_pre(self, src,
<span class="linenos" data-linenos="44 "></span>                    src_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="45 "></span>                    src_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="46 "></span>                    pos: Optional[Tensor] = None):
<span class="linenos" data-linenos="47 "></span>        src2 = self.norm1(src)
<span class="linenos" data-linenos="48 "></span>        q = k = self.with_pos_embed(src2, pos)
<span class="linenos" data-linenos="49 "></span>        src2 = self.self_attn(q, k, value=src2, attn_mask=src_mask,
<span class="linenos" data-linenos="50 "></span>                              key_padding_mask=src_key_padding_mask)[0]
<span class="linenos" data-linenos="51 "></span>        src = src + self.dropout1(src2)
<span class="linenos" data-linenos="52 "></span>        src2 = self.norm2(src)
<span class="linenos" data-linenos="53 "></span>        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))
<span class="linenos" data-linenos="54 "></span>        src = src + self.dropout2(src2)
<span class="linenos" data-linenos="55 "></span>        return src
<span class="linenos" data-linenos="56 "></span>
<span class="linenos" data-linenos="57 "></span>    def forward(self, src,
<span class="linenos" data-linenos="58 "></span>                src_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="59 "></span>                src_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="60 "></span>                pos: Optional[Tensor] = None):
<span class="linenos" data-linenos="61 "></span>        if self.normalize_before:
<span class="linenos" data-linenos="62 "></span>            return self.forward_pre(src, src_mask, src_key_padding_mask, pos)
<span class="linenos" data-linenos="63 "></span>        return self.forward_post(src, src_mask, src_key_padding_mask, pos)
</code></pre></div>
<p><strong>有了一个 Encoder Layer 的定义，再看 Transformer 的整个 Encoder：</strong></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class TransformerEncoder(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    def __init__(self, encoder_layer, num_layers, norm=None):
<span class="linenos" data-linenos=" 3 "></span>        super().__init__()
<span class="linenos" data-linenos=" 4 "></span>        # 编码器copy6份
<span class="linenos" data-linenos=" 5 "></span>        self.layers = _get_clones(encoder_layer, num_layers)
<span class="linenos" data-linenos=" 6 "></span>        self.num_layers = num_layers
<span class="linenos" data-linenos=" 7 "></span>        self.norm = norm
<span class="linenos" data-linenos=" 8 "></span>
<span class="linenos" data-linenos=" 9 "></span>    def forward(self, src,
<span class="linenos" data-linenos="10 "></span>                mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="11 "></span>                src_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="12 "></span>                pos: Optional[Tensor] = None):
<span class="linenos" data-linenos="13 "></span>        # 内部包括6个编码器，顺序运行
<span class="linenos" data-linenos="14 "></span>        # src是图像特征输入，shape=hxw,b,256
<span class="linenos" data-linenos="15 "></span>        output = src
<span class="linenos" data-linenos="16 "></span>        for layer in self.layers:
<span class="linenos" data-linenos="17 "></span>            # 第一个编码器输入来自图像特征，后面的编码器输入来自前一个编码器输出
<span class="linenos" data-linenos="18 "></span>            output = layer(output, src_mask=mask,
<span class="linenos" data-linenos="19 "></span>                           src_key_padding_mask=src_key_padding_mask, pos=pos)
<span class="linenos" data-linenos="20 "></span>        return output
</code></pre></div>
<p><strong>Object Queries：可学习的位置编码：</strong><br />
注释中已经注明了变量的 shape 的变化过程，最终输出的是与 Positional Encoding 维度相同的位置编码，维度是 (b,H,W,256)，只是现在这个位置编码是可学习的了。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class PositionEmbeddingLearned(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &quot;&quot;&quot;
<span class="linenos" data-linenos=" 3 "></span>    Absolute pos embedding, learned.
<span class="linenos" data-linenos=" 4 "></span>    &quot;&quot;&quot;
<span class="linenos" data-linenos=" 5 "></span>    def __init__(self, num_pos_feats=256):
<span class="linenos" data-linenos=" 6 "></span>        super().__init__()]
<span class="linenos" data-linenos=" 7 "></span>#这里使用了nn.Embedding，这是一个矩阵类，里面初始化了一个随机矩阵，矩阵的长是字典的大小，宽是用来表示字典中每个元素的属性向量，
<span class="linenos" data-linenos=" 8 "></span># 向量的维度根据你想要表示的元素的复杂度而定。类实例化之后可以根据字典中元素的下标来查找元素对应的向量。输入下标0，输出就是embeds矩阵中第0行。
<span class="linenos" data-linenos=" 9 "></span>        self.row_embed = nn.Embedding(50, num_pos_feats)
<span class="linenos" data-linenos="10 "></span>        self.col_embed = nn.Embedding(50, num_pos_feats)
<span class="linenos" data-linenos="11 "></span>        self.reset_parameters()
<span class="linenos" data-linenos="12 "></span>
<span class="linenos" data-linenos="13 "></span>    def reset_parameters(self):
<span class="linenos" data-linenos="14 "></span>        nn.init.uniform_(self.row_embed.weight)
<span class="linenos" data-linenos="15 "></span>        nn.init.uniform_(self.col_embed.weight)
<span class="linenos" data-linenos="16 "></span>
<span class="linenos" data-linenos="17 "></span>#输入依旧是NestedTensor
<span class="linenos" data-linenos="18 "></span>    def forward(self, tensor_list: NestedTensor):
<span class="linenos" data-linenos="19 "></span>        x = tensor_list.tensors
<span class="linenos" data-linenos="20 "></span>        h, w = x.shape[-2:]
<span class="linenos" data-linenos="21 "></span>        i = torch.arange(w, device=x.device)
<span class="linenos" data-linenos="22 "></span>        j = torch.arange(h, device=x.device)
<span class="linenos" data-linenos="23 "></span>
<span class="linenos" data-linenos="24 "></span>#x_emb：(w, 128)
<span class="linenos" data-linenos="25 "></span>#y_emb：(h, 128)
<span class="linenos" data-linenos="26 "></span>        x_emb = self.col_embed(i)
<span class="linenos" data-linenos="27 "></span>        y_emb = self.row_embed(j)
<span class="linenos" data-linenos="28 "></span>        pos = torch.cat([
<span class="linenos" data-linenos="29 "></span>            x_emb.unsqueeze(0).repeat(h, 1, 1),#(1,w,128) → (h,w,128)
<span class="linenos" data-linenos="30 "></span>            y_emb.unsqueeze(1).repeat(1, w, 1),#(h,1,128) → (h,w,128)
<span class="linenos" data-linenos="31 "></span>        ], dim=-1).permute(2, 0, 1).unsqueeze(0).repeat(x.shape[0], 1, 1, 1)
<span class="linenos" data-linenos="32 "></span>#(h,w,256) → (256,h,w) → (1,256,h,w) → (b,256,h,w)
<span class="linenos" data-linenos="33 "></span>        return pos
<span class="linenos" data-linenos="34 "></span>
<span class="linenos" data-linenos="35 "></span>def build_position_encoding(args):
<span class="linenos" data-linenos="36 "></span>    N_steps = args.hidden_dim // 2
<span class="linenos" data-linenos="37 "></span>    if args.position_embedding in (&#39;v2&#39;, &#39;sine&#39;):
<span class="linenos" data-linenos="38 "></span>        # TODO find a better way of exposing other arguments
<span class="linenos" data-linenos="39 "></span>        position_embedding = PositionEmbeddingSine(N_steps, normalize=True)
<span class="linenos" data-linenos="40 "></span>    elif args.position_embedding in (&#39;v3&#39;, &#39;learned&#39;):
<span class="linenos" data-linenos="41 "></span>        position_embedding = PositionEmbeddingLearned(N_steps)
<span class="linenos" data-linenos="42 "></span>    else:
<span class="linenos" data-linenos="43 "></span>        raise ValueError(f&quot;not supported {args.position_embedding}&quot;)
<span class="linenos" data-linenos="44 "></span>
<span class="linenos" data-linenos="45 "></span>    return position_embedding
</code></pre></div>
<p><strong>Transformer 的一个 Decoder Layer：</strong><br />
注意变量的命名：<br />
object queries(query_pos)<br />
Encoder 的位置编码 (pos)<br />
Encoder 的输出 (memory)</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>def forward_post(self, tgt, memory,
<span class="linenos" data-linenos=" 2 "></span>                     tgt_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos=" 3 "></span>                     memory_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos=" 4 "></span>                     tgt_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos=" 5 "></span>                     memory_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos=" 6 "></span>                     pos: Optional[Tensor] = None,
<span class="linenos" data-linenos=" 7 "></span>                     query_pos: Optional[Tensor] = None):
<span class="linenos" data-linenos=" 8 "></span> #query,key的输入是object queries(query_pos) + Decoder的输入(tgt),shape都是(100,b,256)
<span class="linenos" data-linenos=" 9 "></span>#value的输入是Decoder的输入(tgt),shape = (100,b,256)
<span class="linenos" data-linenos="10 "></span>        q = k = self.with_pos_embed(tgt, query_pos)
<span class="linenos" data-linenos="11 "></span> #Multi-head self-attention
<span class="linenos" data-linenos="12 "></span>        tgt2 = self.self_attn(q, k, value=tgt, attn_mask=tgt_mask,
<span class="linenos" data-linenos="13 "></span>                              key_padding_mask=tgt_key_padding_mask)[0]
<span class="linenos" data-linenos="14 "></span>#Add and Norm
<span class="linenos" data-linenos="15 "></span>        tgt = tgt + self.dropout1(tgt2)
<span class="linenos" data-linenos="16 "></span>        tgt = self.norm1(tgt)
<span class="linenos" data-linenos="17 "></span> #query的输入是上一个attention的输出(tgt) + object queries(query_pos)
<span class="linenos" data-linenos="18 "></span>#key的输入是Encoder的位置编码(pos) + Encoder的输出(memory)
<span class="linenos" data-linenos="19 "></span>#value的输入是Encoder的输出(memory)
<span class="linenos" data-linenos="20 "></span>        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt, query_pos),
<span class="linenos" data-linenos="21 "></span>                                   key=self.with_pos_embed(memory, pos),
<span class="linenos" data-linenos="22 "></span>                                   value=memory, attn_mask=memory_mask,
<span class="linenos" data-linenos="23 "></span>                                   key_padding_mask=memory_key_padding_mask)[0]
<span class="linenos" data-linenos="24 "></span> #Add and Norm
<span class="linenos" data-linenos="25 "></span>        tgt = tgt + self.dropout2(tgt2)
<span class="linenos" data-linenos="26 "></span>        tgt = self.norm2(tgt)
<span class="linenos" data-linenos="27 "></span> #FFN
<span class="linenos" data-linenos="28 "></span>        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))
<span class="linenos" data-linenos="29 "></span>        tgt = tgt + self.dropout3(tgt2)
<span class="linenos" data-linenos="30 "></span>        tgt = self.norm3(tgt)
<span class="linenos" data-linenos="31 "></span>        return tgt
<span class="linenos" data-linenos="32 "></span>
<span class="linenos" data-linenos="33 "></span>    def forward_pre(self, tgt, memory,
<span class="linenos" data-linenos="34 "></span>                    tgt_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="35 "></span>                    memory_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="36 "></span>                    tgt_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="37 "></span>                    memory_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="38 "></span>                    pos: Optional[Tensor] = None,
<span class="linenos" data-linenos="39 "></span>                    query_pos: Optional[Tensor] = None):
<span class="linenos" data-linenos="40 "></span>        tgt2 = self.norm1(tgt)
<span class="linenos" data-linenos="41 "></span>        q = k = self.with_pos_embed(tgt2, query_pos)
<span class="linenos" data-linenos="42 "></span>        tgt2 = self.self_attn(q, k, value=tgt2, attn_mask=tgt_mask,
<span class="linenos" data-linenos="43 "></span>                              key_padding_mask=tgt_key_padding_mask)[0]
<span class="linenos" data-linenos="44 "></span>        tgt = tgt + self.dropout1(tgt2)
<span class="linenos" data-linenos="45 "></span>        tgt2 = self.norm2(tgt)
<span class="linenos" data-linenos="46 "></span>        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt2, query_pos),
<span class="linenos" data-linenos="47 "></span>                                   key=self.with_pos_embed(memory, pos),
<span class="linenos" data-linenos="48 "></span>                                   value=memory, attn_mask=memory_mask,
<span class="linenos" data-linenos="49 "></span>                                   key_padding_mask=memory_key_padding_mask)[0]
<span class="linenos" data-linenos="50 "></span>        tgt = tgt + self.dropout2(tgt2)
<span class="linenos" data-linenos="51 "></span>        tgt2 = self.norm3(tgt)
<span class="linenos" data-linenos="52 "></span>        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt2))))
<span class="linenos" data-linenos="53 "></span>        tgt = tgt + self.dropout3(tgt2)
<span class="linenos" data-linenos="54 "></span>        return tgt
<span class="linenos" data-linenos="55 "></span>
<span class="linenos" data-linenos="56 "></span>    def forward(self, tgt, memory,
<span class="linenos" data-linenos="57 "></span>                tgt_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="58 "></span>                memory_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="59 "></span>                tgt_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="60 "></span>                memory_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos="61 "></span>                pos: Optional[Tensor] = None,
<span class="linenos" data-linenos="62 "></span>                query_pos: Optional[Tensor] = None):
<span class="linenos" data-linenos="63 "></span>        if self.normalize_before:
<span class="linenos" data-linenos="64 "></span>            return self.forward_pre(tgt, memory, tgt_mask, memory_mask,
<span class="linenos" data-linenos="65 "></span>                                    tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)
<span class="linenos" data-linenos="66 "></span>        return self.forward_post(tgt, memory, tgt_mask, memory_mask,
<span class="linenos" data-linenos="67 "></span>                                 tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)
</code></pre></div>
<p><strong>有了一个 Decoder Layer 的定义，再看 Transformer 的整个 Decoder：</strong></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class TransformerDecoder(nn.Module):
<span class="linenos" data-linenos=" 2 "></span> #值得注意的是：在使用TransformerDecoder时需要传入的参数有：
<span class="linenos" data-linenos=" 3 "></span># tgt：Decoder的输入，memory：Encoder的输出，pos：Encoder的位置编码的输出，query_pos：Object Queries，一堆mask
<span class="linenos" data-linenos=" 4 "></span>    def forward(self, tgt, memory,
<span class="linenos" data-linenos=" 5 "></span>                tgt_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos=" 6 "></span>                memory_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos=" 7 "></span>                tgt_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos=" 8 "></span>                memory_key_padding_mask: Optional[Tensor] = None,
<span class="linenos" data-linenos=" 9 "></span>                pos: Optional[Tensor] = None,
<span class="linenos" data-linenos="10 "></span>                query_pos: Optional[Tensor] = None):
<span class="linenos" data-linenos="11 "></span>        output = tgt
<span class="linenos" data-linenos="12 "></span> # Decoder输入的tgt:(100, b, 256)
<span class="linenos" data-linenos="13 "></span>        intermediate = []
<span class="linenos" data-linenos="14 "></span>
<span class="linenos" data-linenos="15 "></span>        for layer in self.layers:
<span class="linenos" data-linenos="16 "></span>            output = layer(output, memory, tgt_mask=tgt_mask,
<span class="linenos" data-linenos="17 "></span>                           memory_mask=memory_mask,
<span class="linenos" data-linenos="18 "></span>                           tgt_key_padding_mask=tgt_key_padding_mask,
<span class="linenos" data-linenos="19 "></span>                           memory_key_padding_mask=memory_key_padding_mask,
<span class="linenos" data-linenos="20 "></span>                           pos=pos, query_pos=query_pos)
<span class="linenos" data-linenos="21 "></span>            if self.return_intermediate:
<span class="linenos" data-linenos="22 "></span>                intermediate.append(self.norm(output))
<span class="linenos" data-linenos="23 "></span>
<span class="linenos" data-linenos="24 "></span>        if self.norm is not None:
<span class="linenos" data-linenos="25 "></span>            output = self.norm(output)
<span class="linenos" data-linenos="26 "></span>            if self.return_intermediate:
<span class="linenos" data-linenos="27 "></span>                intermediate.pop()
<span class="linenos" data-linenos="28 "></span>                intermediate.append(output)
<span class="linenos" data-linenos="29 "></span>
<span class="linenos" data-linenos="30 "></span>        if self.return_intermediate:
<span class="linenos" data-linenos="31 "></span>            return torch.stack(intermediate)
<span class="linenos" data-linenos="32 "></span>
<span class="linenos" data-linenos="33 "></span>        return output.unsqueeze(0)
</code></pre></div>
<p><strong>然后是把 Encoder 和 Decoder 拼在一起，即总的 Transformer 结构的实现：</strong><br />
此处考虑到字数限制，省略了代码。<strong>实现了 Transformer，还剩后面的 FFN：</strong></p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span>class MLP(nn.Module):
<span class="linenos" data-linenos=" 2 "></span>    &quot;&quot;&quot; Very simple multi-layer perceptron (also called FFN)&quot;&quot;&quot;
<span class="linenos" data-linenos=" 3 "></span>
<span class="linenos" data-linenos=" 4 "></span>    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):
<span class="linenos" data-linenos=" 5 "></span>        super().__init__()
<span class="linenos" data-linenos=" 6 "></span>        self.num_layers = num_layers
<span class="linenos" data-linenos=" 7 "></span>        h = [hidden_dim] * (num_layers - 1)
<span class="linenos" data-linenos=" 8 "></span>        self.layers = nn.ModuleList(nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim]))
<span class="linenos" data-linenos=" 9 "></span>
<span class="linenos" data-linenos="10 "></span>    def forward(self, x):
<span class="linenos" data-linenos="11 "></span>        for i, layer in enumerate(self.layers):
<span class="linenos" data-linenos="12 "></span>            x = F.relu(layer(x)) if i &lt; self.num_layers - 1 else layer(x)
<span class="linenos" data-linenos="13 "></span>        return x
</code></pre></div>
<p><strong>匈牙利匹配 HungarianMatcher 类：</strong><br />
<strong>这个类的目的是计算从 targets 到 predictions 的一种最优排列。</strong><br />
predictions 比 targets 的数量多，但我们要进行 1-to-1 matching，所以多的 predictions 将与 <span class="arithmatex">\(\varnothing\)</span> 匹配。<br />
这个函数整体在构建 (13) 式，cost_class，cost_bbox，cost_giou，对应的就是 (13) 式中的几个损失函数，它们的维度都是(b,100,m)。<br />
m 包含了这个 batch 内部所有的 <span class="arithmatex">\(\text{GT}\;\color{purple}{\text{Bounding Box}}\)</span> 。</p>
<div class="highlight"><pre><span></span><code><span class="linenos" data-linenos=" 1 "></span># pred_logits:[b,100,92]
<span class="linenos" data-linenos=" 2 "></span># pred_boxes:[b,100,4]
<span class="linenos" data-linenos=" 3 "></span># targets是个长度为b的list，其中的每个元素是个字典，共包含：labels-长度为(m,)的Tensor，元素是标签；boxes-长度为(m,4)的Tensor，元素是Bounding Box。
<span class="linenos" data-linenos=" 4 "></span># detr分类输出，num_queries=100，shape是(b,100,92)
<span class="linenos" data-linenos=" 5 "></span>        bs, num_queries = outputs[&quot;pred_logits&quot;].shape[:2]
<span class="linenos" data-linenos=" 6 "></span>
<span class="linenos" data-linenos=" 7 "></span>
<span class="linenos" data-linenos=" 8 "></span>        # We flatten to compute the cost matrices in a batch
<span class="linenos" data-linenos=" 9 "></span>        out_prob = outputs[&quot;pred_logits&quot;].flatten(0, 1).softmax(-1)  # [batch_size * num_queries, num_classes] = [100b, 92]
<span class="linenos" data-linenos="10 "></span>        out_bbox = outputs[&quot;pred_boxes&quot;].flatten(0, 1)  # [batch_size * num_queries, 4] = [100b, 4]
<span class="linenos" data-linenos="11 "></span>
<span class="linenos" data-linenos="12 "></span># 准备分类target shape=(m,)里面存储的是类别索引，m包括了整个batch内部的所有gt bbox
<span class="linenos" data-linenos="13 "></span>        # Also concat the target labels and boxes
<span class="linenos" data-linenos="14 "></span>        tgt_ids = torch.cat([v[&quot;labels&quot;] for v in targets])# (m,)[3,6,7,9,5,9,3]
<span class="linenos" data-linenos="15 "></span># 准备bbox target shape=(m,4)，已经归一化了
<span class="linenos" data-linenos="16 "></span>        tgt_bbox = torch.cat([v[&quot;boxes&quot;] for v in targets])# (m,4)
<span class="linenos" data-linenos="17 "></span>
<span class="linenos" data-linenos="18 "></span>#(100b,92)-&gt;(100b, m)，对于每个预测结果，把目前gt里面有的所有类别值提取出来，其余值不需要参与匹配
<span class="linenos" data-linenos="19 "></span>#对应上述公式，类似于nll loss，但是更加简单
<span class="linenos" data-linenos="20 "></span>        # Compute the classification cost. Contrary to the loss, we don&#39;t use the NLL,
<span class="linenos" data-linenos="21 "></span>        # but approximate it in 1 - proba[target class].
<span class="linenos" data-linenos="22 "></span>        # The 1 is a constant that doesn&#39;t change the matching, it can be ommitted.
<span class="linenos" data-linenos="23 "></span>#行：取每一行；列：只取tgt_ids对应的m列
<span class="linenos" data-linenos="24 "></span>        cost_class = -out_prob[:, tgt_ids]# (100b, m)
<span class="linenos" data-linenos="25 "></span>
<span class="linenos" data-linenos="26 "></span>        # Compute the L1 cost between boxes, 计算out_bbox和tgt_bbox两两之间的l1距离 (100b, m)
<span class="linenos" data-linenos="27 "></span>        cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)# (100b, m)
<span class="linenos" data-linenos="28 "></span>
<span class="linenos" data-linenos="29 "></span>        # Compute the giou cost betwen boxes, 额外多计算一个giou loss (100b, m)
<span class="linenos" data-linenos="30 "></span>        cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))
<span class="linenos" data-linenos="31 "></span>
<span class="linenos" data-linenos="32 "></span>#得到最终的广义距离(100b, m)，距离越小越可能是最优匹配
<span class="linenos" data-linenos="33 "></span>        # Final cost matrix
<span class="linenos" data-linenos="34 "></span>        C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou
<span class="linenos" data-linenos="35 "></span>#(100b, m)--&gt; (b, 100, m)
<span class="linenos" data-linenos="36 "></span>        C = C.view(bs, num_queries, -1).cpu()
<span class="linenos" data-linenos="37 "></span>
<span class="linenos" data-linenos="38 "></span>#计算每个batch内部有多少物体，后续计算时候按照单张图片进行匹配，没必要batch级别匹配,徒增计算
<span class="linenos" data-linenos="39 "></span>        sizes = [len(v[&quot;boxes&quot;]) for v in targets]
<span class="linenos" data-linenos="40 "></span>#匈牙利最优匹配，返回匹配索引
<span class="linenos" data-linenos="41 "></span>#enumerate(C.split(sizes, -1))]：(b,100,image1,image2,image3,...)
<span class="linenos" data-linenos="42 "></span>        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]   
<span class="linenos" data-linenos="43 "></span>        return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]
</code></pre></div>
<p>在得到匹配关系后算 loss 就水到渠成了。loss_labels 计算分类损失，loss_boxes 计算回归损失，包含 <span class="arithmatex">\(\text{L_1 loss, iou loss}\)</span> 。</p>
<p><strong>代码中的其他结构：</strong></p>
<p><strong>SmoothedValue：</strong></p>
<p>一种自定义的数据结构，属于 object 类。它是 deque 类型的双向队列，通过 update(value) 进行更新。</p>
<p><strong>MetricLogger：</strong></p>
<p>一种自定义的数据结构，属于 object 类。它是字典，通过 update(dict) 进行更新。通过 add_meter(name, meter) 函数添加键值。</p>
<p>log_every(data_loader, print_freq, header) 打印一些中间结果。</p>
<h2 id="_2">总结：<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>本文介绍的是 Transformer 的基础，包含什么是 Attention，什么是 Transformer，以及在检测上的应用。其实在 DETR 之前已经有人尝试过把 self-attention 机制或者 Transformer 应用在视觉任务上面，但是关注不多。DETR 的出现使得这个模型开始广泛应用在各种视觉任务上面，我也会在这个专栏的后续多多解读这些经典工作。</p>
<h2 id="_3"><strong>参考文献：</strong><a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>code：</strong></li>
</ul>
<p><a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch">https://github.com/jadore801120/attention-is-all-you-need-pytorchjadore801120/attention-is-all-you-need-pytorchhttps://github.com/jadore801120/attention-is-all-you-need-pytorch</a><a href="https://github.com/lucidrains/vit-pytorch">https://github.com/lucidrains/vit-pytorch</a><a href="https://github.com/facebookresearch/detr">https://github.com/facebookresearch/detr</a><a href="https://github.com/datawhalechina/leedeeprl-notes">https://github.com/datawhalechina/leedeeprl-notes</a></p>
<ul>
<li><strong>video：</strong></li>
</ul>
<p>第 1 小节的部分插图和文字稿来自李宏毅老师 PPT (如下链接) [侵删]。</p>
<p><a href="https://www.bilibili.com/video/av71295187/?spm_id_from=333.788.videocard.8">https://www.bilibili.com/video/av71295187/?spm_id_from=333.788.videocard.8</a></p>
<ul>
<li><strong>blog：</strong></li>
</ul>
<p><a href="https://baijiahao.baidu.com/s?id=1651219987457222196&amp;wfr=spider&amp;for=pc">Transformer 模型详解</a><a href="https://zhuanlan.zhihu.com/p/308301901">深度眸：3W 字长文带你轻松入门视觉 transformer</a><a href="https://blog.csdn.net/your_answer/article/details/79160045">利用 python 解决指派问题（匈牙利算法）_your_answer 的博客 - CSDN 博客</a></p>







  
  



  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../Self-Supervised%20Learning%20MoCoV2%2C3/" class="md-footer__link md-footer__link--prev" aria-label="Previous: MoCo V2">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                MoCo V2
              </div>
            </div>
          </a>
        
        
          
          <a href="../Vision%20Transformer%20%20%28%E4%BA%8C%29/" class="md-footer__link md-footer__link--next" aria-label="Next: Vision Transformer (二)">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Vision Transformer (二)
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tooltips", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "header.autohide"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.525ec568.min.js"></script>
      
        <script src="../mathjax-config.js"></script>
      
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
        <script src="../extra.js"></script>
      
        <script src="../js/toggle_sidebar.js"></script>
      
    
  </body>
</html>